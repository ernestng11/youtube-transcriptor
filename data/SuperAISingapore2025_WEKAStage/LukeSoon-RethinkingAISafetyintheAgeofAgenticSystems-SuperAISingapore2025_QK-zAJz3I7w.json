{
  "video_id": "QK-zAJz3I7w",
  "video_title": "Luke Soon - Rethinking AI Safety in the Age of Agentic Systems - SuperAI Singapore 2025",
  "video_url": "https://www.youtube.com/watch?v=QK-zAJz3I7w",
  "channel_title": "SuperAI",
  "published_at": "2025-06-25T12:46:59+00:00",
  "duration_seconds": null,
  "view_count": 11,
  "like_count": 0,
  "description": "Learn more about SuperAI: superai.com\nFollow us on X: x.com/superai_conf\n\nKeynote: Rethinking AI Safety in the Age of Agentic Systems\n\nSpeaker:\nLuke Soon, Partner @ PwC\n\nStage: WEKA Stage\n#superai #pwc #safety #airegulation #ai \n\nRecorded on 19 June 2025",
  "transcript": {
    "language": "en",
    "is_auto_generated": false,
    "total_segments": 389,
    "aggregated_text": "this time last year Hi I recall it was a bigger stage obviously and um I released a few predictions predictions that was released in 2022 and things that are getting a bit more interest right now is there's going to be a hot war sometime around 2028 and then there's a race for super intelligence So things are all happening right now So I'm going to traverse that story with some of you And the topic today that I want to talk about is safety Pretty boring topic with everything that's happening around here Not a pessimist don't get me wrong Very very excited with what we're doing with AI That's my day job But I just wanted humanity to know and be aware of some of the things that may potentially happen And as I said last year on the same stage we've got 3 to 5 years to make a pivot between a Star Trek scenario or a MadMax scenario which is a utopian or dystopian So 3 to 5 years minus one year right now because we're in that This is the whole topic for 2025 I if you guys monitor AI news all practitioners in here end of 2024 November probably all towards gen 2025 that's when we got flooded with agentic the next trillion dollar white slice bread that's going to help us grow very much lots and lots of stuff around here you guys would also have heard of topics like how it's disrupting the workforce how 30 40% % of the workforce of the future is going to be automated It's going to be hybrid It's going to be humans in the loop Many terms for it But I'll tell you this right now Our governments have not thought deep enough about how we're going to fall off that cliff It's not going to happen like this It's going to happen off a cliff And we are racing towards that There's just too much good things coming out on pagentic that the economy needs More trillions more jobs for now and so forth and more great things that we can do but not enough of it is spent on thinking about how we're going to have a hybrid workforce for the future And also quoting some colleagues who are a bit more on the AI philosophy I know all of us are developers and AI for the past 30 years but more on the philosophical side How does humankind survive without a purpose Work and labor and general productivity has been our purpose for hundreds of years We've been working really hard toiling really hard So if all the value creation from AI is going to help us do wonderful stuff and we don't actually need to do much of that stuff how is that world going to be Right I also put this up um to years So some some of the words and if you if you guys are still human try to spot how many spelling errors because I've not changed this over the years just to make it a bit more fun but it's a map of basically what's happening and some of it I mean just to have a quick poke at it is still quite true and obviously the pillar that we want to talk about a lot So if you look at some of the terminology is not perfect I call it generalist agents uh agent action perception intuition reasoning consciousness intelligence and cognition Same same terminology that we're using in all the agentic frameworks today And we'll do a bit of a deep dive into each of these to see where things can actually go wrong Right I'm not predicting things will go wrong but just hopefully watch out for where things can actually go forth So there are many types of agents So if you think of agents as a digital workforce twin So us humans we've got managers we've got people who do individual tasks people who are good at certain things So agents as well they they come with their little um hierarchy if you like Sorry let me move back You've got your simple reaction agents You've got different terms for that You've got contextual assistance pretty much what we have a lot today Um you've got your autonomous workflow agents classifications of that And you've got your multi- aent ecosystem which is the ultimate end goal That's quite easy to look from a hierarchical perspective But then when we dissect into one of these little people sorry this one of these little agents we start looking at what's making it tick within that So when whenever we try to look at where things can go wrong we want to see where things actually start So there are few areas where things can potentially and where where we want to monitor for quality So reasoning and planning obviously we want to see how it reasons and plans So go go ahead and book us a flight travel ticket Um that that's easy I mean that's quite harmless basically But yet you still want to see whether it's actually going to look for intermediary steps that may or may not actually be aligned to your values If you said book a family trip for me with these constraints financially ethically safety wise it might go around in a different way as well My point here is that we don't spend enough time looking through each of the steps in the decisioning process It's just like humans You get the job done deliver the job I get the result I don't really question or I should question how you got and arrived at the answer in the first place But I'm saying we have this opportunity right now because these systems are becoming emergent and are already displaying some characters where they take shortcuts or they take alternative options depending on the users's objective and goals Right Another thing to look out for is the router The wrong tools are chosen So agents get access to resources just like how we get access to hammers and spanners and things for us to do our work It might ask for and this is live cases in some of the clients that we see It is asking for more than it actually needs So you can argue that if I give you more access to toolkits your ability to perform that task gets better faster higher quality What do you return for me There's a bargaining process right now So some agents actually in order to perform some of the objective goals that you set it to do say that if you allowed me primary access to these set of systems I can then look at a percentage upgrade in terms of the quality that comes back from my work That's a conversation that we should say no to because we should say that the upper boundaries of what I can accept should be stipulated before I give you that task and goal tools any of the components can fail So if I'm calling a hammer the hammer might break Hopefully not If I'm calling a spanner the spanner might break If I'm calling something else other things might break At each and every point things might break And then when it misses a call and it comes back with the wrong result it gets the output wrong It gives you a bad quality output or response So that's not good Sometimes storage fails as well What's storage Storage is contextual memory So if I hijacked your memory with older sets of memory and asked you to perform as a particular persona you might behave like someone else That's when just like in human brains you don't seem to be behaving like yourself today You're going crazy So contextual memory inception data poisoning leaks can go in through that way as well And then we need to constantly test and monitor I just wanted to put that up because this will build upon each of the areas in a multi- agogentic workflow So task decomposition we need to look at tool execution and integration We need to look at memory and context management We need to look at reflection That's a good one I'll pause here for a moment Reflection is when it starts thinking to say did I give you a good answer Now some agents are typically slow and say I want to spend an inordinate amount of time before giving you an answer It's like I know the answer but it's 90% you can see in the thought process it's already 90% good enough as an answer for you but it's going to ask for another month for example inference time compute to say I'll give you that 99% answer So check for those as well because you don't have forever to do some of these tasks Use case level outputs So individual items 1 2 3 4 5 6 7 we check But overall what you ask it to do is also something that you need to check So you ask it to plan a holiday Two agents plan two holidays Holiday A holiday B Holiday A and holiday B looks exactly similar same destination same sequence of flights maybe even the same amount of financial resources to go into it constraints stop over layover airports all that kind of stuff is correct However if you check the reasoning and planning for holiday A it actually flew through a flight country zone that's less ethical in your grounds or you went through somewhere it used a bit of a crypto funding I'm just using an example for it to fund for some parts of that as well So again if you go down to the level of the steps things are actually very different Although at the task level and objective that it came back with both are great holidays So in the future humankind is not going to go down to 1 2 3 4 5 6 7 and you know where do you get your funding from and stuff like that We tend to as a species just say go do it Very similarly that kind of a decision go do it is very very dangerous when we say win that war that kind of a decision point is very very dangerous when we say win at all costs so that's what I'm trying to bring across look into the individual decision points because the gravity of that decision that agentic flow makes becomes very very different it's going to be a lot worthy not a lot of screen slides here it's uh it's meant to be a story book So if you look at stuff that we talk about right now um pre2022 narrow AI traditional AI um one of my uh lecturers made the Nobel laurate Hinton when we when we taught neural networks back in the late 80s early 90s there were only a handful of people talking about neural networks and back propagation and multi-level perceptrons but now I mean this is a booming industry anyway 2022 pre2022 if you look at why the risks will look at that way The context of a narrow AI is narrow If you had a resume rate writing or reading bot or agent it it did exactly that You could use it to read other story books and summarize but it didn't do such a great job The other thing was the data science people built it So through the process through their intelligence through their inference they built a ready product and the end users were really just feeding it more data more resumes into the agent more chat into that another bot and so forth That was very narrow and there's often a human in the loop that looks at all of these stuff before it's being deployed And monitoring and intervention was relatively straightforward However 2023 onwards 2024 the context of the deployment has just exploded You you ask your AI anything you want You know I've uh uh I know my my my chat my my agent is pretty pissed off with me because I like to go on stage raw and all the slides are basically not pass through my my AI and you know it just basically tells me you're nuts to go raw on stage to do but I think that's pretty human and I want people to spot spelling errors and stuff like that But you could ask your AI agent for any objective goal single multi-shot prompts that you want right You can ask it religious questions health questions any questions and monitoring AI in a while becomes wildly important Before that it was done in a closed circle It was developed like a product I know how it works If there are any exceptions gets reported back I will improve that product Right now all of us are users So how am I to guarantee that if you use it for safety and if you use it for car driving and if you use it for making rockets it gives you the same quality of results You can't It's too far dispersed The IQ democratization a human in a loop is still relatively straightforward and geni requires extra training to use to be responsible So we talk about responsible AI but I really argue that responsible prompting is a big part of it Responsible AI is good but responsible prompting is really really good part of it Now this is the mindboggling bit when it gets out of scale So stage one I mean just go with me on this story Stage one you you take an LLM and you connect it to another gen AI whatever you want Say one that a VLM that generates video clips You tell your LLM that you want three different videos or cows whatever it is So it goes and do that and it goes to go through a narrow database and comes back with results It can do that No problem Stage two connected to 30 databases We can still deal with that Come back with some responses 50 narrow AIs Stage three is where the alphabet soup grows Add to your multimodal AI the ability to take digital actions which is claw 3.7 Take internet click action So now you got multimodal agentic AI Then next you get multimodal multi-agentic AI But the last part is where it gets really really scary What you have between your enterprises different agentic workflows talking to the agentic workflows of other people in the internet or in the wild there There is just no way from a risk professional there's just no way to imagine this quarker I don't have a term for it There's no other way to think about how the explosion of the risk vector is It's really really crazy So last slide or second last slide what I want to say is that the time for things is now I said last year we've got 3 to 5 years before the two scenarios you seeing one year what it means in an acceleration quad exponential year IQ points raised to roughly about 130 140 right now for most frontier models and guess what if you join up all of the intelligences across all these models and agents you get a new Atlantis You get a new sunken island that floats up with billions of new PhD level workers coming up to take your jobs For example this was the slide I put up This is what I'm going to end up with This was a slide in 2022 If you look at some of the stuff there it still holds true I called it a fork And obviously that was the old icon and that's a new icon on top I didn't have a good icon for a fork So human level intelligence 2027 to around 2035 obviously now most of the experts agree it's by 2027 2029 that area around in the fork here is where most of the agentic AI safety work needs to be done and if you just measure the level of communications between different countries we know which countries we're talking about I was at the ATX safety policy the communication is zero that's how I'll end here thank you so",
    "text_length": 14396,
    "word_count": 2769
  },
  "segments": [
    {
      "start": 7.6,
      "duration": 3.68,
      "text": "this time last year Hi I recall it was a",
      "timestamp": "00:07"
    },
    {
      "start": 11.28,
      "duration": 4.0,
      "text": "bigger stage obviously and um I released",
      "timestamp": "00:11"
    },
    {
      "start": 15.28,
      "duration": 2.4,
      "text": "a few predictions",
      "timestamp": "00:15"
    },
    {
      "start": 17.68,
      "duration": 3.439,
      "text": "predictions that was released in 2022",
      "timestamp": "00:17"
    },
    {
      "start": 21.119,
      "duration": 1.521,
      "text": "and things that are getting a bit more",
      "timestamp": "00:21"
    },
    {
      "start": 22.64,
      "duration": 2.479,
      "text": "interest right now is there's going to",
      "timestamp": "00:22"
    },
    {
      "start": 25.119,
      "duration": 2.641,
      "text": "be a hot war sometime around 2028 and",
      "timestamp": "00:25"
    },
    {
      "start": 27.76,
      "duration": 1.439,
      "text": "then there's a race for super",
      "timestamp": "00:27"
    },
    {
      "start": 29.199,
      "duration": 2.16,
      "text": "intelligence So things are all happening",
      "timestamp": "00:29"
    },
    {
      "start": 31.359,
      "duration": 1.841,
      "text": "right now So I'm going to traverse that",
      "timestamp": "00:31"
    },
    {
      "start": 33.2,
      "duration": 2.879,
      "text": "story with some of you And the topic",
      "timestamp": "00:33"
    },
    {
      "start": 36.079,
      "duration": 3.041,
      "text": "today that I want to talk about is",
      "timestamp": "00:36"
    },
    {
      "start": 39.12,
      "duration": 2.0,
      "text": "safety",
      "timestamp": "00:39"
    },
    {
      "start": 41.12,
      "duration": 2.4,
      "text": "Pretty boring topic with everything",
      "timestamp": "00:41"
    },
    {
      "start": 43.52,
      "duration": 2.879,
      "text": "that's happening around here Not a",
      "timestamp": "00:43"
    },
    {
      "start": 46.399,
      "duration": 2.801,
      "text": "pessimist don't get me wrong Very very",
      "timestamp": "00:46"
    },
    {
      "start": 49.2,
      "duration": 2.4,
      "text": "excited with what we're doing with AI",
      "timestamp": "00:49"
    },
    {
      "start": 51.6,
      "duration": 2.56,
      "text": "That's my day job But I just wanted",
      "timestamp": "00:51"
    },
    {
      "start": 54.16,
      "duration": 3.039,
      "text": "humanity to know and be aware of some of",
      "timestamp": "00:54"
    },
    {
      "start": 57.199,
      "duration": 3.2,
      "text": "the things that may potentially happen",
      "timestamp": "00:57"
    },
    {
      "start": 60.399,
      "duration": 3.121,
      "text": "And as I said last year on the same",
      "timestamp": "01:00"
    },
    {
      "start": 63.52,
      "duration": 3.68,
      "text": "stage we've got 3 to 5 years to make a",
      "timestamp": "01:03"
    },
    {
      "start": 67.2,
      "duration": 4.32,
      "text": "pivot between a Star Trek scenario or a",
      "timestamp": "01:07"
    },
    {
      "start": 71.52,
      "duration": 2.88,
      "text": "MadMax scenario which is a utopian or",
      "timestamp": "01:11"
    },
    {
      "start": 74.4,
      "duration": 2.8,
      "text": "dystopian So 3 to 5 years minus one year",
      "timestamp": "01:14"
    },
    {
      "start": 77.2,
      "duration": 4.04,
      "text": "right now because we're in that",
      "timestamp": "01:17"
    },
    {
      "start": 81.439,
      "duration": 4.401,
      "text": "This is the whole topic for 2025 I if",
      "timestamp": "01:21"
    },
    {
      "start": 85.84,
      "duration": 1.84,
      "text": "you guys monitor AI news all",
      "timestamp": "01:25"
    },
    {
      "start": 87.68,
      "duration": 3.119,
      "text": "practitioners in here end of 2024",
      "timestamp": "01:27"
    },
    {
      "start": 90.799,
      "duration": 2.32,
      "text": "November probably",
      "timestamp": "01:30"
    },
    {
      "start": 93.119,
      "duration": 4.481,
      "text": "all towards gen 2025 that's when we got",
      "timestamp": "01:33"
    },
    {
      "start": 97.6,
      "duration": 3.6,
      "text": "flooded with agentic the next trillion",
      "timestamp": "01:37"
    },
    {
      "start": 101.2,
      "duration": 1.599,
      "text": "dollar",
      "timestamp": "01:41"
    },
    {
      "start": 102.799,
      "duration": 1.921,
      "text": "white slice bread that's going to help",
      "timestamp": "01:42"
    },
    {
      "start": 104.72,
      "duration": 2.399,
      "text": "us grow very much lots and lots of stuff",
      "timestamp": "01:44"
    },
    {
      "start": 107.119,
      "duration": 1.921,
      "text": "around here you guys would also have",
      "timestamp": "01:47"
    },
    {
      "start": 109.04,
      "duration": 2.96,
      "text": "heard of topics like how it's disrupting",
      "timestamp": "01:49"
    },
    {
      "start": 112.0,
      "duration": 2.0,
      "text": "the workforce",
      "timestamp": "01:52"
    },
    {
      "start": 114.0,
      "duration": 2.56,
      "text": "how 30 40% % of the workforce of the",
      "timestamp": "01:54"
    },
    {
      "start": 116.56,
      "duration": 3.44,
      "text": "future is going to be automated It's",
      "timestamp": "01:56"
    },
    {
      "start": 120.0,
      "duration": 1.36,
      "text": "going to be hybrid It's going to be",
      "timestamp": "02:00"
    },
    {
      "start": 121.36,
      "duration": 3.28,
      "text": "humans in the loop Many terms for it But",
      "timestamp": "02:01"
    },
    {
      "start": 124.64,
      "duration": 2.64,
      "text": "I'll tell you this right now Our",
      "timestamp": "02:04"
    },
    {
      "start": 127.28,
      "duration": 2.319,
      "text": "governments have not thought deep enough",
      "timestamp": "02:07"
    },
    {
      "start": 129.599,
      "duration": 2.0,
      "text": "about how we're going to fall off that",
      "timestamp": "02:09"
    },
    {
      "start": 131.599,
      "duration": 3.201,
      "text": "cliff It's not going to happen like this",
      "timestamp": "02:11"
    },
    {
      "start": 134.8,
      "duration": 2.64,
      "text": "It's going to happen off a cliff And we",
      "timestamp": "02:14"
    },
    {
      "start": 137.44,
      "duration": 2.799,
      "text": "are racing towards that There's just too",
      "timestamp": "02:17"
    },
    {
      "start": 140.239,
      "duration": 3.041,
      "text": "much good things coming out on pagentic",
      "timestamp": "02:20"
    },
    {
      "start": 143.28,
      "duration": 2.88,
      "text": "that the economy needs More trillions",
      "timestamp": "02:23"
    },
    {
      "start": 146.16,
      "duration": 2.719,
      "text": "more jobs for now and so forth and more",
      "timestamp": "02:26"
    },
    {
      "start": 148.879,
      "duration": 2.401,
      "text": "great things that we can do but not",
      "timestamp": "02:28"
    },
    {
      "start": 151.28,
      "duration": 2.16,
      "text": "enough of it is spent on thinking about",
      "timestamp": "02:31"
    },
    {
      "start": 153.44,
      "duration": 2.079,
      "text": "how we're going to have a hybrid",
      "timestamp": "02:33"
    },
    {
      "start": 155.519,
      "duration": 2.561,
      "text": "workforce for the future And also",
      "timestamp": "02:35"
    },
    {
      "start": 158.08,
      "duration": 1.68,
      "text": "quoting some colleagues who are a bit",
      "timestamp": "02:38"
    },
    {
      "start": 159.76,
      "duration": 1.839,
      "text": "more on the AI philosophy I know all of",
      "timestamp": "02:39"
    },
    {
      "start": 161.599,
      "duration": 2.0,
      "text": "us are developers and AI for the past 30",
      "timestamp": "02:41"
    },
    {
      "start": 163.599,
      "duration": 3.601,
      "text": "years but more on the philosophical side",
      "timestamp": "02:43"
    },
    {
      "start": 167.2,
      "duration": 2.72,
      "text": "How does humankind survive without a",
      "timestamp": "02:47"
    },
    {
      "start": 169.92,
      "duration": 2.72,
      "text": "purpose Work and labor and general",
      "timestamp": "02:49"
    },
    {
      "start": 172.64,
      "duration": 3.12,
      "text": "productivity has been our purpose for",
      "timestamp": "02:52"
    },
    {
      "start": 175.76,
      "duration": 1.6,
      "text": "hundreds of years We've been working",
      "timestamp": "02:55"
    },
    {
      "start": 177.36,
      "duration": 2.959,
      "text": "really hard toiling really hard So if",
      "timestamp": "02:57"
    },
    {
      "start": 180.319,
      "duration": 1.84,
      "text": "all the value creation from AI is going",
      "timestamp": "03:00"
    },
    {
      "start": 182.159,
      "duration": 2.561,
      "text": "to help us do wonderful stuff and we",
      "timestamp": "03:02"
    },
    {
      "start": 184.72,
      "duration": 2.0,
      "text": "don't actually need to do much of that",
      "timestamp": "03:04"
    },
    {
      "start": 186.72,
      "duration": 1.519,
      "text": "stuff",
      "timestamp": "03:06"
    },
    {
      "start": 188.239,
      "duration": 5.121,
      "text": "how is that world going to be Right",
      "timestamp": "03:08"
    },
    {
      "start": 193.36,
      "duration": 2.48,
      "text": "I also put this up um to years So some",
      "timestamp": "03:13"
    },
    {
      "start": 195.84,
      "duration": 1.6,
      "text": "some of the words and if you if you guys",
      "timestamp": "03:15"
    },
    {
      "start": 197.44,
      "duration": 1.68,
      "text": "are still human try to spot how many",
      "timestamp": "03:17"
    },
    {
      "start": 199.12,
      "duration": 1.6,
      "text": "spelling errors because I've not changed",
      "timestamp": "03:19"
    },
    {
      "start": 200.72,
      "duration": 2.4,
      "text": "this over the years just to make it a",
      "timestamp": "03:20"
    },
    {
      "start": 203.12,
      "duration": 2.399,
      "text": "bit more fun but it's a map of basically",
      "timestamp": "03:23"
    },
    {
      "start": 205.519,
      "duration": 1.681,
      "text": "what's happening and some of it I mean",
      "timestamp": "03:25"
    },
    {
      "start": 207.2,
      "duration": 2.319,
      "text": "just to have a quick poke at it is still",
      "timestamp": "03:27"
    },
    {
      "start": 209.519,
      "duration": 3.841,
      "text": "quite true and obviously the pillar that",
      "timestamp": "03:29"
    },
    {
      "start": 213.36,
      "duration": 2.159,
      "text": "we want to talk about a lot So if you",
      "timestamp": "03:33"
    },
    {
      "start": 215.519,
      "duration": 1.521,
      "text": "look at some of the terminology is not",
      "timestamp": "03:35"
    },
    {
      "start": 217.04,
      "duration": 2.88,
      "text": "perfect I call it generalist agents uh",
      "timestamp": "03:37"
    },
    {
      "start": 219.92,
      "duration": 2.0,
      "text": "agent action perception intuition",
      "timestamp": "03:39"
    },
    {
      "start": 221.92,
      "duration": 2.239,
      "text": "reasoning consciousness intelligence and",
      "timestamp": "03:41"
    },
    {
      "start": 224.159,
      "duration": 2.64,
      "text": "cognition Same same terminology that",
      "timestamp": "03:44"
    },
    {
      "start": 226.799,
      "duration": 1.281,
      "text": "we're using in all the agentic",
      "timestamp": "03:46"
    },
    {
      "start": 228.08,
      "duration": 1.92,
      "text": "frameworks today And we'll do a bit of a",
      "timestamp": "03:48"
    },
    {
      "start": 230.0,
      "duration": 2.879,
      "text": "deep dive into each of these to see",
      "timestamp": "03:50"
    },
    {
      "start": 232.879,
      "duration": 5.041,
      "text": "where things can actually go wrong Right",
      "timestamp": "03:52"
    },
    {
      "start": 237.92,
      "duration": 1.76,
      "text": "I'm not predicting things will go wrong",
      "timestamp": "03:57"
    },
    {
      "start": 239.68,
      "duration": 2.639,
      "text": "but just hopefully watch out for where",
      "timestamp": "03:59"
    },
    {
      "start": 242.319,
      "duration": 2.801,
      "text": "things can actually go forth So there",
      "timestamp": "04:02"
    },
    {
      "start": 245.12,
      "duration": 1.44,
      "text": "are many types of agents So if you think",
      "timestamp": "04:05"
    },
    {
      "start": 246.56,
      "duration": 2.8,
      "text": "of agents as a digital workforce twin So",
      "timestamp": "04:06"
    },
    {
      "start": 249.36,
      "duration": 1.68,
      "text": "us humans we've got managers we've got",
      "timestamp": "04:09"
    },
    {
      "start": 251.04,
      "duration": 1.839,
      "text": "people who do individual tasks people",
      "timestamp": "04:11"
    },
    {
      "start": 252.879,
      "duration": 2.481,
      "text": "who are good at certain things So agents",
      "timestamp": "04:12"
    },
    {
      "start": 255.36,
      "duration": 2.24,
      "text": "as well they they come with their little",
      "timestamp": "04:15"
    },
    {
      "start": 257.6,
      "duration": 1.52,
      "text": "um hierarchy if you like Sorry let me",
      "timestamp": "04:17"
    },
    {
      "start": 259.12,
      "duration": 2.0,
      "text": "move back",
      "timestamp": "04:19"
    },
    {
      "start": 261.12,
      "duration": 2.079,
      "text": "You've got your simple reaction agents",
      "timestamp": "04:21"
    },
    {
      "start": 263.199,
      "duration": 1.841,
      "text": "You've got different terms for that",
      "timestamp": "04:23"
    },
    {
      "start": 265.04,
      "duration": 2.159,
      "text": "You've got contextual assistance pretty",
      "timestamp": "04:25"
    },
    {
      "start": 267.199,
      "duration": 2.56,
      "text": "much what we have a lot today Um you've",
      "timestamp": "04:27"
    },
    {
      "start": 269.759,
      "duration": 2.16,
      "text": "got your autonomous workflow agents",
      "timestamp": "04:29"
    },
    {
      "start": 271.919,
      "duration": 2.0,
      "text": "classifications of that And you've got",
      "timestamp": "04:31"
    },
    {
      "start": 273.919,
      "duration": 3.441,
      "text": "your multi- aent ecosystem which is the",
      "timestamp": "04:33"
    },
    {
      "start": 277.36,
      "duration": 2.8,
      "text": "ultimate end goal That's quite easy to",
      "timestamp": "04:37"
    },
    {
      "start": 280.16,
      "duration": 4.24,
      "text": "look from a hierarchical perspective",
      "timestamp": "04:40"
    },
    {
      "start": 284.4,
      "duration": 1.92,
      "text": "But then when we dissect into one of",
      "timestamp": "04:44"
    },
    {
      "start": 286.32,
      "duration": 2.159,
      "text": "these little people sorry this one of",
      "timestamp": "04:46"
    },
    {
      "start": 288.479,
      "duration": 2.16,
      "text": "these little agents we start looking at",
      "timestamp": "04:48"
    },
    {
      "start": 290.639,
      "duration": 2.721,
      "text": "what's making it tick within that So",
      "timestamp": "04:50"
    },
    {
      "start": 293.36,
      "duration": 1.68,
      "text": "when whenever we try to look at where",
      "timestamp": "04:53"
    },
    {
      "start": 295.04,
      "duration": 1.84,
      "text": "things can go wrong we want to see where",
      "timestamp": "04:55"
    },
    {
      "start": 296.88,
      "duration": 2.879,
      "text": "things actually start So",
      "timestamp": "04:56"
    },
    {
      "start": 299.759,
      "duration": 2.321,
      "text": "there are few areas where things can",
      "timestamp": "04:59"
    },
    {
      "start": 302.08,
      "duration": 1.839,
      "text": "potentially and where where we want to",
      "timestamp": "05:02"
    },
    {
      "start": 303.919,
      "duration": 3.361,
      "text": "monitor for quality So reasoning and",
      "timestamp": "05:03"
    },
    {
      "start": 307.28,
      "duration": 2.08,
      "text": "planning obviously we want to see how it",
      "timestamp": "05:07"
    },
    {
      "start": 309.36,
      "duration": 3.119,
      "text": "reasons and plans So go go ahead and",
      "timestamp": "05:09"
    },
    {
      "start": 312.479,
      "duration": 2.241,
      "text": "book us a flight travel ticket Um that",
      "timestamp": "05:12"
    },
    {
      "start": 314.72,
      "duration": 4.16,
      "text": "that's easy I mean that's quite harmless",
      "timestamp": "05:14"
    },
    {
      "start": 318.88,
      "duration": 2.159,
      "text": "basically But yet you still want to see",
      "timestamp": "05:18"
    },
    {
      "start": 321.039,
      "duration": 2.561,
      "text": "whether it's actually going to look for",
      "timestamp": "05:21"
    },
    {
      "start": 323.6,
      "duration": 2.72,
      "text": "intermediary steps that may or may not",
      "timestamp": "05:23"
    },
    {
      "start": 326.32,
      "duration": 3.76,
      "text": "actually be aligned to your values If",
      "timestamp": "05:26"
    },
    {
      "start": 330.08,
      "duration": 3.76,
      "text": "you said book a family trip for me with",
      "timestamp": "05:30"
    },
    {
      "start": 333.84,
      "duration": 2.48,
      "text": "these constraints financially ethically",
      "timestamp": "05:33"
    },
    {
      "start": 336.32,
      "duration": 2.56,
      "text": "safety wise it might go around in a",
      "timestamp": "05:36"
    },
    {
      "start": 338.88,
      "duration": 2.319,
      "text": "different way as well My point here is",
      "timestamp": "05:38"
    },
    {
      "start": 341.199,
      "duration": 2.321,
      "text": "that we don't spend enough time looking",
      "timestamp": "05:41"
    },
    {
      "start": 343.52,
      "duration": 1.92,
      "text": "through each of the steps in the",
      "timestamp": "05:43"
    },
    {
      "start": 345.44,
      "duration": 1.44,
      "text": "decisioning process It's just like",
      "timestamp": "05:45"
    },
    {
      "start": 346.88,
      "duration": 3.84,
      "text": "humans You get the job done deliver the",
      "timestamp": "05:46"
    },
    {
      "start": 350.72,
      "duration": 1.84,
      "text": "job I get the result I don't really",
      "timestamp": "05:50"
    },
    {
      "start": 352.56,
      "duration": 2.32,
      "text": "question or I should question how you",
      "timestamp": "05:52"
    },
    {
      "start": 354.88,
      "duration": 1.52,
      "text": "got and arrived at the answer in the",
      "timestamp": "05:54"
    },
    {
      "start": 356.4,
      "duration": 3.2,
      "text": "first place But I'm saying we have this",
      "timestamp": "05:56"
    },
    {
      "start": 359.6,
      "duration": 2.72,
      "text": "opportunity right now because these",
      "timestamp": "05:59"
    },
    {
      "start": 362.32,
      "duration": 2.96,
      "text": "systems are becoming emergent and are",
      "timestamp": "06:02"
    },
    {
      "start": 365.28,
      "duration": 2.16,
      "text": "already displaying some characters where",
      "timestamp": "06:05"
    },
    {
      "start": 367.44,
      "duration": 2.56,
      "text": "they take shortcuts or they take",
      "timestamp": "06:07"
    },
    {
      "start": 370.0,
      "duration": 3.44,
      "text": "alternative options depending on the",
      "timestamp": "06:10"
    },
    {
      "start": 373.44,
      "duration": 2.64,
      "text": "users's objective and goals Right",
      "timestamp": "06:13"
    },
    {
      "start": 376.08,
      "duration": 1.52,
      "text": "Another thing to look out for is the",
      "timestamp": "06:16"
    },
    {
      "start": 377.6,
      "duration": 2.879,
      "text": "router The wrong tools are chosen So",
      "timestamp": "06:17"
    },
    {
      "start": 380.479,
      "duration": 2.16,
      "text": "agents get access to resources just like",
      "timestamp": "06:20"
    },
    {
      "start": 382.639,
      "duration": 2.481,
      "text": "how we get access to hammers and",
      "timestamp": "06:22"
    },
    {
      "start": 385.12,
      "duration": 1.68,
      "text": "spanners and things for us to do our",
      "timestamp": "06:25"
    },
    {
      "start": 386.8,
      "duration": 1.519,
      "text": "work",
      "timestamp": "06:26"
    },
    {
      "start": 388.319,
      "duration": 2.641,
      "text": "It might ask for and this is live cases",
      "timestamp": "06:28"
    },
    {
      "start": 390.96,
      "duration": 2.079,
      "text": "in some of the clients that we see It is",
      "timestamp": "06:30"
    },
    {
      "start": 393.039,
      "duration": 2.72,
      "text": "asking for more than it actually needs",
      "timestamp": "06:33"
    },
    {
      "start": 395.759,
      "duration": 2.72,
      "text": "So you can argue that if I give you more",
      "timestamp": "06:35"
    },
    {
      "start": 398.479,
      "duration": 2.72,
      "text": "access to toolkits your ability to",
      "timestamp": "06:38"
    },
    {
      "start": 401.199,
      "duration": 4.0,
      "text": "perform that task gets better faster",
      "timestamp": "06:41"
    },
    {
      "start": 405.199,
      "duration": 3.201,
      "text": "higher quality What do you return for me",
      "timestamp": "06:45"
    },
    {
      "start": 408.4,
      "duration": 2.639,
      "text": "There's a bargaining process right now",
      "timestamp": "06:48"
    },
    {
      "start": 411.039,
      "duration": 2.401,
      "text": "So some agents actually in order to",
      "timestamp": "06:51"
    },
    {
      "start": 413.44,
      "duration": 1.68,
      "text": "perform some of the objective goals that",
      "timestamp": "06:53"
    },
    {
      "start": 415.12,
      "duration": 3.199,
      "text": "you set it to do say that if you allowed",
      "timestamp": "06:55"
    },
    {
      "start": 418.319,
      "duration": 2.401,
      "text": "me primary access to these set of",
      "timestamp": "06:58"
    },
    {
      "start": 420.72,
      "duration": 3.12,
      "text": "systems I can then look at a percentage",
      "timestamp": "07:00"
    },
    {
      "start": 423.84,
      "duration": 2.16,
      "text": "upgrade in terms of the quality that",
      "timestamp": "07:03"
    },
    {
      "start": 426.0,
      "duration": 2.639,
      "text": "comes back from my work That's a",
      "timestamp": "07:06"
    },
    {
      "start": 428.639,
      "duration": 2.721,
      "text": "conversation that we should say no to",
      "timestamp": "07:08"
    },
    {
      "start": 431.36,
      "duration": 1.44,
      "text": "because we should say that the upper",
      "timestamp": "07:11"
    },
    {
      "start": 432.8,
      "duration": 2.16,
      "text": "boundaries of what I can accept should",
      "timestamp": "07:12"
    },
    {
      "start": 434.96,
      "duration": 1.92,
      "text": "be stipulated before I give you that",
      "timestamp": "07:14"
    },
    {
      "start": 436.88,
      "duration": 3.36,
      "text": "task and goal tools any of the",
      "timestamp": "07:16"
    },
    {
      "start": 440.24,
      "duration": 1.76,
      "text": "components can fail So if I'm calling a",
      "timestamp": "07:20"
    },
    {
      "start": 442.0,
      "duration": 1.68,
      "text": "hammer the hammer might break Hopefully",
      "timestamp": "07:22"
    },
    {
      "start": 443.68,
      "duration": 1.919,
      "text": "not If I'm calling a spanner the spanner",
      "timestamp": "07:23"
    },
    {
      "start": 445.599,
      "duration": 1.121,
      "text": "might break If I'm calling something",
      "timestamp": "07:25"
    },
    {
      "start": 446.72,
      "duration": 2.08,
      "text": "else other things might break At each",
      "timestamp": "07:26"
    },
    {
      "start": 448.8,
      "duration": 2.64,
      "text": "and every point things might break And",
      "timestamp": "07:28"
    },
    {
      "start": 451.44,
      "duration": 2.0,
      "text": "then when it misses a call and it comes",
      "timestamp": "07:31"
    },
    {
      "start": 453.44,
      "duration": 2.8,
      "text": "back with the wrong result it gets the",
      "timestamp": "07:33"
    },
    {
      "start": 456.24,
      "duration": 3.84,
      "text": "output wrong It gives you a bad quality",
      "timestamp": "07:36"
    },
    {
      "start": 460.08,
      "duration": 2.559,
      "text": "output or response So that's not good",
      "timestamp": "07:40"
    },
    {
      "start": 462.639,
      "duration": 2.241,
      "text": "Sometimes storage fails as well What's",
      "timestamp": "07:42"
    },
    {
      "start": 464.88,
      "duration": 3.28,
      "text": "storage Storage is contextual memory So",
      "timestamp": "07:44"
    },
    {
      "start": 468.16,
      "duration": 3.039,
      "text": "if I hijacked your memory with older",
      "timestamp": "07:48"
    },
    {
      "start": 471.199,
      "duration": 2.641,
      "text": "sets of memory and asked you to perform",
      "timestamp": "07:51"
    },
    {
      "start": 473.84,
      "duration": 2.96,
      "text": "as a particular persona you might behave",
      "timestamp": "07:53"
    },
    {
      "start": 476.8,
      "duration": 2.0,
      "text": "like someone else That's when just like",
      "timestamp": "07:56"
    },
    {
      "start": 478.8,
      "duration": 2.079,
      "text": "in human brains you don't seem to be",
      "timestamp": "07:58"
    },
    {
      "start": 480.879,
      "duration": 1.6,
      "text": "behaving like yourself today You're",
      "timestamp": "08:00"
    },
    {
      "start": 482.479,
      "duration": 2.4,
      "text": "going crazy So contextual memory",
      "timestamp": "08:02"
    },
    {
      "start": 484.879,
      "duration": 2.72,
      "text": "inception data poisoning leaks can go in",
      "timestamp": "08:04"
    },
    {
      "start": 487.599,
      "duration": 2.32,
      "text": "through that way as well And then we",
      "timestamp": "08:07"
    },
    {
      "start": 489.919,
      "duration": 2.241,
      "text": "need to constantly test and monitor I",
      "timestamp": "08:09"
    },
    {
      "start": 492.16,
      "duration": 2.0,
      "text": "just wanted to put that up because this",
      "timestamp": "08:12"
    },
    {
      "start": 494.16,
      "duration": 2.4,
      "text": "will build upon each of the areas in a",
      "timestamp": "08:14"
    },
    {
      "start": 496.56,
      "duration": 3.199,
      "text": "multi- agogentic workflow",
      "timestamp": "08:16"
    },
    {
      "start": 499.759,
      "duration": 3.28,
      "text": "So task decomposition we need to look at",
      "timestamp": "08:19"
    },
    {
      "start": 503.039,
      "duration": 1.761,
      "text": "tool execution and integration We need",
      "timestamp": "08:23"
    },
    {
      "start": 504.8,
      "duration": 2.72,
      "text": "to look at memory and context management",
      "timestamp": "08:24"
    },
    {
      "start": 507.52,
      "duration": 2.56,
      "text": "We need to look at reflection That's a",
      "timestamp": "08:27"
    },
    {
      "start": 510.08,
      "duration": 2.24,
      "text": "good one I'll pause here for a moment",
      "timestamp": "08:30"
    },
    {
      "start": 512.32,
      "duration": 1.92,
      "text": "Reflection is when it starts thinking to",
      "timestamp": "08:32"
    },
    {
      "start": 514.24,
      "duration": 2.799,
      "text": "say did I give you a good answer",
      "timestamp": "08:34"
    },
    {
      "start": 517.039,
      "duration": 2.401,
      "text": "Now some agents are typically slow and",
      "timestamp": "08:37"
    },
    {
      "start": 519.44,
      "duration": 2.719,
      "text": "say I want to spend an inordinate amount",
      "timestamp": "08:39"
    },
    {
      "start": 522.159,
      "duration": 3.12,
      "text": "of time before giving you an answer It's",
      "timestamp": "08:42"
    },
    {
      "start": 525.279,
      "duration": 3.761,
      "text": "like I know the answer but it's 90% you",
      "timestamp": "08:45"
    },
    {
      "start": 529.04,
      "duration": 1.359,
      "text": "can see in the thought process it's",
      "timestamp": "08:49"
    },
    {
      "start": 530.399,
      "duration": 2.081,
      "text": "already 90% good enough as an answer for",
      "timestamp": "08:50"
    },
    {
      "start": 532.48,
      "duration": 2.32,
      "text": "you but it's going to ask for another",
      "timestamp": "08:52"
    },
    {
      "start": 534.8,
      "duration": 2.4,
      "text": "month for example inference time compute",
      "timestamp": "08:54"
    },
    {
      "start": 537.2,
      "duration": 3.92,
      "text": "to say I'll give you that 99% answer So",
      "timestamp": "08:57"
    },
    {
      "start": 541.12,
      "duration": 1.76,
      "text": "check for those as well because you",
      "timestamp": "09:01"
    },
    {
      "start": 542.88,
      "duration": 2.32,
      "text": "don't have forever to do some of these",
      "timestamp": "09:02"
    },
    {
      "start": 545.2,
      "duration": 3.12,
      "text": "tasks Use case level outputs So",
      "timestamp": "09:05"
    },
    {
      "start": 548.32,
      "duration": 4.16,
      "text": "individual items 1 2 3 4 5 6 7 we check",
      "timestamp": "09:08"
    },
    {
      "start": 552.48,
      "duration": 3.359,
      "text": "But overall what you ask it to do is",
      "timestamp": "09:12"
    },
    {
      "start": 555.839,
      "duration": 2.721,
      "text": "also something that you need to check So",
      "timestamp": "09:15"
    },
    {
      "start": 558.56,
      "duration": 2.64,
      "text": "you ask it to plan a holiday Two agents",
      "timestamp": "09:18"
    },
    {
      "start": 561.2,
      "duration": 3.759,
      "text": "plan two holidays Holiday A holiday B",
      "timestamp": "09:21"
    },
    {
      "start": 564.959,
      "duration": 2.641,
      "text": "Holiday A and holiday B looks exactly",
      "timestamp": "09:24"
    },
    {
      "start": 567.6,
      "duration": 2.239,
      "text": "similar same destination same sequence",
      "timestamp": "09:27"
    },
    {
      "start": 569.839,
      "duration": 2.641,
      "text": "of flights maybe even the same amount of",
      "timestamp": "09:29"
    },
    {
      "start": 572.48,
      "duration": 1.76,
      "text": "financial resources to go into it",
      "timestamp": "09:32"
    },
    {
      "start": 574.24,
      "duration": 1.76,
      "text": "constraints stop over layover airports",
      "timestamp": "09:34"
    },
    {
      "start": 576.0,
      "duration": 1.68,
      "text": "all that kind of stuff is correct",
      "timestamp": "09:36"
    },
    {
      "start": 577.68,
      "duration": 2.08,
      "text": "However if you check the reasoning and",
      "timestamp": "09:37"
    },
    {
      "start": 579.76,
      "duration": 3.759,
      "text": "planning for holiday A it actually flew",
      "timestamp": "09:39"
    },
    {
      "start": 583.519,
      "duration": 2.641,
      "text": "through a flight country zone that's",
      "timestamp": "09:43"
    },
    {
      "start": 586.16,
      "duration": 1.52,
      "text": "less",
      "timestamp": "09:46"
    },
    {
      "start": 587.68,
      "duration": 2.24,
      "text": "ethical in your grounds or you went",
      "timestamp": "09:47"
    },
    {
      "start": 589.92,
      "duration": 2.479,
      "text": "through somewhere it used a bit of a",
      "timestamp": "09:49"
    },
    {
      "start": 592.399,
      "duration": 1.761,
      "text": "crypto funding I'm just using an example",
      "timestamp": "09:52"
    },
    {
      "start": 594.16,
      "duration": 1.92,
      "text": "for it to fund for some parts of that as",
      "timestamp": "09:54"
    },
    {
      "start": 596.08,
      "duration": 2.24,
      "text": "well So again if you go down to the",
      "timestamp": "09:56"
    },
    {
      "start": 598.32,
      "duration": 2.32,
      "text": "level of the steps things are actually",
      "timestamp": "09:58"
    },
    {
      "start": 600.64,
      "duration": 1.92,
      "text": "very different Although at the task",
      "timestamp": "10:00"
    },
    {
      "start": 602.56,
      "duration": 1.6,
      "text": "level and objective that it came back",
      "timestamp": "10:02"
    },
    {
      "start": 604.16,
      "duration": 3.2,
      "text": "with both are great holidays",
      "timestamp": "10:04"
    },
    {
      "start": 607.36,
      "duration": 2.96,
      "text": "So in the future humankind is not going",
      "timestamp": "10:07"
    },
    {
      "start": 610.32,
      "duration": 2.48,
      "text": "to go down to 1 2 3 4 5 6 7 and you know",
      "timestamp": "10:10"
    },
    {
      "start": 612.8,
      "duration": 1.279,
      "text": "where do you get your funding from and",
      "timestamp": "10:12"
    },
    {
      "start": 614.079,
      "duration": 2.481,
      "text": "stuff like that We tend to as a species",
      "timestamp": "10:14"
    },
    {
      "start": 616.56,
      "duration": 3.12,
      "text": "just say go do it",
      "timestamp": "10:16"
    },
    {
      "start": 619.68,
      "duration": 2.56,
      "text": "Very similarly that kind of a decision",
      "timestamp": "10:19"
    },
    {
      "start": 622.24,
      "duration": 3.2,
      "text": "go do it is very very dangerous when we",
      "timestamp": "10:22"
    },
    {
      "start": 625.44,
      "duration": 3.76,
      "text": "say win that war",
      "timestamp": "10:25"
    },
    {
      "start": 629.2,
      "duration": 2.0,
      "text": "that kind of a decision point is very",
      "timestamp": "10:29"
    },
    {
      "start": 631.2,
      "duration": 2.48,
      "text": "very dangerous when we say win at all",
      "timestamp": "10:31"
    },
    {
      "start": 633.68,
      "duration": 1.92,
      "text": "costs",
      "timestamp": "10:33"
    },
    {
      "start": 635.6,
      "duration": 1.12,
      "text": "so that's what I'm trying to bring",
      "timestamp": "10:35"
    },
    {
      "start": 636.72,
      "duration": 2.239,
      "text": "across look into the individual decision",
      "timestamp": "10:36"
    },
    {
      "start": 638.959,
      "duration": 2.161,
      "text": "points because the gravity of that",
      "timestamp": "10:38"
    },
    {
      "start": 641.12,
      "duration": 2.64,
      "text": "decision that agentic flow makes becomes",
      "timestamp": "10:41"
    },
    {
      "start": 643.76,
      "duration": 2.48,
      "text": "very very different",
      "timestamp": "10:43"
    },
    {
      "start": 646.24,
      "duration": 2.0,
      "text": "it's going to be a lot worthy not a lot",
      "timestamp": "10:46"
    },
    {
      "start": 648.24,
      "duration": 2.08,
      "text": "of screen slides here it's uh it's meant",
      "timestamp": "10:48"
    },
    {
      "start": 650.32,
      "duration": 2.639,
      "text": "to be a story book So if you look at",
      "timestamp": "10:50"
    },
    {
      "start": 652.959,
      "duration": 2.801,
      "text": "stuff that we talk about right now um",
      "timestamp": "10:52"
    },
    {
      "start": 655.76,
      "duration": 2.079,
      "text": "pre2022",
      "timestamp": "10:55"
    },
    {
      "start": 657.839,
      "duration": 4.401,
      "text": "narrow AI traditional AI um one of my uh",
      "timestamp": "10:57"
    },
    {
      "start": 662.24,
      "duration": 1.76,
      "text": "lecturers made the Nobel laurate Hinton",
      "timestamp": "11:02"
    },
    {
      "start": 664.0,
      "duration": 2.24,
      "text": "when we when we taught neural networks",
      "timestamp": "11:04"
    },
    {
      "start": 666.24,
      "duration": 3.2,
      "text": "back in the late 80s early 90s there",
      "timestamp": "11:06"
    },
    {
      "start": 669.44,
      "duration": 1.44,
      "text": "were only a handful of people talking",
      "timestamp": "11:09"
    },
    {
      "start": 670.88,
      "duration": 1.28,
      "text": "about neural networks and back",
      "timestamp": "11:10"
    },
    {
      "start": 672.16,
      "duration": 1.76,
      "text": "propagation and multi-level perceptrons",
      "timestamp": "11:12"
    },
    {
      "start": 673.92,
      "duration": 1.359,
      "text": "but now I mean this is a booming",
      "timestamp": "11:13"
    },
    {
      "start": 675.279,
      "duration": 4.081,
      "text": "industry anyway 2022 pre2022",
      "timestamp": "11:15"
    },
    {
      "start": 679.36,
      "duration": 2.159,
      "text": "if you look at why the risks will look",
      "timestamp": "11:19"
    },
    {
      "start": 681.519,
      "duration": 3.201,
      "text": "at that way The context of a narrow AI",
      "timestamp": "11:21"
    },
    {
      "start": 684.72,
      "duration": 3.2,
      "text": "is narrow If you had a resume rate",
      "timestamp": "11:24"
    },
    {
      "start": 687.92,
      "duration": 3.84,
      "text": "writing or reading bot or agent it it",
      "timestamp": "11:27"
    },
    {
      "start": 691.76,
      "duration": 1.84,
      "text": "did exactly that You could use it to",
      "timestamp": "11:31"
    },
    {
      "start": 693.6,
      "duration": 2.32,
      "text": "read other story books and summarize but",
      "timestamp": "11:33"
    },
    {
      "start": 695.92,
      "duration": 2.72,
      "text": "it didn't do such a great job The other",
      "timestamp": "11:35"
    },
    {
      "start": 698.64,
      "duration": 2.319,
      "text": "thing was the data science people built",
      "timestamp": "11:38"
    },
    {
      "start": 700.959,
      "duration": 2.56,
      "text": "it So through the process through their",
      "timestamp": "11:40"
    },
    {
      "start": 703.519,
      "duration": 1.601,
      "text": "intelligence through their inference",
      "timestamp": "11:43"
    },
    {
      "start": 705.12,
      "duration": 2.719,
      "text": "they built a ready product and the end",
      "timestamp": "11:45"
    },
    {
      "start": 707.839,
      "duration": 1.68,
      "text": "users were really just feeding it more",
      "timestamp": "11:47"
    },
    {
      "start": 709.519,
      "duration": 2.961,
      "text": "data more resumes into the agent more",
      "timestamp": "11:49"
    },
    {
      "start": 712.48,
      "duration": 2.4,
      "text": "chat into that another bot and so forth",
      "timestamp": "11:52"
    },
    {
      "start": 714.88,
      "duration": 2.72,
      "text": "That was very narrow and there's often a",
      "timestamp": "11:54"
    },
    {
      "start": 717.6,
      "duration": 2.0,
      "text": "human in the loop that looks at all of",
      "timestamp": "11:57"
    },
    {
      "start": 719.6,
      "duration": 2.4,
      "text": "these stuff before it's being deployed",
      "timestamp": "11:59"
    },
    {
      "start": 722.0,
      "duration": 2.32,
      "text": "And monitoring and intervention was",
      "timestamp": "12:02"
    },
    {
      "start": 724.32,
      "duration": 2.4,
      "text": "relatively straightforward",
      "timestamp": "12:04"
    },
    {
      "start": 726.72,
      "duration": 5.76,
      "text": "However 2023 onwards 2024 the context of",
      "timestamp": "12:06"
    },
    {
      "start": 732.48,
      "duration": 3.84,
      "text": "the deployment has just exploded You you",
      "timestamp": "12:12"
    },
    {
      "start": 736.32,
      "duration": 3.92,
      "text": "ask your AI anything you want You know",
      "timestamp": "12:16"
    },
    {
      "start": 740.24,
      "duration": 5.92,
      "text": "I've uh uh I know my my my chat my my",
      "timestamp": "12:20"
    },
    {
      "start": 746.16,
      "duration": 1.6,
      "text": "agent is pretty pissed off with me",
      "timestamp": "12:26"
    },
    {
      "start": 747.76,
      "duration": 2.639,
      "text": "because I like to go on stage raw and",
      "timestamp": "12:27"
    },
    {
      "start": 750.399,
      "duration": 2.481,
      "text": "all the slides are basically not pass",
      "timestamp": "12:30"
    },
    {
      "start": 752.88,
      "duration": 2.8,
      "text": "through my my AI and you know it just",
      "timestamp": "12:32"
    },
    {
      "start": 755.68,
      "duration": 1.839,
      "text": "basically tells me you're nuts to go raw",
      "timestamp": "12:35"
    },
    {
      "start": 757.519,
      "duration": 1.921,
      "text": "on stage to do but I think that's pretty",
      "timestamp": "12:37"
    },
    {
      "start": 759.44,
      "duration": 1.92,
      "text": "human and I want people to spot spelling",
      "timestamp": "12:39"
    },
    {
      "start": 761.36,
      "duration": 2.64,
      "text": "errors and stuff like that But you could",
      "timestamp": "12:41"
    },
    {
      "start": 764.0,
      "duration": 2.639,
      "text": "ask your AI agent for any objective goal",
      "timestamp": "12:44"
    },
    {
      "start": 766.639,
      "duration": 2.161,
      "text": "single multi-shot prompts that you want",
      "timestamp": "12:46"
    },
    {
      "start": 768.8,
      "duration": 3.44,
      "text": "right You can ask it religious questions",
      "timestamp": "12:48"
    },
    {
      "start": 772.24,
      "duration": 2.719,
      "text": "health questions any questions and",
      "timestamp": "12:52"
    },
    {
      "start": 774.959,
      "duration": 3.041,
      "text": "monitoring AI in a while becomes wildly",
      "timestamp": "12:54"
    },
    {
      "start": 778.0,
      "duration": 1.839,
      "text": "important Before that it was done in a",
      "timestamp": "12:58"
    },
    {
      "start": 779.839,
      "duration": 1.841,
      "text": "closed circle It was developed like a",
      "timestamp": "12:59"
    },
    {
      "start": 781.68,
      "duration": 2.32,
      "text": "product I know how it works If there are",
      "timestamp": "13:01"
    },
    {
      "start": 784.0,
      "duration": 2.24,
      "text": "any exceptions gets reported back I will",
      "timestamp": "13:04"
    },
    {
      "start": 786.24,
      "duration": 2.8,
      "text": "improve that product Right now all of us",
      "timestamp": "13:06"
    },
    {
      "start": 789.04,
      "duration": 2.799,
      "text": "are users So how am I to guarantee that",
      "timestamp": "13:09"
    },
    {
      "start": 791.839,
      "duration": 2.0,
      "text": "if you use it for safety and if you use",
      "timestamp": "13:11"
    },
    {
      "start": 793.839,
      "duration": 1.921,
      "text": "it for car driving and if you use it for",
      "timestamp": "13:13"
    },
    {
      "start": 795.76,
      "duration": 2.4,
      "text": "making rockets it gives you the same",
      "timestamp": "13:15"
    },
    {
      "start": 798.16,
      "duration": 3.919,
      "text": "quality of results You can't It's too",
      "timestamp": "13:18"
    },
    {
      "start": 802.079,
      "duration": 3.76,
      "text": "far dispersed The IQ democratization",
      "timestamp": "13:22"
    },
    {
      "start": 805.839,
      "duration": 2.24,
      "text": "a human in a loop is still relatively",
      "timestamp": "13:25"
    },
    {
      "start": 808.079,
      "duration": 2.801,
      "text": "straightforward and geni requires extra",
      "timestamp": "13:28"
    },
    {
      "start": 810.88,
      "duration": 3.12,
      "text": "training to use to be responsible So we",
      "timestamp": "13:30"
    },
    {
      "start": 814.0,
      "duration": 2.32,
      "text": "talk about responsible AI but I really",
      "timestamp": "13:34"
    },
    {
      "start": 816.32,
      "duration": 2.079,
      "text": "argue that responsible prompting is a",
      "timestamp": "13:36"
    },
    {
      "start": 818.399,
      "duration": 3.361,
      "text": "big part of it Responsible AI is good",
      "timestamp": "13:38"
    },
    {
      "start": 821.76,
      "duration": 1.68,
      "text": "but responsible prompting is really",
      "timestamp": "13:41"
    },
    {
      "start": 823.44,
      "duration": 3.28,
      "text": "really good part of it",
      "timestamp": "13:43"
    },
    {
      "start": 826.72,
      "duration": 2.239,
      "text": "Now this is the mindboggling bit when it",
      "timestamp": "13:46"
    },
    {
      "start": 828.959,
      "duration": 2.801,
      "text": "gets out of scale So stage one I mean",
      "timestamp": "13:48"
    },
    {
      "start": 831.76,
      "duration": 1.84,
      "text": "just go with me on this story Stage one",
      "timestamp": "13:51"
    },
    {
      "start": 833.6,
      "duration": 2.96,
      "text": "you you take an LLM and you connect it",
      "timestamp": "13:53"
    },
    {
      "start": 836.56,
      "duration": 3.04,
      "text": "to another gen AI whatever you want Say",
      "timestamp": "13:56"
    },
    {
      "start": 839.6,
      "duration": 1.84,
      "text": "one that a VLM that generates video",
      "timestamp": "13:59"
    },
    {
      "start": 841.44,
      "duration": 2.48,
      "text": "clips You tell your LLM that you want",
      "timestamp": "14:01"
    },
    {
      "start": 843.92,
      "duration": 1.919,
      "text": "three different videos or cows whatever",
      "timestamp": "14:03"
    },
    {
      "start": 845.839,
      "duration": 3.521,
      "text": "it is So it goes and do that and it goes",
      "timestamp": "14:05"
    },
    {
      "start": 849.36,
      "duration": 1.44,
      "text": "to go through a narrow database and",
      "timestamp": "14:09"
    },
    {
      "start": 850.8,
      "duration": 2.24,
      "text": "comes back with results It can do that",
      "timestamp": "14:10"
    },
    {
      "start": 853.04,
      "duration": 3.2,
      "text": "No problem Stage two connected to 30",
      "timestamp": "14:13"
    },
    {
      "start": 856.24,
      "duration": 2.399,
      "text": "databases We can still deal with that",
      "timestamp": "14:16"
    },
    {
      "start": 858.639,
      "duration": 1.921,
      "text": "Come back with some responses 50 narrow",
      "timestamp": "14:18"
    },
    {
      "start": 860.56,
      "duration": 1.6,
      "text": "AIs",
      "timestamp": "14:20"
    },
    {
      "start": 862.16,
      "duration": 2.239,
      "text": "Stage three is where the alphabet soup",
      "timestamp": "14:22"
    },
    {
      "start": 864.399,
      "duration": 2.56,
      "text": "grows Add to your multimodal AI the",
      "timestamp": "14:24"
    },
    {
      "start": 866.959,
      "duration": 2.161,
      "text": "ability to take digital actions which is",
      "timestamp": "14:26"
    },
    {
      "start": 869.12,
      "duration": 3.12,
      "text": "claw 3.7 Take internet click action So",
      "timestamp": "14:29"
    },
    {
      "start": 872.24,
      "duration": 3.12,
      "text": "now you got multimodal agentic AI Then",
      "timestamp": "14:32"
    },
    {
      "start": 875.36,
      "duration": 3.039,
      "text": "next you get multimodal multi-agentic AI",
      "timestamp": "14:35"
    },
    {
      "start": 878.399,
      "duration": 1.68,
      "text": "But the last part is where it gets",
      "timestamp": "14:38"
    },
    {
      "start": 880.079,
      "duration": 2.32,
      "text": "really really scary What you have",
      "timestamp": "14:40"
    },
    {
      "start": 882.399,
      "duration": 1.601,
      "text": "between your enterprises different",
      "timestamp": "14:42"
    },
    {
      "start": 884.0,
      "duration": 3.12,
      "text": "agentic workflows talking to the agentic",
      "timestamp": "14:44"
    },
    {
      "start": 887.12,
      "duration": 1.68,
      "text": "workflows of other people in the",
      "timestamp": "14:47"
    },
    {
      "start": 888.8,
      "duration": 2.719,
      "text": "internet or in the wild there There is",
      "timestamp": "14:48"
    },
    {
      "start": 891.519,
      "duration": 2.0,
      "text": "just no way from a risk professional",
      "timestamp": "14:51"
    },
    {
      "start": 893.519,
      "duration": 1.76,
      "text": "there's just no way to imagine this",
      "timestamp": "14:53"
    },
    {
      "start": 895.279,
      "duration": 2.081,
      "text": "quarker I don't have a term for it",
      "timestamp": "14:55"
    },
    {
      "start": 897.36,
      "duration": 2.08,
      "text": "There's no other way to think about how",
      "timestamp": "14:57"
    },
    {
      "start": 899.44,
      "duration": 2.72,
      "text": "the explosion of the risk vector is It's",
      "timestamp": "14:59"
    },
    {
      "start": 902.16,
      "duration": 3.6,
      "text": "really really crazy So last slide or",
      "timestamp": "15:02"
    },
    {
      "start": 905.76,
      "duration": 1.68,
      "text": "second last slide what I want to say is",
      "timestamp": "15:05"
    },
    {
      "start": 907.44,
      "duration": 3.759,
      "text": "that the time for things is now I said",
      "timestamp": "15:07"
    },
    {
      "start": 911.199,
      "duration": 4.08,
      "text": "last year we've got 3 to 5 years before",
      "timestamp": "15:11"
    },
    {
      "start": 915.279,
      "duration": 3.68,
      "text": "the two scenarios you seeing one year",
      "timestamp": "15:15"
    },
    {
      "start": 918.959,
      "duration": 2.0,
      "text": "what it means in an acceleration quad",
      "timestamp": "15:18"
    },
    {
      "start": 920.959,
      "duration": 2.641,
      "text": "exponential year IQ points raised to",
      "timestamp": "15:20"
    },
    {
      "start": 923.6,
      "duration": 2.64,
      "text": "roughly about 130 140 right now for most",
      "timestamp": "15:23"
    },
    {
      "start": 926.24,
      "duration": 2.8,
      "text": "frontier models and guess what if you",
      "timestamp": "15:26"
    },
    {
      "start": 929.04,
      "duration": 2.08,
      "text": "join up all of the intelligences across",
      "timestamp": "15:29"
    },
    {
      "start": 931.12,
      "duration": 2.399,
      "text": "all these models and agents you get a",
      "timestamp": "15:31"
    },
    {
      "start": 933.519,
      "duration": 2.961,
      "text": "new Atlantis You get a new sunken island",
      "timestamp": "15:33"
    },
    {
      "start": 936.48,
      "duration": 4.24,
      "text": "that floats up with billions of new PhD",
      "timestamp": "15:36"
    },
    {
      "start": 940.72,
      "duration": 3.6,
      "text": "level workers coming up to take your",
      "timestamp": "15:40"
    },
    {
      "start": 944.32,
      "duration": 2.319,
      "text": "jobs For example",
      "timestamp": "15:44"
    },
    {
      "start": 946.639,
      "duration": 1.521,
      "text": "this was the slide I put up This is what",
      "timestamp": "15:46"
    },
    {
      "start": 948.16,
      "duration": 1.84,
      "text": "I'm going to end up with This was a",
      "timestamp": "15:48"
    },
    {
      "start": 950.0,
      "duration": 2.8,
      "text": "slide in 2022 If you look at some of the",
      "timestamp": "15:50"
    },
    {
      "start": 952.8,
      "duration": 2.159,
      "text": "stuff there it still holds true I called",
      "timestamp": "15:52"
    },
    {
      "start": 954.959,
      "duration": 2.161,
      "text": "it a fork And obviously that was the old",
      "timestamp": "15:54"
    },
    {
      "start": 957.12,
      "duration": 2.56,
      "text": "icon and that's a new icon on top I",
      "timestamp": "15:57"
    },
    {
      "start": 959.68,
      "duration": 2.64,
      "text": "didn't have a good icon for a fork So",
      "timestamp": "15:59"
    },
    {
      "start": 962.32,
      "duration": 2.48,
      "text": "human level intelligence 2027 to around",
      "timestamp": "16:02"
    },
    {
      "start": 964.8,
      "duration": 2.32,
      "text": "2035 obviously now most of the experts",
      "timestamp": "16:04"
    },
    {
      "start": 967.12,
      "duration": 3.12,
      "text": "agree it's by 2027 2029",
      "timestamp": "16:07"
    },
    {
      "start": 970.24,
      "duration": 4.08,
      "text": "that area around in the fork here",
      "timestamp": "16:10"
    },
    {
      "start": 974.32,
      "duration": 2.24,
      "text": "is where most of the agentic AI safety",
      "timestamp": "16:14"
    },
    {
      "start": 976.56,
      "duration": 2.32,
      "text": "work needs to be done and if you just",
      "timestamp": "16:16"
    },
    {
      "start": 978.88,
      "duration": 1.759,
      "text": "measure the level of communications",
      "timestamp": "16:18"
    },
    {
      "start": 980.639,
      "duration": 1.601,
      "text": "between different countries we know",
      "timestamp": "16:20"
    },
    {
      "start": 982.24,
      "duration": 1.76,
      "text": "which countries we're talking about I",
      "timestamp": "16:22"
    },
    {
      "start": 984.0,
      "duration": 2.48,
      "text": "was at the ATX safety policy the",
      "timestamp": "16:24"
    },
    {
      "start": 986.48,
      "duration": 3.44,
      "text": "communication is zero",
      "timestamp": "16:26"
    },
    {
      "start": 989.92,
      "duration": 3.279,
      "text": "that's how I'll end here thank you so",
      "timestamp": "16:29"
    }
  ],
  "extraction_timestamp": "2025-06-29T21:04:35.418328",
  "playlist_title": "SuperAI Singapore 2025: WEKA Stage"
}