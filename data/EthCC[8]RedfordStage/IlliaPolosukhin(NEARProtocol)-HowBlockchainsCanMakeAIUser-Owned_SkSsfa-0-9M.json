{
  "video_id": "SkSsfa-0-9M",
  "video_title": "Illia Polosukhin (NEAR Protocol )-How Blockchains Can Make AI User-Owned",
  "video_url": "https://www.youtube.com/watch?v=SkSsfa-0-9M",
  "channel_title": "[EthCC] Livestream 4",
  "published_at": "2025-07-03T23:12:48+00:00",
  "duration_seconds": null,
  "view_count": 256,
  "like_count": 19,
  "description": "To preserve open economies and individual sovereignty, AI must become user-owned, not corporate-owned. Illia shows how blockchains will make AI open source yet monetizable, unpacking the AIxWeb3 stack and protocols powering the agentic future.",
  "transcript": {
    "language": "en",
    "is_auto_generated": false,
    "total_segments": 520,
    "aggregated_text": "[Music] And we're back. Uh thank everyone for coming after lunch. Hope you don't fall asleep uh during this presentation. Uh today I want to talk about how blockchains can make AI user owned. For those who not familiar with me, I am a co-founder of Near Ilia Suhen. My background is in machine learning and AI research. I worked at Google research um until 2017. I was working across infrastructure like TensorFlow as well as natural language understanding back in the day. you know before Gemini you could ask questions and there was an AI model trying to respond uh reading different articles now one of the challenges we faced there was that uh models we're using were highly not performant they couldn't read all the context in the time that Google needs to respond and so that actually what gave birth to the transformer model which is a TGPT and so I'm one of the co-authors working with a team to actually bring this uh to life. Now I left Google to start near as an AI startup. It originally was about using transformers to uh teach machines to code which now is called VIPE coding. Back then we had uh way less uh compute capacity. There was no uh kind of even A100s yet. And so we're trying to get a lot more training data for us to train our models. And so we had a lot of users um kind of students uh around the world who would give us um kind of contribute data in various ways write some uh small amounts of code write some descriptions for code and we had challenge paying them right in China students don't have bank accounts they have which pay in Ukraine you need to sell half of your dollars in arrival back in the day uh in Russia you know PayPal didn't work and so like all of the systems had some kind of challenges and so we ended uh looking at blockchain as a solution to our problem as AI company. How do we actually facilitate this contributions uh from different people around the world to our model and we didn't find anything that would scale and would be cheap enough for the for our need and that's how we started Near Protocol in 2018. Now fast forwarding we're now here with AI evolving faster than ever. we have effectively AGI that is coming closer and closer where most of the digital work will get automated and physical work is not far behind with robotics. Now the challenge is whoever controls this AI, whoever decides how you can use it, whoever defines what bias the training data has, whoever defines what safety rules can be applied controls everything. Right? We already have this. You know, I was just checking two Nobel prizes last year were won by effectively AI. Uh the, you know, a lot more code has been written by AI. A lot more decisions are going to be delegated to AI as well. And so whoever controls how this AIS are trained will effectively affect all the decisions, all this code, and all this inventions. There's also a paradigm shift on kind of application and user side. We're going from kind of web two where we had uh kind of converged into this aggregator model right we had Google for aggregating all the websites we had Amazon for getting all products we had you know social media for aggregating all content um where we now seen this transition where um you starting to talk to you know kind of instead of asking these models you're talking to your AI assistant and and it kind of routes you maybe to this content but actually tries to answer things directly. Now the next step is it actually goes and does even actions on your behalf on those different websites right it goes and registers for you uh and you know books tickets and figures out how to uh do minion tasks. Now the interesting step be after that going to be where you can trust this AI with more decisions because it has more context and now it's able to go in directly for example talk to AI of the pharma company and figure out exact medicines exact proteins that need to be synthesized for you specifically based on your medical data right this bypasses five or you know 10 different middleman decision makers everything from FDA to you know pharma to kind uh all of the different entities including pharmacies that are right now facilitating how you you know transacting with uh kind of medicine. So all of this is the transformation that kind of we see happening with agent network right this is this is going to happen with or without web 3 but as I said if AI is controlled by a single party it's effectively this whole system will be controlled by them now there's also just general challenges in AI one of them is monetization right now if you're building kind of a normal AI company uh you effectively have very scarce resource of compute and uh you build a model or you build some agent. You offer this to the uh to the users. If this is a good model, you get lots of usage and now you run out of compute. You also don't have now capacity to train new model because you're out of compute and you know getting more compute uh at a good price is actually pretty long process you know takes time because you only want to get it from you know few of the providers uh like Amazon, Microsoft, Asia or Google or Corv and so you actually have a and even though there is maybe data centers around the world you have this challenge now you also taking all the data risks all the privacy risks of the users, right? You're handling all the user data as is this. Now the other alternative is you just open source the model but the problem is it's not sustainable, right? You're not making any money. There's no way to reinvest and train your model and this is expensive process. So right now we have like few companies developing this a ton of people especially in universities s sitting on sidelines without access to compute. So we have unsustainable model and a very complex kind of logistics of compute and trust uh on the closed source side and so there's a lot of kind of challenges there because again as a company you don't trust external data centers because your models your IP and if this IP leaks then you effectively lose your business and so you don't trust with your model to some external parties and so this ends up having this kind of lots of problems. One is you only trust a few data centers. Data centers don't build that fast. They need a lot of electricity. This is all in kind of some close proximity. There's like few cities uh kind of in regions in US where right now this is buildout happening. Um even though there's again lots and lots of space with electricity around the world. Uh which also leads to latency. Right? If I'm sitting in Japan and I'm using chat GPT, I need you know round trips to Texas. you have um data that you know gets uploaded and you know there's been stories of for example Samsung their data got leaked to uh their competitor through openAI because they were just using uh you know copilot style product and their code ends up being in training data for uh openi model you have so this goes to you know general corporate security especially if you're handling users data this is even more private right a lot of legal firms financial firms are not allowing to to use AI on user data because they're afraid that this is gonna leak. And this a sovereignty question right at the end if I'm a country and I'm using a centralized provider of the models from another country that country effectively have more power over me especially when the AI starts to become really big contributor to GDP big contributor to automation big contributor to decision- making of the country. So all of the challenges now on top of this there's kind of this more fundamental safety challenge right there's a lot of conversations about is AI safe uh how do we ensure it is and uh kind of there's always a reason oh we're not going to open source our model because it's unsafe and then people get you know open weights model and use it uh but generally the problem is the safety is applied very unevenly right we don't have kind of a universal way to apply safety rules across all models that and how people participate with them. So that's why we formulated a new way new uh vision called user on AI. It's approach where AI is optimized for users well-being and economic success not corporate profits and it's built on top of you know all of the kind of approaches we've built in web 3. So what we want to make sure is everyone has access equal access to the models while the safety applied equally as well kind of safety constraints right nobody should be able to use it to design nuclear weapon nobody should able to design bioeapon um user data should be preserved in private unless user wants to contribute it to training in in return for something so confidentiality and permissionlessness is extremely important we want to know how models trained again right now even the so-called open source models are actually not open source. They're open weights. We don't actually know what went into them. And if you don't know what went into them, you don't know what actually bias this model has, right? Is it leaning right or left in US? Is this more pro, you know, some religion? We don't know it. You also don't know if there is so-called sleeper agents. Sleeper agents is a special way to train a model where it will ex have a different behavior under certain conditions. For example, normally when you look at the model, it does behave normally, but when you're using it to build production software, it will actually import some malicious library and effectively infect your production system. So you want to make sure that you know what training data went in verifiably. And so you want to know effectively the whole provenence of training of this model. Now, more importantly, this needs to be a state-of-the-art model, right? Nobody will use some meh model. Uh it people will prefer better product over you know values. That's always been the case. That's why crypto been so slow to adopt. Now uh you want to make sure that this state-of-the-art model has verifiability of data and model training. So we need a whole setup for that. And we need continuous research and improvements, right? Like it cannot be just like hey cool we build one state of the model and we're done. It needs to be a continuous process of getting state-of-the-art model and research. There's also a very uh you know important aspect that if you completely open source that means that any other closed source lab can take it open source and build on top of it and so you cannot be at state-of-the-art if you're completely open source. So you need to create some asymmetry of information for this to be really true. So we introduced a solution called decentralized confidential machine learning at NVIDIA GTC. It's really about creating a platform for this kind of user own AI uh and the road map how we can get there. So it's it's really about creating verifiable and confidential computing that can be run anywhere in the world. Nodes can join it. Uh that allows to monetize models as well as train uh fine-tune models in a verifiable way. and it offers a safety tooling that is kind of applied to everyone uh and nobody can get privileged access to the models. How does this work? Well, first it's built on top of trusted execution environments. So, as of about a year ago, uh Nvidia has enabled a confidential computing mode on their GPUs that works with Intel, AMD and ARM uh uh kind of T environments. And so uh which themselves have improved at least Intels and ARMs have improved uh since the past. And this environment itself allows to effectively run computing in a vault right in such a way that whoever even owns the computer is not able to access it uh directly. It now has GPU enabled and interestingly it has this verifiableility property that this code is running on this computer. It ran this data and only this compute was run on this data right meaning you can guarantee that after the running on my data it will delete it and will never you know store it or use it again. So you have this interesting privacy confidentiality properties that you actually don't get even from some of the FHE solutions and definitely don't get uh with ZK and other kind of traditional methods. Now we all put it together into what we kind of this decentralized machine learning cloud where a user effectively uh paying on chain uh for using the models and then can connect directly to the data to the compute providers and run inside the confidential VM different models and different agents and then there's a lot of pieces that need to be done to kind of tie it all together to ensure you know livveness of computers to ensure kind of this model marketplace uh But it provides us with this fundamental building blocks for bu kind of running and building user own AI. So we have a number of teams actually building this together. This is not kind of a single team effort in a you know decentralization spirit. And so uh we have you know on the near one side the team that builds near protocol they're doing a lot of the uh key management and uh kind of uh encryption decryption. We have proof of response done uh to ensure the livveness of nodes. We have Fala doing trust execution environments and consension inference. We also have teams building on top of it everything from model training to benchmarking to hosting to rack to private memory uh and and various data synthetic data and human label data. And this is not a full list but this is kind of just to show you that this is a whole stack of teams working together. Now this actually is about deconstructing the AI lab right? If you go into one of the centralized labs and you open it up, right, there's actually a number of teams that working together and they're creating a flywheel of research that's happening inside, right? And so it's important to kind of replicate this process in a decentralized way, opening up ability to actually source talent from everywhere in the world and give them opportunity to participate. Uh so it starts with data, right? You want data acquisition, ability to find better data, uh clean it and improve it, right? There's a number of techniques and hacks to improve this as well as using kind of a lower grade models to uh refine data. There's a synthetic data proc kind of reprocessing as well as user contributed data. If users are willing to contribute their data in various ways which here we can actually guarantee that nobody no single person can actually sees the data. It will be cleaned in a very specific way and then it'll be used for training again without revealing the individual data. Um then we go to pre-training step right this is kind of the foundational part. This is about ali algorithmical improvements improvements to the training process itself. How do you do curriculum learning? How do you improve you know uh ability model to learn from less data from seeing less examples and then obviously research on how do we do it across a distributed and decentralized cluster. Right? There's a few teams that have been already working on this and making good progress. Um and decentralized training is kind of this uh I would say holy grail that people talk about because it would allow us to actually replicate the whole process right if we can do decentralized training on DCML that means we have this verifiability of where data came from how it was processed and then this model artifact effectively came from this data now you can actually keep the model artifact encrypted right the weights of the model doesn't need to be open so open to everyone they can be encrypted and available in this decentralized network. This actually has all the properties of open weights. You can use it permissionlessly. It's available everywhere. You can use it even on your own hardware. Uh but it's monetizable now. You can actually charge. So even if you are like you know individual developer who just trained a model, you can now charge for using this if it's a good model. And so this solves really this fundamental problem that kind of open source is not monetizable. We're actually kind of changing the game to have you know encrypted models with open source to be monetizable and at the same time have all the properties and so kind of if you simplify there's effect three steps. Step one create a market for inference where you can serve this encrypted models so anyone can participate upload their models and uh uh serve it. uh this solves for this kind of trust problem between model providers and solves for privacy from companies and users who care. Then we can run benchmarks competitions for different aspects of model building. Refine data better, get uh you know get the reward, improve the model algorithm, improve the model training, get reward, run this continuous benchmark effectively as in you would run the teams internally with you know OKRs and uh bonuses on uh people actually coming up with new ideas. Step three, put it all together into you know training fine-tuning post-training process and actually deliver different specialized models for different use cases that people can use that are beating on this benchmarks. Uh and that's really all together this is how we build this userowned AI and this is what we believe is the way to actually ensure we're not going to end up in 1984 you know big brother style world. So this is pretty much it. If you're interested to learn more, follow us on Twitter at near protocol at Elbugdragon. And uh thank you very much for coming. [Applause] Have time for one question, two questions. Hi, thank you. Very interesting. The question is the near AI which you're building can it be rolled out as a wallet itself so that the agent is a wallet? So uh there's a whole kind of this is this is really the infrastructure and foundational side. There's also the application side. So on application side the wallets you know your user wallet uh will have your private memory private data for AI. You can have agents running there on your behalf but you can also run autonomous agents and autonomous agents have their own wallet. They can enable and transact and you know through near chain signatures and intents they can transact everywhere. They can even start buying physical businesses hire people can do all those things but they're autonomous. So there's effectively a dichotomy between agents that work on behalf of people behalf of businesses and autonomous that run kind of themselves. Think of them as you know fully independent companies that may have shareholders through a token but effectively run themselves. Hi Pedro here. Thank thank you for the talk. Um I have a question related to the maturity of your project so far. uh spec specifically about the use of TE's and the GPU TE's. Are you guys already kind of using them heavily and do you have already kind of remote attestation figured out and how this integrates into your whole um ecosystem? Yeah. So, uh the T and confidential inference is live right now uh through follow and then uh what we're finishing right now is the key management for the specifically recovering keys in TE. So you can decrypt encrypt models uh for this kind of serving but you could right now you can use confidential inference on open source models. So this is available right now you can verify all the signatures kind of invidia etc. And we have key management authority on near that can effectively provision all this. All right. Thank you very much.",
    "text_length": 19511,
    "word_count": 3525
  },
  "segments": [
    {
      "start": 2.3,
      "duration": 8.419,
      "text": "[Music]",
      "timestamp": "00:02"
    },
    {
      "start": 10.719,
      "duration": 4.0,
      "text": "And we're back. Uh thank everyone for",
      "timestamp": "00:10"
    },
    {
      "start": 14.719,
      "duration": 2.64,
      "text": "coming after lunch. Hope you don't fall",
      "timestamp": "00:14"
    },
    {
      "start": 17.359,
      "duration": 3.201,
      "text": "asleep uh during this presentation. Uh",
      "timestamp": "00:17"
    },
    {
      "start": 20.56,
      "duration": 1.2,
      "text": "today I want to talk about how",
      "timestamp": "00:20"
    },
    {
      "start": 21.76,
      "duration": 3.599,
      "text": "blockchains can make AI user owned. For",
      "timestamp": "00:21"
    },
    {
      "start": 25.359,
      "duration": 3.281,
      "text": "those who not familiar with me, I am a",
      "timestamp": "00:25"
    },
    {
      "start": 28.64,
      "duration": 3.2,
      "text": "co-founder of Near Ilia Suhen. My",
      "timestamp": "00:28"
    },
    {
      "start": 31.84,
      "duration": 1.92,
      "text": "background is in machine learning and AI",
      "timestamp": "00:31"
    },
    {
      "start": 33.76,
      "duration": 3.76,
      "text": "research. I worked at Google research um",
      "timestamp": "00:33"
    },
    {
      "start": 37.52,
      "duration": 2.32,
      "text": "until 2017.",
      "timestamp": "00:37"
    },
    {
      "start": 39.84,
      "duration": 3.36,
      "text": "I was working across infrastructure like",
      "timestamp": "00:39"
    },
    {
      "start": 43.2,
      "duration": 2.879,
      "text": "TensorFlow as well as natural language",
      "timestamp": "00:43"
    },
    {
      "start": 46.079,
      "duration": 2.081,
      "text": "understanding back in the day. you know",
      "timestamp": "00:46"
    },
    {
      "start": 48.16,
      "duration": 1.84,
      "text": "before Gemini you could ask questions",
      "timestamp": "00:48"
    },
    {
      "start": 50.0,
      "duration": 2.16,
      "text": "and there was an AI model trying to",
      "timestamp": "00:50"
    },
    {
      "start": 52.16,
      "duration": 3.52,
      "text": "respond uh reading different articles",
      "timestamp": "00:52"
    },
    {
      "start": 55.68,
      "duration": 2.24,
      "text": "now one of the challenges we faced there",
      "timestamp": "00:55"
    },
    {
      "start": 57.92,
      "duration": 3.04,
      "text": "was that uh models we're using were",
      "timestamp": "00:57"
    },
    {
      "start": 60.96,
      "duration": 2.56,
      "text": "highly not performant they couldn't read",
      "timestamp": "01:00"
    },
    {
      "start": 63.52,
      "duration": 2.48,
      "text": "all the context in the time that Google",
      "timestamp": "01:03"
    },
    {
      "start": 66.0,
      "duration": 1.92,
      "text": "needs to respond and so that actually",
      "timestamp": "01:06"
    },
    {
      "start": 67.92,
      "duration": 2.32,
      "text": "what gave birth to the transformer model",
      "timestamp": "01:07"
    },
    {
      "start": 70.24,
      "duration": 2.72,
      "text": "which is a TGPT and so I'm one of the",
      "timestamp": "01:10"
    },
    {
      "start": 72.96,
      "duration": 1.76,
      "text": "co-authors working with a team to",
      "timestamp": "01:12"
    },
    {
      "start": 74.72,
      "duration": 3.2,
      "text": "actually bring this uh to life. Now I",
      "timestamp": "01:14"
    },
    {
      "start": 77.92,
      "duration": 2.0,
      "text": "left Google to start near as an AI",
      "timestamp": "01:17"
    },
    {
      "start": 79.92,
      "duration": 2.879,
      "text": "startup. It originally was about using",
      "timestamp": "01:19"
    },
    {
      "start": 82.799,
      "duration": 2.561,
      "text": "transformers to uh teach machines to",
      "timestamp": "01:22"
    },
    {
      "start": 85.36,
      "duration": 2.799,
      "text": "code which now is called VIPE coding.",
      "timestamp": "01:25"
    },
    {
      "start": 88.159,
      "duration": 3.6,
      "text": "Back then we had uh way less uh compute",
      "timestamp": "01:28"
    },
    {
      "start": 91.759,
      "duration": 2.881,
      "text": "capacity. There was no uh kind of even",
      "timestamp": "01:31"
    },
    {
      "start": 94.64,
      "duration": 2.799,
      "text": "A100s yet. And so we're trying to get a",
      "timestamp": "01:34"
    },
    {
      "start": 97.439,
      "duration": 2.401,
      "text": "lot more training data for us to train",
      "timestamp": "01:37"
    },
    {
      "start": 99.84,
      "duration": 3.52,
      "text": "our models. And so we had a lot of users",
      "timestamp": "01:39"
    },
    {
      "start": 103.36,
      "duration": 2.399,
      "text": "um kind of students uh around the world",
      "timestamp": "01:43"
    },
    {
      "start": 105.759,
      "duration": 3.121,
      "text": "who would give us um kind of contribute",
      "timestamp": "01:45"
    },
    {
      "start": 108.88,
      "duration": 2.64,
      "text": "data in various ways write some uh small",
      "timestamp": "01:48"
    },
    {
      "start": 111.52,
      "duration": 1.919,
      "text": "amounts of code write some descriptions",
      "timestamp": "01:51"
    },
    {
      "start": 113.439,
      "duration": 2.0,
      "text": "for code and we had challenge paying",
      "timestamp": "01:53"
    },
    {
      "start": 115.439,
      "duration": 2.401,
      "text": "them right in China students don't have",
      "timestamp": "01:55"
    },
    {
      "start": 117.84,
      "duration": 1.84,
      "text": "bank accounts they have which pay in",
      "timestamp": "01:57"
    },
    {
      "start": 119.68,
      "duration": 1.68,
      "text": "Ukraine you need to sell half of your",
      "timestamp": "01:59"
    },
    {
      "start": 121.36,
      "duration": 2.799,
      "text": "dollars in arrival back in the day uh in",
      "timestamp": "02:01"
    },
    {
      "start": 124.159,
      "duration": 2.161,
      "text": "Russia you know PayPal didn't work and",
      "timestamp": "02:04"
    },
    {
      "start": 126.32,
      "duration": 2.159,
      "text": "so like all of the systems had some kind",
      "timestamp": "02:06"
    },
    {
      "start": 128.479,
      "duration": 2.4,
      "text": "of challenges and so we ended",
      "timestamp": "02:08"
    },
    {
      "start": 130.879,
      "duration": 2.0,
      "text": "uh looking at blockchain as a solution",
      "timestamp": "02:10"
    },
    {
      "start": 132.879,
      "duration": 2.481,
      "text": "to our problem as AI company. How do we",
      "timestamp": "02:12"
    },
    {
      "start": 135.36,
      "duration": 2.72,
      "text": "actually facilitate this contributions",
      "timestamp": "02:15"
    },
    {
      "start": 138.08,
      "duration": 1.28,
      "text": "uh from different people around the",
      "timestamp": "02:18"
    },
    {
      "start": 139.36,
      "duration": 2.959,
      "text": "world to our model and we didn't find",
      "timestamp": "02:19"
    },
    {
      "start": 142.319,
      "duration": 1.761,
      "text": "anything that would scale and would be",
      "timestamp": "02:22"
    },
    {
      "start": 144.08,
      "duration": 2.08,
      "text": "cheap enough for the for our need and",
      "timestamp": "02:24"
    },
    {
      "start": 146.16,
      "duration": 2.079,
      "text": "that's how we started Near Protocol in",
      "timestamp": "02:26"
    },
    {
      "start": 148.239,
      "duration": 2.161,
      "text": "2018.",
      "timestamp": "02:28"
    },
    {
      "start": 150.4,
      "duration": 3.6,
      "text": "Now fast forwarding we're now here with",
      "timestamp": "02:30"
    },
    {
      "start": 154.0,
      "duration": 3.28,
      "text": "AI evolving faster than ever. we have",
      "timestamp": "02:34"
    },
    {
      "start": 157.28,
      "duration": 2.72,
      "text": "effectively AGI that is coming closer",
      "timestamp": "02:37"
    },
    {
      "start": 160.0,
      "duration": 3.04,
      "text": "and closer where most of the digital",
      "timestamp": "02:40"
    },
    {
      "start": 163.04,
      "duration": 3.12,
      "text": "work will get automated and physical",
      "timestamp": "02:43"
    },
    {
      "start": 166.16,
      "duration": 3.12,
      "text": "work is not far behind with robotics.",
      "timestamp": "02:46"
    },
    {
      "start": 169.28,
      "duration": 2.319,
      "text": "Now the challenge is whoever controls",
      "timestamp": "02:49"
    },
    {
      "start": 171.599,
      "duration": 2.481,
      "text": "this AI, whoever decides how you can use",
      "timestamp": "02:51"
    },
    {
      "start": 174.08,
      "duration": 2.48,
      "text": "it, whoever defines what bias the",
      "timestamp": "02:54"
    },
    {
      "start": 176.56,
      "duration": 2.319,
      "text": "training data has, whoever defines what",
      "timestamp": "02:56"
    },
    {
      "start": 178.879,
      "duration": 2.481,
      "text": "safety rules can be applied controls",
      "timestamp": "02:58"
    },
    {
      "start": 181.36,
      "duration": 2.56,
      "text": "everything. Right? We already have this.",
      "timestamp": "03:01"
    },
    {
      "start": 183.92,
      "duration": 1.599,
      "text": "You know, I was just checking two Nobel",
      "timestamp": "03:03"
    },
    {
      "start": 185.519,
      "duration": 2.64,
      "text": "prizes last year were won by effectively",
      "timestamp": "03:05"
    },
    {
      "start": 188.159,
      "duration": 4.08,
      "text": "AI. Uh the, you know, a lot more code",
      "timestamp": "03:08"
    },
    {
      "start": 192.239,
      "duration": 2.161,
      "text": "has been written by AI. A lot more",
      "timestamp": "03:12"
    },
    {
      "start": 194.4,
      "duration": 1.6,
      "text": "decisions are going to be delegated to",
      "timestamp": "03:14"
    },
    {
      "start": 196.0,
      "duration": 2.72,
      "text": "AI as well. And so whoever controls how",
      "timestamp": "03:16"
    },
    {
      "start": 198.72,
      "duration": 2.0,
      "text": "this AIS are trained will effectively",
      "timestamp": "03:18"
    },
    {
      "start": 200.72,
      "duration": 2.08,
      "text": "affect all the decisions, all this code,",
      "timestamp": "03:20"
    },
    {
      "start": 202.8,
      "duration": 3.2,
      "text": "and all this inventions.",
      "timestamp": "03:22"
    },
    {
      "start": 206.0,
      "duration": 2.159,
      "text": "There's also a paradigm shift on kind of",
      "timestamp": "03:26"
    },
    {
      "start": 208.159,
      "duration": 2.08,
      "text": "application and user side. We're going",
      "timestamp": "03:28"
    },
    {
      "start": 210.239,
      "duration": 4.401,
      "text": "from kind of web two where we had uh",
      "timestamp": "03:30"
    },
    {
      "start": 214.64,
      "duration": 2.239,
      "text": "kind of converged into this aggregator",
      "timestamp": "03:34"
    },
    {
      "start": 216.879,
      "duration": 1.44,
      "text": "model right we had Google for",
      "timestamp": "03:36"
    },
    {
      "start": 218.319,
      "duration": 1.84,
      "text": "aggregating all the websites we had",
      "timestamp": "03:38"
    },
    {
      "start": 220.159,
      "duration": 2.481,
      "text": "Amazon for getting all products we had",
      "timestamp": "03:40"
    },
    {
      "start": 222.64,
      "duration": 2.08,
      "text": "you know social media for aggregating",
      "timestamp": "03:42"
    },
    {
      "start": 224.72,
      "duration": 3.36,
      "text": "all content um where we now seen this",
      "timestamp": "03:44"
    },
    {
      "start": 228.08,
      "duration": 4.4,
      "text": "transition where um you starting to talk",
      "timestamp": "03:48"
    },
    {
      "start": 232.48,
      "duration": 2.88,
      "text": "to you know kind of instead of asking",
      "timestamp": "03:52"
    },
    {
      "start": 235.36,
      "duration": 3.04,
      "text": "these models you're talking to your AI",
      "timestamp": "03:55"
    },
    {
      "start": 238.4,
      "duration": 1.919,
      "text": "assistant and and it kind of routes you",
      "timestamp": "03:58"
    },
    {
      "start": 240.319,
      "duration": 2.48,
      "text": "maybe to this content but actually tries",
      "timestamp": "04:00"
    },
    {
      "start": 242.799,
      "duration": 2.8,
      "text": "to answer things directly. Now the next",
      "timestamp": "04:02"
    },
    {
      "start": 245.599,
      "duration": 1.92,
      "text": "step is it actually goes and does even",
      "timestamp": "04:05"
    },
    {
      "start": 247.519,
      "duration": 1.841,
      "text": "actions on your behalf on those",
      "timestamp": "04:07"
    },
    {
      "start": 249.36,
      "duration": 1.519,
      "text": "different websites right it goes and",
      "timestamp": "04:09"
    },
    {
      "start": 250.879,
      "duration": 3.44,
      "text": "registers for you uh and you know books",
      "timestamp": "04:10"
    },
    {
      "start": 254.319,
      "duration": 4.081,
      "text": "tickets and figures out how to uh do",
      "timestamp": "04:14"
    },
    {
      "start": 258.4,
      "duration": 2.799,
      "text": "minion tasks. Now the interesting step",
      "timestamp": "04:18"
    },
    {
      "start": 261.199,
      "duration": 3.28,
      "text": "be after that going to be where you can",
      "timestamp": "04:21"
    },
    {
      "start": 264.479,
      "duration": 2.481,
      "text": "trust this AI with more decisions",
      "timestamp": "04:24"
    },
    {
      "start": 266.96,
      "duration": 2.64,
      "text": "because it has more context and now it's",
      "timestamp": "04:26"
    },
    {
      "start": 269.6,
      "duration": 2.159,
      "text": "able to go in directly for example talk",
      "timestamp": "04:29"
    },
    {
      "start": 271.759,
      "duration": 2.401,
      "text": "to AI of the pharma company and figure",
      "timestamp": "04:31"
    },
    {
      "start": 274.16,
      "duration": 2.24,
      "text": "out exact medicines exact proteins that",
      "timestamp": "04:34"
    },
    {
      "start": 276.4,
      "duration": 1.519,
      "text": "need to be synthesized for you",
      "timestamp": "04:36"
    },
    {
      "start": 277.919,
      "duration": 2.161,
      "text": "specifically based on your medical data",
      "timestamp": "04:37"
    },
    {
      "start": 280.08,
      "duration": 3.28,
      "text": "right this bypasses five or you know 10",
      "timestamp": "04:40"
    },
    {
      "start": 283.36,
      "duration": 2.16,
      "text": "different middleman decision makers",
      "timestamp": "04:43"
    },
    {
      "start": 285.52,
      "duration": 2.56,
      "text": "everything from FDA to you know pharma",
      "timestamp": "04:45"
    },
    {
      "start": 288.08,
      "duration": 3.76,
      "text": "to kind uh all of the different entities",
      "timestamp": "04:48"
    },
    {
      "start": 291.84,
      "duration": 2.079,
      "text": "including pharmacies that are right now",
      "timestamp": "04:51"
    },
    {
      "start": 293.919,
      "duration": 2.081,
      "text": "facilitating how you you know",
      "timestamp": "04:53"
    },
    {
      "start": 296.0,
      "duration": 4.08,
      "text": "transacting with uh kind of medicine. So",
      "timestamp": "04:56"
    },
    {
      "start": 300.08,
      "duration": 2.16,
      "text": "all of this is the transformation that",
      "timestamp": "05:00"
    },
    {
      "start": 302.24,
      "duration": 1.92,
      "text": "kind of we see happening with agent",
      "timestamp": "05:02"
    },
    {
      "start": 304.16,
      "duration": 1.759,
      "text": "network right this is this is going to",
      "timestamp": "05:04"
    },
    {
      "start": 305.919,
      "duration": 2.241,
      "text": "happen with or without web 3 but as I",
      "timestamp": "05:05"
    },
    {
      "start": 308.16,
      "duration": 2.4,
      "text": "said if AI is controlled by a single",
      "timestamp": "05:08"
    },
    {
      "start": 310.56,
      "duration": 2.4,
      "text": "party it's effectively this whole system",
      "timestamp": "05:10"
    },
    {
      "start": 312.96,
      "duration": 2.56,
      "text": "will be controlled by them now there's",
      "timestamp": "05:12"
    },
    {
      "start": 315.52,
      "duration": 2.72,
      "text": "also just general challenges in AI one",
      "timestamp": "05:15"
    },
    {
      "start": 318.24,
      "duration": 2.16,
      "text": "of them is monetization right now if",
      "timestamp": "05:18"
    },
    {
      "start": 320.4,
      "duration": 2.079,
      "text": "you're building kind of a normal AI",
      "timestamp": "05:20"
    },
    {
      "start": 322.479,
      "duration": 3.28,
      "text": "company uh you effectively have very",
      "timestamp": "05:22"
    },
    {
      "start": 325.759,
      "duration": 3.761,
      "text": "scarce resource of compute and uh you",
      "timestamp": "05:25"
    },
    {
      "start": 329.52,
      "duration": 2.08,
      "text": "build a model or you build some agent.",
      "timestamp": "05:29"
    },
    {
      "start": 331.6,
      "duration": 3.039,
      "text": "You offer this to the uh to the users.",
      "timestamp": "05:31"
    },
    {
      "start": 334.639,
      "duration": 2.321,
      "text": "If this is a good model, you get lots of",
      "timestamp": "05:34"
    },
    {
      "start": 336.96,
      "duration": 2.32,
      "text": "usage and now you run out of compute.",
      "timestamp": "05:36"
    },
    {
      "start": 339.28,
      "duration": 1.68,
      "text": "You also don't have now capacity to",
      "timestamp": "05:39"
    },
    {
      "start": 340.96,
      "duration": 1.6,
      "text": "train new model because you're out of",
      "timestamp": "05:40"
    },
    {
      "start": 342.56,
      "duration": 2.079,
      "text": "compute and you know getting more",
      "timestamp": "05:42"
    },
    {
      "start": 344.639,
      "duration": 2.56,
      "text": "compute uh at a good price is actually",
      "timestamp": "05:44"
    },
    {
      "start": 347.199,
      "duration": 2.481,
      "text": "pretty long process you know takes time",
      "timestamp": "05:47"
    },
    {
      "start": 349.68,
      "duration": 2.0,
      "text": "because you only want to get it from you",
      "timestamp": "05:49"
    },
    {
      "start": 351.68,
      "duration": 2.56,
      "text": "know few of the providers uh like",
      "timestamp": "05:51"
    },
    {
      "start": 354.24,
      "duration": 4.08,
      "text": "Amazon, Microsoft, Asia or Google or",
      "timestamp": "05:54"
    },
    {
      "start": 358.32,
      "duration": 3.36,
      "text": "Corv and so you actually have a and even",
      "timestamp": "05:58"
    },
    {
      "start": 361.68,
      "duration": 1.6,
      "text": "though there is maybe data centers",
      "timestamp": "06:01"
    },
    {
      "start": 363.28,
      "duration": 1.919,
      "text": "around the world you have this challenge",
      "timestamp": "06:03"
    },
    {
      "start": 365.199,
      "duration": 2.56,
      "text": "now you also taking all the data risks",
      "timestamp": "06:05"
    },
    {
      "start": 367.759,
      "duration": 1.841,
      "text": "all the privacy risks of the users,",
      "timestamp": "06:07"
    },
    {
      "start": 369.6,
      "duration": 1.76,
      "text": "right? You're handling all the user data",
      "timestamp": "06:09"
    },
    {
      "start": 371.36,
      "duration": 2.8,
      "text": "as is this. Now the other alternative is",
      "timestamp": "06:11"
    },
    {
      "start": 374.16,
      "duration": 2.0,
      "text": "you just open source the model but the",
      "timestamp": "06:14"
    },
    {
      "start": 376.16,
      "duration": 1.44,
      "text": "problem is it's not sustainable, right?",
      "timestamp": "06:16"
    },
    {
      "start": 377.6,
      "duration": 1.439,
      "text": "You're not making any money. There's no",
      "timestamp": "06:17"
    },
    {
      "start": 379.039,
      "duration": 2.081,
      "text": "way to reinvest and train your model and",
      "timestamp": "06:19"
    },
    {
      "start": 381.12,
      "duration": 2.0,
      "text": "this is expensive process. So right now",
      "timestamp": "06:21"
    },
    {
      "start": 383.12,
      "duration": 1.919,
      "text": "we have like few companies developing",
      "timestamp": "06:23"
    },
    {
      "start": 385.039,
      "duration": 1.921,
      "text": "this a ton of people especially in",
      "timestamp": "06:25"
    },
    {
      "start": 386.96,
      "duration": 2.16,
      "text": "universities s sitting on sidelines",
      "timestamp": "06:26"
    },
    {
      "start": 389.12,
      "duration": 2.079,
      "text": "without access to compute. So we have",
      "timestamp": "06:29"
    },
    {
      "start": 391.199,
      "duration": 3.44,
      "text": "unsustainable model and a very complex",
      "timestamp": "06:31"
    },
    {
      "start": 394.639,
      "duration": 2.881,
      "text": "kind of logistics of compute and trust",
      "timestamp": "06:34"
    },
    {
      "start": 397.52,
      "duration": 2.64,
      "text": "uh on the closed source side",
      "timestamp": "06:37"
    },
    {
      "start": 400.16,
      "duration": 1.52,
      "text": "and so there's a lot of kind of",
      "timestamp": "06:40"
    },
    {
      "start": 401.68,
      "duration": 2.639,
      "text": "challenges there because again as a",
      "timestamp": "06:41"
    },
    {
      "start": 404.319,
      "duration": 2.641,
      "text": "company you don't trust external data",
      "timestamp": "06:44"
    },
    {
      "start": 406.96,
      "duration": 3.12,
      "text": "centers because your models your IP and",
      "timestamp": "06:46"
    },
    {
      "start": 410.08,
      "duration": 2.64,
      "text": "if this IP leaks then you effectively",
      "timestamp": "06:50"
    },
    {
      "start": 412.72,
      "duration": 3.36,
      "text": "lose your business and so you don't",
      "timestamp": "06:52"
    },
    {
      "start": 416.08,
      "duration": 1.92,
      "text": "trust with your model to some external",
      "timestamp": "06:56"
    },
    {
      "start": 418.0,
      "duration": 3.039,
      "text": "parties and so this ends up having this",
      "timestamp": "06:58"
    },
    {
      "start": 421.039,
      "duration": 2.081,
      "text": "kind of lots of problems. One is you",
      "timestamp": "07:01"
    },
    {
      "start": 423.12,
      "duration": 2.079,
      "text": "only trust a few data centers. Data",
      "timestamp": "07:03"
    },
    {
      "start": 425.199,
      "duration": 1.361,
      "text": "centers don't build that fast. They need",
      "timestamp": "07:05"
    },
    {
      "start": 426.56,
      "duration": 1.919,
      "text": "a lot of electricity. This is all in",
      "timestamp": "07:06"
    },
    {
      "start": 428.479,
      "duration": 2.0,
      "text": "kind of some close proximity. There's",
      "timestamp": "07:08"
    },
    {
      "start": 430.479,
      "duration": 2.16,
      "text": "like few cities uh kind of in regions in",
      "timestamp": "07:10"
    },
    {
      "start": 432.639,
      "duration": 1.921,
      "text": "US where right now this is buildout",
      "timestamp": "07:12"
    },
    {
      "start": 434.56,
      "duration": 3.359,
      "text": "happening. Um even though there's again",
      "timestamp": "07:14"
    },
    {
      "start": 437.919,
      "duration": 1.921,
      "text": "lots and lots of space with electricity",
      "timestamp": "07:17"
    },
    {
      "start": 439.84,
      "duration": 2.799,
      "text": "around the world. Uh which also leads to",
      "timestamp": "07:19"
    },
    {
      "start": 442.639,
      "duration": 2.321,
      "text": "latency. Right? If I'm sitting in Japan",
      "timestamp": "07:22"
    },
    {
      "start": 444.96,
      "duration": 2.239,
      "text": "and I'm using chat GPT, I need you know",
      "timestamp": "07:24"
    },
    {
      "start": 447.199,
      "duration": 4.72,
      "text": "round trips to Texas. you have um data",
      "timestamp": "07:27"
    },
    {
      "start": 451.919,
      "duration": 3.12,
      "text": "that you know gets uploaded and you know",
      "timestamp": "07:31"
    },
    {
      "start": 455.039,
      "duration": 1.6,
      "text": "there's been stories of for example",
      "timestamp": "07:35"
    },
    {
      "start": 456.639,
      "duration": 2.56,
      "text": "Samsung their data got leaked to uh",
      "timestamp": "07:36"
    },
    {
      "start": 459.199,
      "duration": 2.321,
      "text": "their competitor through openAI because",
      "timestamp": "07:39"
    },
    {
      "start": 461.52,
      "duration": 2.88,
      "text": "they were just using uh you know copilot",
      "timestamp": "07:41"
    },
    {
      "start": 464.4,
      "duration": 1.76,
      "text": "style product and their code ends up",
      "timestamp": "07:44"
    },
    {
      "start": 466.16,
      "duration": 2.479,
      "text": "being in training data for uh openi",
      "timestamp": "07:46"
    },
    {
      "start": 468.639,
      "duration": 3.12,
      "text": "model you have so this goes to you know",
      "timestamp": "07:48"
    },
    {
      "start": 471.759,
      "duration": 1.84,
      "text": "general corporate security especially if",
      "timestamp": "07:51"
    },
    {
      "start": 473.599,
      "duration": 1.6,
      "text": "you're handling users data this is even",
      "timestamp": "07:53"
    },
    {
      "start": 475.199,
      "duration": 1.68,
      "text": "more private right a lot of legal firms",
      "timestamp": "07:55"
    },
    {
      "start": 476.879,
      "duration": 2.081,
      "text": "financial firms are not allowing to to",
      "timestamp": "07:56"
    },
    {
      "start": 478.96,
      "duration": 3.04,
      "text": "use AI on user data because they're",
      "timestamp": "07:58"
    },
    {
      "start": 482.0,
      "duration": 2.24,
      "text": "afraid that this is gonna leak. And this",
      "timestamp": "08:02"
    },
    {
      "start": 484.24,
      "duration": 2.079,
      "text": "a sovereignty question right at the end",
      "timestamp": "08:04"
    },
    {
      "start": 486.319,
      "duration": 2.801,
      "text": "if I'm a country and I'm using a",
      "timestamp": "08:06"
    },
    {
      "start": 489.12,
      "duration": 2.88,
      "text": "centralized provider of the models from",
      "timestamp": "08:09"
    },
    {
      "start": 492.0,
      "duration": 2.16,
      "text": "another country that country effectively",
      "timestamp": "08:12"
    },
    {
      "start": 494.16,
      "duration": 1.84,
      "text": "have more power over me especially when",
      "timestamp": "08:14"
    },
    {
      "start": 496.0,
      "duration": 2.96,
      "text": "the AI starts to become really big",
      "timestamp": "08:16"
    },
    {
      "start": 498.96,
      "duration": 1.679,
      "text": "contributor to GDP big contributor to",
      "timestamp": "08:18"
    },
    {
      "start": 500.639,
      "duration": 1.921,
      "text": "automation big contributor to decision-",
      "timestamp": "08:20"
    },
    {
      "start": 502.56,
      "duration": 2.639,
      "text": "making of the country. So all of the",
      "timestamp": "08:22"
    },
    {
      "start": 505.199,
      "duration": 2.481,
      "text": "challenges now on top of this there's",
      "timestamp": "08:25"
    },
    {
      "start": 507.68,
      "duration": 1.44,
      "text": "kind of this more fundamental safety",
      "timestamp": "08:27"
    },
    {
      "start": 509.12,
      "duration": 1.04,
      "text": "challenge right there's a lot of",
      "timestamp": "08:29"
    },
    {
      "start": 510.16,
      "duration": 2.879,
      "text": "conversations about is AI safe uh how do",
      "timestamp": "08:30"
    },
    {
      "start": 513.039,
      "duration": 2.479,
      "text": "we ensure it is",
      "timestamp": "08:33"
    },
    {
      "start": 515.519,
      "duration": 2.241,
      "text": "and uh kind of there's always a reason",
      "timestamp": "08:35"
    },
    {
      "start": 517.76,
      "duration": 1.199,
      "text": "oh we're not going to open source our",
      "timestamp": "08:37"
    },
    {
      "start": 518.959,
      "duration": 2.801,
      "text": "model because it's unsafe and then",
      "timestamp": "08:38"
    },
    {
      "start": 521.76,
      "duration": 2.399,
      "text": "people get you know open weights model",
      "timestamp": "08:41"
    },
    {
      "start": 524.159,
      "duration": 3.12,
      "text": "and use it uh but generally the problem",
      "timestamp": "08:44"
    },
    {
      "start": 527.279,
      "duration": 2.321,
      "text": "is the safety is applied very unevenly",
      "timestamp": "08:47"
    },
    {
      "start": 529.6,
      "duration": 2.16,
      "text": "right we don't have kind of a universal",
      "timestamp": "08:49"
    },
    {
      "start": 531.76,
      "duration": 2.24,
      "text": "way to apply safety rules across all",
      "timestamp": "08:51"
    },
    {
      "start": 534.0,
      "duration": 1.76,
      "text": "models that and how people participate",
      "timestamp": "08:54"
    },
    {
      "start": 535.76,
      "duration": 2.8,
      "text": "with them. So that's why we formulated a",
      "timestamp": "08:55"
    },
    {
      "start": 538.56,
      "duration": 2.959,
      "text": "new way new uh vision called user on AI.",
      "timestamp": "08:58"
    },
    {
      "start": 541.519,
      "duration": 2.081,
      "text": "It's approach where AI is optimized for",
      "timestamp": "09:01"
    },
    {
      "start": 543.6,
      "duration": 2.08,
      "text": "users well-being and economic success",
      "timestamp": "09:03"
    },
    {
      "start": 545.68,
      "duration": 2.48,
      "text": "not corporate profits and it's built on",
      "timestamp": "09:05"
    },
    {
      "start": 548.16,
      "duration": 2.08,
      "text": "top of you know all of the kind of",
      "timestamp": "09:08"
    },
    {
      "start": 550.24,
      "duration": 2.88,
      "text": "approaches we've built in web 3. So what",
      "timestamp": "09:10"
    },
    {
      "start": 553.12,
      "duration": 2.0,
      "text": "we want to make sure is everyone has",
      "timestamp": "09:13"
    },
    {
      "start": 555.12,
      "duration": 2.8,
      "text": "access equal access to the models while",
      "timestamp": "09:15"
    },
    {
      "start": 557.92,
      "duration": 2.16,
      "text": "the safety applied equally as well kind",
      "timestamp": "09:17"
    },
    {
      "start": 560.08,
      "duration": 1.84,
      "text": "of safety constraints right nobody",
      "timestamp": "09:20"
    },
    {
      "start": 561.92,
      "duration": 1.359,
      "text": "should be able to use it to design",
      "timestamp": "09:21"
    },
    {
      "start": 563.279,
      "duration": 1.761,
      "text": "nuclear weapon nobody should able to",
      "timestamp": "09:23"
    },
    {
      "start": 565.04,
      "duration": 3.04,
      "text": "design bioeapon um user data should be",
      "timestamp": "09:25"
    },
    {
      "start": 568.08,
      "duration": 2.08,
      "text": "preserved in private unless user wants",
      "timestamp": "09:28"
    },
    {
      "start": 570.16,
      "duration": 2.239,
      "text": "to contribute it to training in in",
      "timestamp": "09:30"
    },
    {
      "start": 572.399,
      "duration": 2.641,
      "text": "return for something so confidentiality",
      "timestamp": "09:32"
    },
    {
      "start": 575.04,
      "duration": 1.52,
      "text": "and permissionlessness is extremely",
      "timestamp": "09:35"
    },
    {
      "start": 576.56,
      "duration": 2.56,
      "text": "important we want to know how models",
      "timestamp": "09:36"
    },
    {
      "start": 579.12,
      "duration": 2.08,
      "text": "trained again right now even the",
      "timestamp": "09:39"
    },
    {
      "start": 581.2,
      "duration": 1.28,
      "text": "so-called open source models are",
      "timestamp": "09:41"
    },
    {
      "start": 582.48,
      "duration": 1.52,
      "text": "actually not open source. They're open",
      "timestamp": "09:42"
    },
    {
      "start": 584.0,
      "duration": 1.44,
      "text": "weights. We don't actually know what",
      "timestamp": "09:44"
    },
    {
      "start": 585.44,
      "duration": 1.519,
      "text": "went into them. And if you don't know",
      "timestamp": "09:45"
    },
    {
      "start": 586.959,
      "duration": 1.841,
      "text": "what went into them, you don't know what",
      "timestamp": "09:46"
    },
    {
      "start": 588.8,
      "duration": 2.32,
      "text": "actually bias this model has, right? Is",
      "timestamp": "09:48"
    },
    {
      "start": 591.12,
      "duration": 2.8,
      "text": "it leaning right or left in US? Is this",
      "timestamp": "09:51"
    },
    {
      "start": 593.92,
      "duration": 2.4,
      "text": "more pro, you know, some religion? We",
      "timestamp": "09:53"
    },
    {
      "start": 596.32,
      "duration": 2.16,
      "text": "don't know it. You also don't know if",
      "timestamp": "09:56"
    },
    {
      "start": 598.48,
      "duration": 1.76,
      "text": "there is so-called sleeper agents.",
      "timestamp": "09:58"
    },
    {
      "start": 600.24,
      "duration": 1.76,
      "text": "Sleeper agents is a special way to train",
      "timestamp": "10:00"
    },
    {
      "start": 602.0,
      "duration": 2.72,
      "text": "a model where it will ex have a",
      "timestamp": "10:02"
    },
    {
      "start": 604.72,
      "duration": 1.2,
      "text": "different behavior under certain",
      "timestamp": "10:04"
    },
    {
      "start": 605.92,
      "duration": 2.4,
      "text": "conditions. For example, normally when",
      "timestamp": "10:05"
    },
    {
      "start": 608.32,
      "duration": 1.84,
      "text": "you look at the model, it does behave",
      "timestamp": "10:08"
    },
    {
      "start": 610.16,
      "duration": 2.48,
      "text": "normally, but when you're using it to",
      "timestamp": "10:10"
    },
    {
      "start": 612.64,
      "duration": 1.68,
      "text": "build production software, it will",
      "timestamp": "10:12"
    },
    {
      "start": 614.32,
      "duration": 1.759,
      "text": "actually import some malicious library",
      "timestamp": "10:14"
    },
    {
      "start": 616.079,
      "duration": 2.0,
      "text": "and effectively infect your production",
      "timestamp": "10:16"
    },
    {
      "start": 618.079,
      "duration": 2.561,
      "text": "system. So you want to make sure that",
      "timestamp": "10:18"
    },
    {
      "start": 620.64,
      "duration": 1.6,
      "text": "you know what training data went in",
      "timestamp": "10:20"
    },
    {
      "start": 622.24,
      "duration": 2.48,
      "text": "verifiably. And so you want to know",
      "timestamp": "10:22"
    },
    {
      "start": 624.72,
      "duration": 1.52,
      "text": "effectively the whole provenence of",
      "timestamp": "10:24"
    },
    {
      "start": 626.24,
      "duration": 2.88,
      "text": "training of this model.",
      "timestamp": "10:26"
    },
    {
      "start": 629.12,
      "duration": 2.56,
      "text": "Now, more importantly, this needs to be",
      "timestamp": "10:29"
    },
    {
      "start": 631.68,
      "duration": 1.839,
      "text": "a state-of-the-art model, right? Nobody",
      "timestamp": "10:31"
    },
    {
      "start": 633.519,
      "duration": 3.281,
      "text": "will use some meh model. Uh it people",
      "timestamp": "10:33"
    },
    {
      "start": 636.8,
      "duration": 3.36,
      "text": "will prefer better product over you know",
      "timestamp": "10:36"
    },
    {
      "start": 640.16,
      "duration": 2.0,
      "text": "values. That's always been the case.",
      "timestamp": "10:40"
    },
    {
      "start": 642.16,
      "duration": 2.88,
      "text": "That's why crypto been so slow to adopt.",
      "timestamp": "10:42"
    },
    {
      "start": 645.04,
      "duration": 3.12,
      "text": "Now uh you want to make sure that this",
      "timestamp": "10:45"
    },
    {
      "start": 648.16,
      "duration": 1.76,
      "text": "state-of-the-art model has verifiability",
      "timestamp": "10:48"
    },
    {
      "start": 649.92,
      "duration": 2.159,
      "text": "of data and model training. So we need a",
      "timestamp": "10:49"
    },
    {
      "start": 652.079,
      "duration": 2.241,
      "text": "whole setup for that. And we need",
      "timestamp": "10:52"
    },
    {
      "start": 654.32,
      "duration": 1.6,
      "text": "continuous research and improvements,",
      "timestamp": "10:54"
    },
    {
      "start": 655.92,
      "duration": 1.84,
      "text": "right? Like it cannot be just like hey",
      "timestamp": "10:55"
    },
    {
      "start": 657.76,
      "duration": 1.6,
      "text": "cool we build one state of the model and",
      "timestamp": "10:57"
    },
    {
      "start": 659.36,
      "duration": 1.919,
      "text": "we're done. It needs to be a continuous",
      "timestamp": "10:59"
    },
    {
      "start": 661.279,
      "duration": 1.841,
      "text": "process of getting state-of-the-art",
      "timestamp": "11:01"
    },
    {
      "start": 663.12,
      "duration": 3.04,
      "text": "model and research. There's also a very",
      "timestamp": "11:03"
    },
    {
      "start": 666.16,
      "duration": 2.72,
      "text": "uh you know important aspect that if you",
      "timestamp": "11:06"
    },
    {
      "start": 668.88,
      "duration": 2.079,
      "text": "completely open source that means that",
      "timestamp": "11:08"
    },
    {
      "start": 670.959,
      "duration": 1.921,
      "text": "any other closed source lab can take it",
      "timestamp": "11:10"
    },
    {
      "start": 672.88,
      "duration": 2.24,
      "text": "open source and build on top of it and",
      "timestamp": "11:12"
    },
    {
      "start": 675.12,
      "duration": 2.159,
      "text": "so you cannot be at state-of-the-art if",
      "timestamp": "11:15"
    },
    {
      "start": 677.279,
      "duration": 1.521,
      "text": "you're completely open source. So you",
      "timestamp": "11:17"
    },
    {
      "start": 678.8,
      "duration": 1.92,
      "text": "need to create some asymmetry of",
      "timestamp": "11:18"
    },
    {
      "start": 680.72,
      "duration": 3.28,
      "text": "information for this to be really true.",
      "timestamp": "11:20"
    },
    {
      "start": 684.0,
      "duration": 1.76,
      "text": "So we introduced a solution called",
      "timestamp": "11:24"
    },
    {
      "start": 685.76,
      "duration": 1.44,
      "text": "decentralized confidential machine",
      "timestamp": "11:25"
    },
    {
      "start": 687.2,
      "duration": 2.48,
      "text": "learning at NVIDIA GTC. It's really",
      "timestamp": "11:27"
    },
    {
      "start": 689.68,
      "duration": 3.04,
      "text": "about creating a platform for this kind",
      "timestamp": "11:29"
    },
    {
      "start": 692.72,
      "duration": 3.28,
      "text": "of user own AI uh and the road map how",
      "timestamp": "11:32"
    },
    {
      "start": 696.0,
      "duration": 2.88,
      "text": "we can get there. So it's it's really",
      "timestamp": "11:36"
    },
    {
      "start": 698.88,
      "duration": 1.76,
      "text": "about creating verifiable and",
      "timestamp": "11:38"
    },
    {
      "start": 700.64,
      "duration": 2.24,
      "text": "confidential computing that can be run",
      "timestamp": "11:40"
    },
    {
      "start": 702.88,
      "duration": 1.84,
      "text": "anywhere in the world. Nodes can join",
      "timestamp": "11:42"
    },
    {
      "start": 704.72,
      "duration": 3.28,
      "text": "it. Uh that allows to monetize models as",
      "timestamp": "11:44"
    },
    {
      "start": 708.0,
      "duration": 2.88,
      "text": "well as train uh fine-tune models in a",
      "timestamp": "11:48"
    },
    {
      "start": 710.88,
      "duration": 2.16,
      "text": "verifiable way. and it offers a safety",
      "timestamp": "11:50"
    },
    {
      "start": 713.04,
      "duration": 2.239,
      "text": "tooling that is kind of applied to",
      "timestamp": "11:53"
    },
    {
      "start": 715.279,
      "duration": 2.24,
      "text": "everyone uh and nobody can get",
      "timestamp": "11:55"
    },
    {
      "start": 717.519,
      "duration": 2.641,
      "text": "privileged access to the models. How",
      "timestamp": "11:57"
    },
    {
      "start": 720.16,
      "duration": 1.84,
      "text": "does this work? Well, first it's built",
      "timestamp": "12:00"
    },
    {
      "start": 722.0,
      "duration": 1.6,
      "text": "on top of trusted execution",
      "timestamp": "12:02"
    },
    {
      "start": 723.6,
      "duration": 2.32,
      "text": "environments. So, as of about a year",
      "timestamp": "12:03"
    },
    {
      "start": 725.92,
      "duration": 2.56,
      "text": "ago, uh Nvidia has enabled a",
      "timestamp": "12:05"
    },
    {
      "start": 728.48,
      "duration": 1.44,
      "text": "confidential computing mode on their",
      "timestamp": "12:08"
    },
    {
      "start": 729.92,
      "duration": 4.159,
      "text": "GPUs that works with Intel, AMD and ARM",
      "timestamp": "12:09"
    },
    {
      "start": 734.079,
      "duration": 4.721,
      "text": "uh uh kind of T environments. And so uh",
      "timestamp": "12:14"
    },
    {
      "start": 738.8,
      "duration": 2.64,
      "text": "which themselves have improved at least",
      "timestamp": "12:18"
    },
    {
      "start": 741.44,
      "duration": 3.12,
      "text": "Intels and ARMs have improved uh since",
      "timestamp": "12:21"
    },
    {
      "start": 744.56,
      "duration": 3.12,
      "text": "the past. And this environment itself",
      "timestamp": "12:24"
    },
    {
      "start": 747.68,
      "duration": 2.959,
      "text": "allows to effectively run computing in a",
      "timestamp": "12:27"
    },
    {
      "start": 750.639,
      "duration": 2.64,
      "text": "vault right in such a way that whoever",
      "timestamp": "12:30"
    },
    {
      "start": 753.279,
      "duration": 1.841,
      "text": "even owns the computer is not able to",
      "timestamp": "12:33"
    },
    {
      "start": 755.12,
      "duration": 3.6,
      "text": "access it uh directly. It now has GPU",
      "timestamp": "12:35"
    },
    {
      "start": 758.72,
      "duration": 1.679,
      "text": "enabled and interestingly it has this",
      "timestamp": "12:38"
    },
    {
      "start": 760.399,
      "duration": 2.24,
      "text": "verifiableility property that this code",
      "timestamp": "12:40"
    },
    {
      "start": 762.639,
      "duration": 2.161,
      "text": "is running on this computer. It ran this",
      "timestamp": "12:42"
    },
    {
      "start": 764.8,
      "duration": 2.64,
      "text": "data and only this compute was run on",
      "timestamp": "12:44"
    },
    {
      "start": 767.44,
      "duration": 1.839,
      "text": "this data right meaning you can",
      "timestamp": "12:47"
    },
    {
      "start": 769.279,
      "duration": 2.641,
      "text": "guarantee that after the running on my",
      "timestamp": "12:49"
    },
    {
      "start": 771.92,
      "duration": 2.24,
      "text": "data it will delete it and will never",
      "timestamp": "12:51"
    },
    {
      "start": 774.16,
      "duration": 2.479,
      "text": "you know store it or use it again. So",
      "timestamp": "12:54"
    },
    {
      "start": 776.639,
      "duration": 2.081,
      "text": "you have this interesting privacy",
      "timestamp": "12:56"
    },
    {
      "start": 778.72,
      "duration": 1.52,
      "text": "confidentiality properties that you",
      "timestamp": "12:58"
    },
    {
      "start": 780.24,
      "duration": 2.159,
      "text": "actually don't get even from some of the",
      "timestamp": "13:00"
    },
    {
      "start": 782.399,
      "duration": 2.401,
      "text": "FHE solutions and definitely don't get",
      "timestamp": "13:02"
    },
    {
      "start": 784.8,
      "duration": 2.479,
      "text": "uh with ZK and other kind of traditional",
      "timestamp": "13:04"
    },
    {
      "start": 787.279,
      "duration": 3.68,
      "text": "methods. Now we all put it together into",
      "timestamp": "13:07"
    },
    {
      "start": 790.959,
      "duration": 1.841,
      "text": "what we kind of this decentralized",
      "timestamp": "13:10"
    },
    {
      "start": 792.8,
      "duration": 2.4,
      "text": "machine learning cloud where a user",
      "timestamp": "13:12"
    },
    {
      "start": 795.2,
      "duration": 1.759,
      "text": "effectively",
      "timestamp": "13:15"
    },
    {
      "start": 796.959,
      "duration": 2.32,
      "text": "uh paying on chain uh for using the",
      "timestamp": "13:16"
    },
    {
      "start": 799.279,
      "duration": 2.641,
      "text": "models and then can connect directly to",
      "timestamp": "13:19"
    },
    {
      "start": 801.92,
      "duration": 2.159,
      "text": "the data to the compute providers and",
      "timestamp": "13:21"
    },
    {
      "start": 804.079,
      "duration": 2.32,
      "text": "run inside the confidential VM different",
      "timestamp": "13:24"
    },
    {
      "start": 806.399,
      "duration": 2.081,
      "text": "models and different agents and then",
      "timestamp": "13:26"
    },
    {
      "start": 808.48,
      "duration": 1.76,
      "text": "there's a lot of pieces that need to be",
      "timestamp": "13:28"
    },
    {
      "start": 810.24,
      "duration": 2.0,
      "text": "done to kind of tie it all together to",
      "timestamp": "13:30"
    },
    {
      "start": 812.24,
      "duration": 2.32,
      "text": "ensure you know livveness of computers",
      "timestamp": "13:32"
    },
    {
      "start": 814.56,
      "duration": 2.88,
      "text": "to ensure kind of this model marketplace",
      "timestamp": "13:34"
    },
    {
      "start": 817.44,
      "duration": 2.32,
      "text": "uh But it provides us with this",
      "timestamp": "13:37"
    },
    {
      "start": 819.76,
      "duration": 3.12,
      "text": "fundamental building blocks for bu kind",
      "timestamp": "13:39"
    },
    {
      "start": 822.88,
      "duration": 2.32,
      "text": "of running and building user own AI. So",
      "timestamp": "13:42"
    },
    {
      "start": 825.2,
      "duration": 1.68,
      "text": "we have a number of teams actually",
      "timestamp": "13:45"
    },
    {
      "start": 826.88,
      "duration": 1.84,
      "text": "building this together. This is not kind",
      "timestamp": "13:46"
    },
    {
      "start": 828.72,
      "duration": 2.559,
      "text": "of a single team effort in a you know",
      "timestamp": "13:48"
    },
    {
      "start": 831.279,
      "duration": 2.8,
      "text": "decentralization spirit. And so uh we",
      "timestamp": "13:51"
    },
    {
      "start": 834.079,
      "duration": 1.921,
      "text": "have you know on the near one side the",
      "timestamp": "13:54"
    },
    {
      "start": 836.0,
      "duration": 1.519,
      "text": "team that builds near protocol they're",
      "timestamp": "13:56"
    },
    {
      "start": 837.519,
      "duration": 3.041,
      "text": "doing a lot of the uh key management and",
      "timestamp": "13:57"
    },
    {
      "start": 840.56,
      "duration": 2.56,
      "text": "uh kind of uh encryption decryption. We",
      "timestamp": "14:00"
    },
    {
      "start": 843.12,
      "duration": 2.48,
      "text": "have proof of response done uh to ensure",
      "timestamp": "14:03"
    },
    {
      "start": 845.6,
      "duration": 1.76,
      "text": "the livveness of nodes. We have Fala",
      "timestamp": "14:05"
    },
    {
      "start": 847.36,
      "duration": 1.52,
      "text": "doing trust execution environments and",
      "timestamp": "14:07"
    },
    {
      "start": 848.88,
      "duration": 1.92,
      "text": "consension inference. We also have teams",
      "timestamp": "14:08"
    },
    {
      "start": 850.8,
      "duration": 2.08,
      "text": "building on top of it everything from",
      "timestamp": "14:10"
    },
    {
      "start": 852.88,
      "duration": 1.68,
      "text": "model training to benchmarking to",
      "timestamp": "14:12"
    },
    {
      "start": 854.56,
      "duration": 3.68,
      "text": "hosting to rack to private memory uh and",
      "timestamp": "14:14"
    },
    {
      "start": 858.24,
      "duration": 1.52,
      "text": "and",
      "timestamp": "14:18"
    },
    {
      "start": 859.76,
      "duration": 1.6,
      "text": "various data synthetic data and human",
      "timestamp": "14:19"
    },
    {
      "start": 861.36,
      "duration": 1.76,
      "text": "label data. And this is not a full list",
      "timestamp": "14:21"
    },
    {
      "start": 863.12,
      "duration": 1.279,
      "text": "but this is kind of just to show you",
      "timestamp": "14:23"
    },
    {
      "start": 864.399,
      "duration": 1.921,
      "text": "that this is a whole stack of teams",
      "timestamp": "14:24"
    },
    {
      "start": 866.32,
      "duration": 2.4,
      "text": "working together.",
      "timestamp": "14:26"
    },
    {
      "start": 868.72,
      "duration": 2.559,
      "text": "Now this actually is about",
      "timestamp": "14:28"
    },
    {
      "start": 871.279,
      "duration": 2.0,
      "text": "deconstructing the AI lab right? If you",
      "timestamp": "14:31"
    },
    {
      "start": 873.279,
      "duration": 1.68,
      "text": "go into one of the centralized labs and",
      "timestamp": "14:33"
    },
    {
      "start": 874.959,
      "duration": 1.281,
      "text": "you open it up, right, there's actually",
      "timestamp": "14:34"
    },
    {
      "start": 876.24,
      "duration": 1.839,
      "text": "a number of teams that working together",
      "timestamp": "14:36"
    },
    {
      "start": 878.079,
      "duration": 1.681,
      "text": "and they're creating a flywheel of",
      "timestamp": "14:38"
    },
    {
      "start": 879.76,
      "duration": 2.56,
      "text": "research that's happening inside, right?",
      "timestamp": "14:39"
    },
    {
      "start": 882.32,
      "duration": 1.6,
      "text": "And so it's important to kind of",
      "timestamp": "14:42"
    },
    {
      "start": 883.92,
      "duration": 1.599,
      "text": "replicate this process in a",
      "timestamp": "14:43"
    },
    {
      "start": 885.519,
      "duration": 3.201,
      "text": "decentralized way, opening up ability to",
      "timestamp": "14:45"
    },
    {
      "start": 888.72,
      "duration": 1.919,
      "text": "actually source talent from everywhere",
      "timestamp": "14:48"
    },
    {
      "start": 890.639,
      "duration": 1.361,
      "text": "in the world and give them opportunity",
      "timestamp": "14:50"
    },
    {
      "start": 892.0,
      "duration": 2.8,
      "text": "to participate. Uh so it starts with",
      "timestamp": "14:52"
    },
    {
      "start": 894.8,
      "duration": 1.76,
      "text": "data, right? You want data acquisition,",
      "timestamp": "14:54"
    },
    {
      "start": 896.56,
      "duration": 3.68,
      "text": "ability to find better data, uh clean it",
      "timestamp": "14:56"
    },
    {
      "start": 900.24,
      "duration": 1.76,
      "text": "and improve it, right? There's a number",
      "timestamp": "15:00"
    },
    {
      "start": 902.0,
      "duration": 2.16,
      "text": "of techniques and hacks to improve this",
      "timestamp": "15:02"
    },
    {
      "start": 904.16,
      "duration": 2.56,
      "text": "as well as using kind of a lower grade",
      "timestamp": "15:04"
    },
    {
      "start": 906.72,
      "duration": 2.72,
      "text": "models to uh refine data. There's a",
      "timestamp": "15:06"
    },
    {
      "start": 909.44,
      "duration": 2.56,
      "text": "synthetic data proc kind of reprocessing",
      "timestamp": "15:09"
    },
    {
      "start": 912.0,
      "duration": 1.6,
      "text": "as well as user contributed data. If",
      "timestamp": "15:12"
    },
    {
      "start": 913.6,
      "duration": 1.359,
      "text": "users are willing to contribute their",
      "timestamp": "15:13"
    },
    {
      "start": 914.959,
      "duration": 2.481,
      "text": "data in various ways which here we can",
      "timestamp": "15:14"
    },
    {
      "start": 917.44,
      "duration": 2.079,
      "text": "actually guarantee that nobody no single",
      "timestamp": "15:17"
    },
    {
      "start": 919.519,
      "duration": 2.0,
      "text": "person can actually sees the data. It",
      "timestamp": "15:19"
    },
    {
      "start": 921.519,
      "duration": 1.76,
      "text": "will be cleaned in a very specific way",
      "timestamp": "15:21"
    },
    {
      "start": 923.279,
      "duration": 1.92,
      "text": "and then it'll be used for training",
      "timestamp": "15:23"
    },
    {
      "start": 925.199,
      "duration": 1.681,
      "text": "again without revealing the individual",
      "timestamp": "15:25"
    },
    {
      "start": 926.88,
      "duration": 3.199,
      "text": "data. Um then we go to pre-training step",
      "timestamp": "15:26"
    },
    {
      "start": 930.079,
      "duration": 2.161,
      "text": "right this is kind of the foundational",
      "timestamp": "15:30"
    },
    {
      "start": 932.24,
      "duration": 2.64,
      "text": "part. This is about ali algorithmical",
      "timestamp": "15:32"
    },
    {
      "start": 934.88,
      "duration": 1.519,
      "text": "improvements improvements to the",
      "timestamp": "15:34"
    },
    {
      "start": 936.399,
      "duration": 1.761,
      "text": "training process itself. How do you do",
      "timestamp": "15:36"
    },
    {
      "start": 938.16,
      "duration": 1.919,
      "text": "curriculum learning? How do you improve",
      "timestamp": "15:38"
    },
    {
      "start": 940.079,
      "duration": 2.641,
      "text": "you know uh ability model to learn from",
      "timestamp": "15:40"
    },
    {
      "start": 942.72,
      "duration": 3.679,
      "text": "less data from seeing less examples and",
      "timestamp": "15:42"
    },
    {
      "start": 946.399,
      "duration": 2.0,
      "text": "then obviously research on how do we do",
      "timestamp": "15:46"
    },
    {
      "start": 948.399,
      "duration": 1.601,
      "text": "it across a distributed and",
      "timestamp": "15:48"
    },
    {
      "start": 950.0,
      "duration": 1.44,
      "text": "decentralized cluster. Right? There's a",
      "timestamp": "15:50"
    },
    {
      "start": 951.44,
      "duration": 1.519,
      "text": "few teams that have been already working",
      "timestamp": "15:51"
    },
    {
      "start": 952.959,
      "duration": 3.201,
      "text": "on this and making good progress. Um and",
      "timestamp": "15:52"
    },
    {
      "start": 956.16,
      "duration": 2.0,
      "text": "decentralized training is kind of this",
      "timestamp": "15:56"
    },
    {
      "start": 958.16,
      "duration": 1.84,
      "text": "uh I would say holy grail that people",
      "timestamp": "15:58"
    },
    {
      "start": 960.0,
      "duration": 2.56,
      "text": "talk about because it would allow us to",
      "timestamp": "16:00"
    },
    {
      "start": 962.56,
      "duration": 1.76,
      "text": "actually replicate the whole process",
      "timestamp": "16:02"
    },
    {
      "start": 964.32,
      "duration": 1.36,
      "text": "right if we can do decentralized",
      "timestamp": "16:04"
    },
    {
      "start": 965.68,
      "duration": 2.959,
      "text": "training on DCML that means we have this",
      "timestamp": "16:05"
    },
    {
      "start": 968.639,
      "duration": 1.921,
      "text": "verifiability of where data came from",
      "timestamp": "16:08"
    },
    {
      "start": 970.56,
      "duration": 2.959,
      "text": "how it was processed and then this model",
      "timestamp": "16:10"
    },
    {
      "start": 973.519,
      "duration": 2.801,
      "text": "artifact effectively came from this data",
      "timestamp": "16:13"
    },
    {
      "start": 976.32,
      "duration": 2.24,
      "text": "now you can actually keep the model",
      "timestamp": "16:16"
    },
    {
      "start": 978.56,
      "duration": 1.839,
      "text": "artifact encrypted right the weights of",
      "timestamp": "16:18"
    },
    {
      "start": 980.399,
      "duration": 1.761,
      "text": "the model doesn't need to be open so",
      "timestamp": "16:20"
    },
    {
      "start": 982.16,
      "duration": 1.84,
      "text": "open to everyone they can be encrypted",
      "timestamp": "16:22"
    },
    {
      "start": 984.0,
      "duration": 1.68,
      "text": "and available in this decentralized",
      "timestamp": "16:24"
    },
    {
      "start": 985.68,
      "duration": 1.839,
      "text": "network. This actually has all the",
      "timestamp": "16:25"
    },
    {
      "start": 987.519,
      "duration": 2.24,
      "text": "properties of open weights. You can use",
      "timestamp": "16:27"
    },
    {
      "start": 989.759,
      "duration": 1.44,
      "text": "it permissionlessly. It's available",
      "timestamp": "16:29"
    },
    {
      "start": 991.199,
      "duration": 1.44,
      "text": "everywhere. You can use it even on your",
      "timestamp": "16:31"
    },
    {
      "start": 992.639,
      "duration": 3.12,
      "text": "own hardware. Uh but it's monetizable",
      "timestamp": "16:32"
    },
    {
      "start": 995.759,
      "duration": 2.161,
      "text": "now. You can actually charge. So even if",
      "timestamp": "16:35"
    },
    {
      "start": 997.92,
      "duration": 1.52,
      "text": "you are like you know individual",
      "timestamp": "16:37"
    },
    {
      "start": 999.44,
      "duration": 1.68,
      "text": "developer who just trained a model, you",
      "timestamp": "16:39"
    },
    {
      "start": 1001.12,
      "duration": 1.92,
      "text": "can now charge for using this if it's a",
      "timestamp": "16:41"
    },
    {
      "start": 1003.04,
      "duration": 1.84,
      "text": "good model. And so this solves really",
      "timestamp": "16:43"
    },
    {
      "start": 1004.88,
      "duration": 2.24,
      "text": "this fundamental problem that kind of",
      "timestamp": "16:44"
    },
    {
      "start": 1007.12,
      "duration": 2.079,
      "text": "open source is not monetizable. We're",
      "timestamp": "16:47"
    },
    {
      "start": 1009.199,
      "duration": 2.161,
      "text": "actually kind of changing the game to",
      "timestamp": "16:49"
    },
    {
      "start": 1011.36,
      "duration": 2.0,
      "text": "have you know encrypted models with open",
      "timestamp": "16:51"
    },
    {
      "start": 1013.36,
      "duration": 2.96,
      "text": "source to be monetizable and at the same",
      "timestamp": "16:53"
    },
    {
      "start": 1016.32,
      "duration": 3.04,
      "text": "time have all the properties",
      "timestamp": "16:56"
    },
    {
      "start": 1019.36,
      "duration": 2.8,
      "text": "and so kind of if you simplify there's",
      "timestamp": "16:59"
    },
    {
      "start": 1022.16,
      "duration": 2.159,
      "text": "effect three steps. Step one create a",
      "timestamp": "17:02"
    },
    {
      "start": 1024.319,
      "duration": 1.921,
      "text": "market for inference where you can serve",
      "timestamp": "17:04"
    },
    {
      "start": 1026.24,
      "duration": 2.558,
      "text": "this encrypted models so anyone can",
      "timestamp": "17:06"
    },
    {
      "start": 1028.799,
      "duration": 3.201,
      "text": "participate upload their models and uh",
      "timestamp": "17:08"
    },
    {
      "start": 1032.0,
      "duration": 2.88,
      "text": "uh serve it. uh this solves for this",
      "timestamp": "17:12"
    },
    {
      "start": 1034.88,
      "duration": 1.76,
      "text": "kind of trust problem between model",
      "timestamp": "17:14"
    },
    {
      "start": 1036.64,
      "duration": 2.48,
      "text": "providers and solves for privacy from",
      "timestamp": "17:16"
    },
    {
      "start": 1039.12,
      "duration": 3.6,
      "text": "companies and users who care.",
      "timestamp": "17:19"
    },
    {
      "start": 1042.72,
      "duration": 2.318,
      "text": "Then we can run benchmarks competitions",
      "timestamp": "17:22"
    },
    {
      "start": 1045.039,
      "duration": 2.639,
      "text": "for different aspects of model building.",
      "timestamp": "17:25"
    },
    {
      "start": 1047.679,
      "duration": 2.721,
      "text": "Refine data better, get uh you know get",
      "timestamp": "17:27"
    },
    {
      "start": 1050.4,
      "duration": 2.159,
      "text": "the reward, improve the model algorithm,",
      "timestamp": "17:30"
    },
    {
      "start": 1052.559,
      "duration": 2.24,
      "text": "improve the model training, get reward,",
      "timestamp": "17:32"
    },
    {
      "start": 1054.799,
      "duration": 1.521,
      "text": "run this continuous benchmark",
      "timestamp": "17:34"
    },
    {
      "start": 1056.32,
      "duration": 2.239,
      "text": "effectively as in you would run the",
      "timestamp": "17:36"
    },
    {
      "start": 1058.559,
      "duration": 2.721,
      "text": "teams internally with you know OKRs and",
      "timestamp": "17:38"
    },
    {
      "start": 1061.28,
      "duration": 3.2,
      "text": "uh bonuses on uh people actually coming",
      "timestamp": "17:41"
    },
    {
      "start": 1064.48,
      "duration": 1.92,
      "text": "up with new ideas.",
      "timestamp": "17:44"
    },
    {
      "start": 1066.4,
      "duration": 2.08,
      "text": "Step three, put it all together into you",
      "timestamp": "17:46"
    },
    {
      "start": 1068.48,
      "duration": 1.92,
      "text": "know training fine-tuning post-training",
      "timestamp": "17:48"
    },
    {
      "start": 1070.4,
      "duration": 3.04,
      "text": "process and actually deliver different",
      "timestamp": "17:50"
    },
    {
      "start": 1073.44,
      "duration": 1.52,
      "text": "specialized models for different use",
      "timestamp": "17:53"
    },
    {
      "start": 1074.96,
      "duration": 2.079,
      "text": "cases that people can use that are",
      "timestamp": "17:54"
    },
    {
      "start": 1077.039,
      "duration": 2.321,
      "text": "beating on this benchmarks. Uh and",
      "timestamp": "17:57"
    },
    {
      "start": 1079.36,
      "duration": 2.319,
      "text": "that's really all together this is how",
      "timestamp": "17:59"
    },
    {
      "start": 1081.679,
      "duration": 3.281,
      "text": "we build this userowned AI and this is",
      "timestamp": "18:01"
    },
    {
      "start": 1084.96,
      "duration": 2.079,
      "text": "what we believe is the way to actually",
      "timestamp": "18:04"
    },
    {
      "start": 1087.039,
      "duration": 2.561,
      "text": "ensure we're not going to end up in 1984",
      "timestamp": "18:07"
    },
    {
      "start": 1089.6,
      "duration": 3.36,
      "text": "you know big brother style world. So",
      "timestamp": "18:09"
    },
    {
      "start": 1092.96,
      "duration": 1.28,
      "text": "this is pretty much it. If you're",
      "timestamp": "18:12"
    },
    {
      "start": 1094.24,
      "duration": 1.679,
      "text": "interested to learn more, follow us on",
      "timestamp": "18:14"
    },
    {
      "start": 1095.919,
      "duration": 3.12,
      "text": "Twitter at near protocol at Elbugdragon.",
      "timestamp": "18:15"
    },
    {
      "start": 1099.039,
      "duration": 2.801,
      "text": "And uh thank you very much for coming.",
      "timestamp": "18:19"
    },
    {
      "start": 1101.84,
      "duration": 5.12,
      "text": "[Applause]",
      "timestamp": "18:21"
    },
    {
      "start": 1106.96,
      "duration": 2.0,
      "text": "Have time for one question, two",
      "timestamp": "18:26"
    },
    {
      "start": 1108.96,
      "duration": 3.0,
      "text": "questions.",
      "timestamp": "18:28"
    },
    {
      "start": 1124.0,
      "duration": 2.48,
      "text": "Hi, thank you. Very interesting. The",
      "timestamp": "18:44"
    },
    {
      "start": 1126.48,
      "duration": 3.68,
      "text": "question is the near AI which you're",
      "timestamp": "18:46"
    },
    {
      "start": 1130.16,
      "duration": 2.8,
      "text": "building can it be rolled out as a",
      "timestamp": "18:50"
    },
    {
      "start": 1132.96,
      "duration": 2.56,
      "text": "wallet itself so that the agent is a",
      "timestamp": "18:52"
    },
    {
      "start": 1135.52,
      "duration": 2.08,
      "text": "wallet?",
      "timestamp": "18:55"
    },
    {
      "start": 1137.6,
      "duration": 2.24,
      "text": "So uh there's a whole kind of this is",
      "timestamp": "18:57"
    },
    {
      "start": 1139.84,
      "duration": 1.6,
      "text": "this is really the infrastructure and",
      "timestamp": "18:59"
    },
    {
      "start": 1141.44,
      "duration": 1.52,
      "text": "foundational side. There's also the",
      "timestamp": "19:01"
    },
    {
      "start": 1142.96,
      "duration": 2.079,
      "text": "application side. So on application side",
      "timestamp": "19:02"
    },
    {
      "start": 1145.039,
      "duration": 3.681,
      "text": "the wallets you know your user wallet uh",
      "timestamp": "19:05"
    },
    {
      "start": 1148.72,
      "duration": 1.92,
      "text": "will have your private memory private",
      "timestamp": "19:08"
    },
    {
      "start": 1150.64,
      "duration": 2.399,
      "text": "data for AI. You can have agents running",
      "timestamp": "19:10"
    },
    {
      "start": 1153.039,
      "duration": 2.241,
      "text": "there on your behalf but you can also",
      "timestamp": "19:13"
    },
    {
      "start": 1155.28,
      "duration": 1.6,
      "text": "run autonomous agents and autonomous",
      "timestamp": "19:15"
    },
    {
      "start": 1156.88,
      "duration": 2.08,
      "text": "agents have their own wallet. They can",
      "timestamp": "19:16"
    },
    {
      "start": 1158.96,
      "duration": 1.52,
      "text": "enable and transact and you know through",
      "timestamp": "19:18"
    },
    {
      "start": 1160.48,
      "duration": 1.68,
      "text": "near chain signatures and intents they",
      "timestamp": "19:20"
    },
    {
      "start": 1162.16,
      "duration": 1.84,
      "text": "can transact everywhere. They can even",
      "timestamp": "19:22"
    },
    {
      "start": 1164.0,
      "duration": 2.24,
      "text": "start buying physical businesses hire",
      "timestamp": "19:24"
    },
    {
      "start": 1166.24,
      "duration": 1.679,
      "text": "people can do all those things but",
      "timestamp": "19:26"
    },
    {
      "start": 1167.919,
      "duration": 1.441,
      "text": "they're autonomous. So there's",
      "timestamp": "19:27"
    },
    {
      "start": 1169.36,
      "duration": 2.88,
      "text": "effectively a dichotomy between agents",
      "timestamp": "19:29"
    },
    {
      "start": 1172.24,
      "duration": 2.88,
      "text": "that work on behalf of people behalf of",
      "timestamp": "19:32"
    },
    {
      "start": 1175.12,
      "duration": 2.559,
      "text": "businesses and autonomous that run kind",
      "timestamp": "19:35"
    },
    {
      "start": 1177.679,
      "duration": 1.681,
      "text": "of themselves. Think of them as you know",
      "timestamp": "19:37"
    },
    {
      "start": 1179.36,
      "duration": 2.319,
      "text": "fully independent companies that may",
      "timestamp": "19:39"
    },
    {
      "start": 1181.679,
      "duration": 2.24,
      "text": "have shareholders through a token but",
      "timestamp": "19:41"
    },
    {
      "start": 1183.919,
      "duration": 2.961,
      "text": "effectively run themselves.",
      "timestamp": "19:43"
    },
    {
      "start": 1186.88,
      "duration": 2.0,
      "text": "Hi Pedro here. Thank thank you for the",
      "timestamp": "19:46"
    },
    {
      "start": 1188.88,
      "duration": 2.08,
      "text": "talk. Um I have a question related to",
      "timestamp": "19:48"
    },
    {
      "start": 1190.96,
      "duration": 3.36,
      "text": "the maturity of your project so far. uh",
      "timestamp": "19:50"
    },
    {
      "start": 1194.32,
      "duration": 2.96,
      "text": "spec specifically about the use of TE's",
      "timestamp": "19:54"
    },
    {
      "start": 1197.28,
      "duration": 3.04,
      "text": "and the GPU TE's. Are you guys already",
      "timestamp": "19:57"
    },
    {
      "start": 1200.32,
      "duration": 2.719,
      "text": "kind of using them heavily and do you",
      "timestamp": "20:00"
    },
    {
      "start": 1203.039,
      "duration": 2.721,
      "text": "have already kind of remote attestation",
      "timestamp": "20:03"
    },
    {
      "start": 1205.76,
      "duration": 2.0,
      "text": "figured out and how this integrates into",
      "timestamp": "20:05"
    },
    {
      "start": 1207.76,
      "duration": 4.24,
      "text": "your whole um ecosystem? Yeah. So, uh",
      "timestamp": "20:07"
    },
    {
      "start": 1212.0,
      "duration": 2.48,
      "text": "the T and confidential inference is live",
      "timestamp": "20:12"
    },
    {
      "start": 1214.48,
      "duration": 3.6,
      "text": "right now uh through follow and then uh",
      "timestamp": "20:14"
    },
    {
      "start": 1218.08,
      "duration": 2.16,
      "text": "what we're finishing right now is the",
      "timestamp": "20:18"
    },
    {
      "start": 1220.24,
      "duration": 2.799,
      "text": "key management for the specifically",
      "timestamp": "20:20"
    },
    {
      "start": 1223.039,
      "duration": 1.52,
      "text": "recovering keys in TE. So you can",
      "timestamp": "20:23"
    },
    {
      "start": 1224.559,
      "duration": 3.681,
      "text": "decrypt encrypt models uh for this kind",
      "timestamp": "20:24"
    },
    {
      "start": 1228.24,
      "duration": 1.919,
      "text": "of serving but you could right now you",
      "timestamp": "20:28"
    },
    {
      "start": 1230.159,
      "duration": 2.241,
      "text": "can use confidential inference on open",
      "timestamp": "20:30"
    },
    {
      "start": 1232.4,
      "duration": 1.6,
      "text": "source models. So this is available",
      "timestamp": "20:32"
    },
    {
      "start": 1234.0,
      "duration": 2.64,
      "text": "right now you can verify all the",
      "timestamp": "20:34"
    },
    {
      "start": 1236.64,
      "duration": 2.48,
      "text": "signatures kind of invidia etc. And we",
      "timestamp": "20:36"
    },
    {
      "start": 1239.12,
      "duration": 3.12,
      "text": "have key management authority on near",
      "timestamp": "20:39"
    },
    {
      "start": 1242.24,
      "duration": 4.0,
      "text": "that can effectively provision all this.",
      "timestamp": "20:42"
    },
    {
      "start": 1246.24,
      "duration": 3.88,
      "text": "All right. Thank you very much.",
      "timestamp": "20:46"
    }
  ],
  "extraction_timestamp": "2025-07-08T14:45:53.103186",
  "playlist_title": "EthCC[8] Redford Stage"
}