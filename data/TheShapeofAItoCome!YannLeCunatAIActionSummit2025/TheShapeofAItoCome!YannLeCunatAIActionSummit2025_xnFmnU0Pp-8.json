{
  "video_id": "xnFmnU0Pp-8",
  "video_title": "The Shape of AI to Come! Yann LeCun at AI Action Summit 2025",
  "video_url": "https://www.youtube.com/watch?v=xnFmnU0Pp-8",
  "channel_title": "DSAI by Dr. Osbert Tay",
  "published_at": null,
  "duration_seconds": null,
  "view_count": "118442",
  "like_count": null,
  "description": "The Next AI Revolution: Yann LeCun‚Äôs Vision Beyond LLMs  \n\nAt the AI Action Summit in Paris, Yann LeCun underscored a fundamental shift in artificial intelligence‚Äîone that moves beyond the brute-force approach of large language models (LLMs). Instead of systems that merely predict the next token, the future of AI hinges on *world models*‚Äîstructured, adaptive representations that can infer, reason, and plan.  \n\nThis vision holds immense potential for fields like healthcare and biology, where complexity defies exhaustive computation. \n\nüîπ 1. Prioritize Key Insights Over Exhaustive Generation  \nIn medicine, capturing every molecular interaction is infeasible. The focus should be on critical variables‚Äîkey biomarkers, for instance‚Äîthat shape disease progression and treatment response. This is where JEPA (Joint Embedding Predictive Architecture) thrives: predicting essential relationships rather than generating redundant details.  \n\nüîπ 2. Replace Probability Overload with Efficient Scoring  \nTraditional AI wastes resources computing endless probabilities. Instead, energy-based models assess how likely or ‚Äúnormal‚Äù a given state is. In healthcare, this translates to identifying anomalous symptoms or lab results instantly‚Äîwithout brute-force calculations.  \n\nüîπ 3. Move Beyond Contrastive Learning to More Direct Approaches  \nContrastive learning hinges on distinguishing ‚Äúpositive vs. negative‚Äù examples, often requiring vast datasets. Simpler, more direct methods can recognize meaningful patterns with less data‚Äîan advantage in medical research, where data is often scarce.  \n\nüîπ 4. Shift from Trial-and-Error to Model-Driven Discovery  \nBlindly testing drugs or protein interactions is slow and costly. AI-driven world models can predict biological behavior, allowing experiments to focus only on deviations from expected outcomes. This approach accelerates breakthroughs while reducing inefficiencies.  \n\nüîπ 5. LLMs Alone Won‚Äôt Achieve Human-Level Intelligence  \nWhile LLMs excel at summarizing and automating documentation, true comprehension‚Äîsuch as understanding disease mechanisms‚Äîrequires AI that grasps causality, not just linguistic patterns. The next frontier isn‚Äôt about scaling transformers but building models that think.  \n\nLeCun‚Äôs vision challenges conventional AI wisdom: instead of merely making models bigger, make them *smarter*. In healthcare and beyond, this shift could redefine how we diagnose, predict, and treat complex conditions. The future of AI isn‚Äôt just about processing data‚Äîit‚Äôs about understanding the world.\n\nIf you would like to support the channel, please join the membership:\nhttps://www.youtube.com/c/AIPursuit/join\n\nSubscribe to the channel:\nhttps://www.youtube.com/c/AIPursuit?sub_confirmation=1\n\nThe video is reposted for educational purposes and encourages involvement in the field of AI research.\nSource: AI Action Summit 2025",
  "transcript": {
    "language": "English (auto-generated)",
    "is_auto_generated": true,
    "total_segments": 1131,
    "aggregated_text": "I'd like to uh welcome our second and final uh plenary uh to the stage um up next is Yan lukan uh he's a chief AI scientist at meta and professor at NYU now Yan was the founding director of meta and of the NYU uh Center I should say for data science he works Prim primarily in a number of fields machine learning computer vision uh mobile Robotics and computational Euro science in 2019 Yan won the prestigious ACM touring award for his work on AI and he's of course a member of uh the US nationaly and the French Academy the sance a warm welcome to you Yan good to have you thank you very much a real pleasure to be here uh last time must have been before covid or something um okay um there's going to be some uh connection a little bit with what Bernard just talked about um and what I'm going to talk about is all the stuff that Mark Jordan earlier today told you you shouldn't be working on um so as a matter of fact we do need human level AI um and it's not just because it's an interesting scientific question it's also sort of a product need um we are going to be uh wearing smart devices like smart glasses and things of that type in the future and in in those smart U devices we'll be able to um access AI assistants that will be with us at all times and we'll be interacting with them either through voice or through U uh electron um electrogram CMG um the glasses will eventually have displays although currently they don't and um and we need those system to have human level intelligence because that's what we're the most familiar um um interacting with we're familiar with interacting with other humans uh we are familiar with the level of intelligence that we expect in a in a human and uh it would be more you know easier to interact with systems that have kind of similar forms of intelligence um so you know those ubiquitous assistants um are going to mediate all of our interactions with the digital world and um that that's why that's why we we we need them to be easy to use for a wide population that is not necessarily familiar with um using technology okay but the problem is machine learning sucks compared to what we observe in humans and animals uh we don't really have the techniques that would um allow us to build machines that have the the same type of uh learning abilities and Common Sense and understanding of the physical world um so animals and humans um have background knowledge that allows them to um learn new tasks extremely quickly understand how the world Works um being able to reason and plan and that's based on what we call common sense it's not a very well- defined concept um and and our behavior and behaviors of animals are driven by objectives essentially um so I'm going to argue that the type of AI systems that we uh we have at the moment um or or that everybody is you know playing with almost everybody is playing with uh do not have the right characteristics uh for for what we want um and the reason is uh they basically um produce one token after the other autor regressively right so you have a sequence of tokens which are subo units but it doesn't matter what they are a sequence of symbols and then you have a predictor that is repeated over the sequence that Bic basically take a window of previous tokens and predict the next token um and the way you train those system is that you put the sequence at the at the input and I really apologize for this I'm going to perhaps change the resolution of the screen so that we don't have this constant flashing hang on just one second okay not sure this is better but hopefully all right um so so so the way those things are trained is you take a sequence and you basically train the system to just reproduce its input on its output and because it has a causal structure um it cannot cheat and use a particular input to predict itself it has to only look at the symbols that are to the left of it that's called causal architecture um so that's very efficient this is you know what people people call a GPT general purpose Transformer but you don't have to put Transformers in it this could be anything it's just a caal architecture and I'm afraid I haven't fixed the flashing anyway um so the the the way you train the uh those systems uh then you can use it to generate text by just Auto aggressively producing a token shifting it into the input and then producing the second token shifting that in ETC that's Auto prediction Not A New Concept at all obviously um and there's an issue with this which is that um the U the that process is basically Divergent every time you produce a token there is some chance that the token is not within the set of reasonable answers and take you outside a set of reasonable answers and if it does that there is no way to fix it afterwards um and if there is if you assume there is some probability for that you know wrong token uh for wrong tokens to be generated and the errors are independent which of course they're not um then you get exponential Divergence uh which is why you know we have with those models hallucination issues um but we're missing something really big because uh you know never mind trying to reproduce human intelligence we can even reproduce cat intelligence or rat intelligence let alone dog intelligence they can do amazing feits they understand the physical world um um you know any house cat can plan very highly complex um actions um and they have causal models of of the world some of them know how to open doors and and Taps and things of that type um and in humans you know a 10-year-old can clear up the dinner table and fill up the dishwasher without learning zero shot the first time you ask a 10-year-old to do it um yeah she will do it any 17-year-old can learn to drive a car in 20 hours of practice but we still don't have robots that can act like a cat we don't have domestic robots that can clear up the dinner table and we don't have level five cell driving cars despite the fact that we have hundreds of thousands if not millions of hours of supervis training data okay so that tells you we're missing something really big um yet we have systems that can pass the bar exam do math problems prove theorems but no domestic robots so we keep bumping into this Paradox called Mor Paradox right things that we take for granted um because humans and animals can do it we think it's not complicated it's actually very complicated and the stuff that we think is uniquely human like manipulating and generating language playing chess playing go playing poker producing poetry and this kind of stuff turn that to be easy relatively okay and perhaps the reason for this is this very simple calculation um a typical llm nowadays is trained on on the order of 30 trillion tokens three 10 to the 13 uh tokens that's two to the 13 words roughly each token is about three bytes um so the data volume is roughly 10 to the 14 bytes uh it would take any of us uh almost half a million years to read through all that material it's basically all the publicly available text on the internet now consider her human child a four-year-old has been awake a total of 16,000 hours which by the way is only 30 minutes of YouTube uploads um we have 2 million optical nerve fibers Each of which carries about 1 B per second maybe a bit less but it doesn't matter so the data volume is about 10 to the 14 in four years a four-year-old child has seen as much data as the biggest llm in the form of visual perception and for blind children is touch it's the same kind of uh bandwidth uh that tells you a number of things we're never going to get to human level intelligence by just turning on text it's not just not happening despite what you know some people who are have a vested interest in this happening are telling us we're going to reach you know PhD level intelligence by next year it's just not happening we might have PhD level in some subfield in some area some uh um problems like chess playing you know but more of them um as long as we train those systems specifically for for those problems as um as Bernard was explaining with the visual Illusions um there are a lot of problems of this type when you formulate a problem you pose a problem to an llm and if the problem is kind of a standard puzzle the answer will be regurgitated in just a few seconds if you change the statement of the problem a little bit the system will still produce the same answer that it had before because it has no real mental model what goes on um in the in the puzzle so how do um humans infants learn how the world works and you know infants accumulate a huge amount of background knowledge about the world in the first few months of life um Notions like object permanence um solidity rigidity natural categories of objects before children understand language they do understand the difference between the table and the chair um that kind of develops naturally and they understand intuitive physics notion like gravity inertia and things of that type around the age of nine months um so it takes a long time uh observation mostly um until four months because babies don't really have any influence on the on the world before that um but then uh through interactions but the amount of interaction that's that's required is astonishingly small so if we want um AI system that can reach eventually reach human level might take a while um we call this Advanced machine intelligence at meta we don't like the term AGI artificial general intelligence the reason being that that human intelligence is actually quite specialized and so calling it AGI is kind of a misnomer um so we call this Ami we actually pronounce it Ami which means friend in French um so we need systems that um learn well models from sensory input basically mental models of how the world works that you can manipulate in your mind learning 2D physics um from video let's say systems that have persistent memory systems that can plan actions uh possibly hierarchically so as to fulfill an objective and systems that can reason um and then systems that are controllable and safe by Design not by fine-tuning which is the the case for llms now the only way I know to build systems of this type is to change the type of of inference um that um current uh AI systems perform so right now the way an llm uh performs inference is by running through a fixed number of layers of anet a transformer then producing a token injecting that token on the input and then running through a fixed number of layers again and the problem with this is that if you ask a simple question or complex question and you ask the system to answer by yes or no like does 2 and two equal four yes or no or does p equal NP yes or no it's going to spend the exact same amount of computation to answer those two questions so people have been kind of cheating and telling the system system will explain you know the Chain of Thought trick you you basically have the system produce more tokens so that is going to spend more competition answering the question but that's kind of a hack the way um a lot of inference in statistics for example that's going to make Mike happy actually um the way inference works is is not that way in uh In classical AI in statistics uh in structure prediction a lot of different domains the way it works is that you have a function that measures the degree of compatibility or incompatibility between your observation and a proposed output and then the inference process consist in finding the value of an output that minimizes this incompatibility measure okay let's call it an energy function so you have an energy function okay represented by the square box here on the right um when it doesn't disappear and and the system just do performs optimization for doing inference now if the inference uh problem is more difficult the system will just spend more time performing inference in other words they will think about complex problems for longer than simple ones for which the answer is pretty obvious um and this is really a very classical thing to do in classical classical AI is all about reasoning and uh search and therefore optimization pretty much any computational problem can be reduce an optimization problem essentially or search problem uh it's also very classical in probabilistic modeling like probabilistic graphical models and things of that type so this type of inference would be more akin to what psychologists call system two in uh sort of human U mind if you want system two is when you think about what action or sequence of actions you're going to take before you you you take them you think about something before doing it and the system one is when you can do the thing without thinking about it you know it becomes sort of subconscious so llms are system one what I'm proposing is system two um and then the appropriate um sort of semi theoretical framework to um explain this is energy based models which I'm not going to have time to get into too much detail but basically you capture the dependency between variables let's say observations X and uh outputs uh y through an energy function that takes low value where when X and Y are compatible and then larger values when X and why are not compatible you don't want to just compute y from X as we just saw you just want an energy function that measures the degree of incompatibility and then you know given an X find a y that has low energy for that X okay so now let's go a little bit into the details of how this type of architecture can be built so essentially and how it kind of relates to um uh thinking or planning uh so a system would look like this um you you get observation from the world it go through a perception module that produces an estimate about the state of the world but of course the state of the world is not completely observable so you may have to combine this with a memory the content of a memory that constit you know contains your idea of the state of the world you don't uh currently perceive um and the combination of those two goes into a world model so what is a world model World model is given given a current estimate of the state of the world which is in an abstract representation space and given an action sequence that you imagine taking uh your world model predicts the the resulting state of the world that will um occur after you take that sequence of actions okay that's what a world model is if I tell you imagine a cube floating in the air in front of you okay now rotate this Cube by 90 degrees around a vertical axis um what does it look like it's very easy for you to kind of have this metal model of a cube rotating um okay okay okay okay hopefully all right let's hope this will be more stable okay um 50 Herz not 60 HZ okay so uh what you can do now is uh feed okay hang on make a more radical Choice here okay this doesn't look like it was a good idea oh I know what I that's nice okay I think we're going to have human level intelligence before we have audio video that actually works okay um so so if we have this world model which is able to predict the result of a sequence of actions um we can feed it to an objective which is a task objective that measure to what extent the predicted final State U satisfies a goal that we set for ourselves it's just a cost function um and we also can set some uh guardrail objectives think of them as constraints that need to be satisfied for the system to behave in a safe manner right so those guardes will be explicitly implemented and the way the system proceeds is by optimization it's looking for an action sequence that minimizes the task objective and the uh guard rail objectives at runtime okay we're not talking about learning here we're just talking about inference um and that will guarantee the safety of the system because uh the guard rails guarantee safety and there is no way you can Jailbreak that system by giving it a prompt that will you know have it ES Escape its guardwire objectives the guard objectives would be just hardwired they might be trained but hardwired now a sequence of actions should probably use a single World model that you repeat you use repeatedly over multiple time steps okay so you have a one model if you did the first action it predicts the next state and the second action predicts the second next state you can have guard R cost and objective uh task uh task objectives along the trajectory the ad specifying what optimization algorithm we can use it doesn't really matter for the discussion that we have um if the world happens not to be completely deterministic and predictable the world model may need to have latent variables to account for all the things about the world that we do not observe and that uh you know makes our prediction basically um inexact and ultimately what we want is a system that can plan hierarchically so something that may have several levels of abstraction in such a way that um at the low level we plan low level actions like basically muscle control but at a high level we can plan abstract macro action where the world model predicts at longer time steps but in a representation space that is more abstract and therefore contains fewer detail so if I want if I'm sitting at my office at NYU and I decide to go to Paris um I can decompose that task into two sub tasks go to the airport and catch a plane okay now I have a sub goal going to the airport um I'm in New York city so going to the airport consist in going down on the street and haing a taxi how do I go down in the street well I need to uh get to the elevator push the button go down go out the building how do I go to the elevator well I need to stand up for my chair pick up my bag open the door walk to the elevator avoid all the obstacles and then at some point I get to a level where I don't need to plan I can just take the actions um but we do those type of this type of hierarchical planning absolutely all the time and I tell you we have no idea how to do this with learning machines almost every robot does hierarchical planning but the the representations at every level of the hierarchy are hand handcrafted what we need is to train an architecture perhaps of the type that I'm describing here so that it can learn repres abstract representations not just of the state of the world but also prediction World models that predict what's going to happen but also abstract actions at levels of abstraction so we can do this hierarchical planning animals do this okay humans do this very well we're completely incapable of doing this withm today if you're starting a PhD great topic might take more than three years um so I with all those Reflections about 3 years ago I wrote a long paper where I kind of explained sort of where where I think AI research should be focusing on so this so before the whole GP CH GPT craze um I haven't changed my mind about this CH GPT hasn't Chang anything we wereing Els before that so we knew what was coming anyway um this is the paper um a path towards autonomous machine intelligence that we now call Advanced machine intelligence because autonomous just scares people um and it's on open review it's not on archive and there's various versions of this talk that I've I've given various ways okay so very natural idea for for getting systems to understand how the world works is um using the same process that we used to um to to train system for natural language and apply this to let's say video okay if a system is capable of predicting what's going to happen in a video you show it A short segment of video and you ask it to predict what's going to happen next presumably it would have understood the underlying structure of the world um and so training it to make that prediction might actually cause the system to understand the annoing structure of the world it works for text because predicting words is relatively simple why is predicting words simple because words um there's only a finite number of possible words certainly a finite number of possible tokens and so we can't predict exactly which word will follow another word or what what word is missing in the text but we can produce a probability distribution or score for every possible word in the dictionary we cannot do this for images for video frames we do not have good ways of representing distributions of our video frames um every attempt to do this uh basically bumps into mathematical intract abilities um and so you could try to get around the problem using you know um statistics and and the math that was invented by by physicists you know vial inference and all that stuff but in fact it's better to just throw away the entire idea of doing probabilistic modeling and just just say I just want to learn this energy function that tells me whether my output is compatible with my input and I don't care if this energy function is a negative log of some distribution um and so the reason we need to do this of course is because we cannot predict exactly what's going to happen in the world there is a whole set of possible things that may happen and if we train a system to just predict one frame it's not going to do a good job um so the solution to that problem is an AR a new architecture I call John tedding predictive architecture or jepa and that's because generative architecture simply do not work for producing videos you may have seen video generation systems that produce pretty amazing stuff there's a lot of hacks that go be Beyond them uh behind them and they don't really understand physics um they don't need to they just need to to predict pretty pictures they don't need to actually have kind of accurate model of the world okay so here's what the JEA is the idea is that you run both the observation and the output which is the next observation into an encoder so that the prediction does not consist in predicting pixels but basically predicting an abstract representations of what goes on in the video video or anything okay so let's compare those two architectures on the left you have generative architectures you run X the observation to an encoder and perhaps to a predictor or decoder and you make a prediction for y okay that straightforward prediction and then on the right this jeta architecture you run both X and Y through and codos which may be identical or different and then you predict the representation of Y from the representation of X in this abstract space what this will cause the system to basically learn an encoder that eliminates all the stuff you cannot predict and this is really what we do there's no way that you know if if I observe the left part of this room here and I kind of pan the camera towards the right there's no way any video prediction system including humans can predict what every one of you looks like or predict the texture on the wall or the texture of the wood U on the on the hardwood floor um there's a lot of things that we just simply cannot predict and so instead of insisting that we should make a probabilistic prediction about stuff that we cannot predict let's just not predict it learn a representation in which all of those details are essentially eliminated so that the prediction is much simpler it may still we need to be uh non- deterministic but at least we simplify the problem so there's various flavors of those jads which I'm not going to go into some of which have latent variables some of which have are action conditioned so I'm going to talk about the action condition because that's uh the the most interesting one because they really are World models right so you have an encoder X is current state of the world or current observation XX is current state of the world you feel an action to a predictor which you imagine taking and the predictor which is a world model predicts the representation of the next state of the world um and that's how you can do planning okay so um you need to we need to train those systems and we need to figure out how to train those jepa architectures and tells that to not be completely trivial because you need to train the the cost function in this JEA architecture that measures the the Divergence between the representation of Y and the predicted representation of Y we need this to be low on the training data but we need also needed to be large outside the training set okay so this is you know this kind of energy function here that has kind of uh Contours of equal equal energy we need to make sure the energy is high outside of the manifold of data and I only know two classes of methods for this one set of method is called contrastive it consists in um having uh data points which are those those blue dark blue dots pushing the down the energy of those and then generating you know those flashing green dots and then pushing the energy up the problem with this type of method Contra method is that they don't scale very well in high dimension if you have too many dimensions in your space of Y you're going to need to push up in lots of different places and um it it doesn't work so well you need a lot of contrastive samples for this to work there's another set of method that um called regularized method and what they do is they use a regularizer on the energy so as to minimize the volume of space that can take low energy okay so that leads to two different types of learning procedure one one learning procedure which is contrastive you need to generate those contrastive points and then push their energy up to some loss function and the other one is some regularizer that is going to sort of shrink wrap the the manifold of data um so as to make sure that the energy is Tire outside so there's a number of techniques to do this um I'll describe just just a handful and the way um we we started testing them several years ago um maybe five six years ago was um to train them to learn representations of images so you take one image you corrupt it or transform it in some ways and you run the original image and the corrupted version in identical encoders and you train a predictor to predict the representation of the original image from the corrupted one once you're done training the system you remove the predictor and you use a representation at the output of the encoder as input to a simple um like a linear classifier or something of that type that you train supervised uh so as to verify that the representations that are learned are good and this idea is very old it goes back to the 198 90s and things like uh we used to call SES networks um and some more recent work on on those joint embedding architectures and then adding the predictor is more is more recent um so s clear which is from from Google is a contrastive method derived from s Nets um but again the dimension is is restricted so the regularized method uh worked the following way you try to estimate have some sort of estimate of the information content coming out of the encoders and what you need to do is prevent the encoder from collapsing this a trivial solution of training a a Jeeter architecture where the encoder basically ignores the input produces a constant output and another the prodction error is zero all the time okay and obviously that's a collapsed solution that is uh not interesting so you need a system you need to prevent the system from collapsing and which is the regularization method I was talking about earlier and an indirect way of doing this is maintain the information content coming out of the encoder Okay so so you're going to have a training objective function which is a negative information content if you want because we minimize in machine learning we don't maximize uh one way to do this is to basically take the um vectors representation vectors that come out of the encoder over a batch of samples um and make sure they contain information how you can you do this you can take that Matrix of representation vectors and compute the product of that matrix by its transposed you get aarian Matrix and you try to make that coari Matrix equal to Identity um so there's a bad news with this which is that this basically approximates the information content by making very strong assumptions about the the nature of the dependencies between the variables and in fact it's an upper bound on information content and we're pushing it up crossing our fingers that the actual information contain which is below is going to follow okay so it's slightly uh uh irregular uh theoretically but but it works all right so again uh you have a matrix coming out of your encoder it's got a number of samples um and each Vector is a separate variable what we're going to try to do is going to try to make each variable individually uh informative so we're going to try to prevent the the variance of the variable from going to to zero force it to be one for example and then we're going to decorrelate the variables with each other and that means Computing The coverance Matrix of this Matrix is transpose multiply by itself and then try to make the resulting coar Matrix as close to the identity uh Matrix as possible um there are other methods that try to make the samples uh orthogonal not the not the variables um and those are contrasting sample contrasting methods um but they don't work in high dimension and they require large batches uh so we have um a method of this type called viag that means variance in variance Co variance regularization and it's got particular loss functions for this ciance Matrix um there been kind of similar methods proposed by uh yima and his team called MCR squar and then another method by uh some colleagues from NYU called mmcr from neuroscience so that's one set of methods and I really like those methods and I I think and they work really well I expect to see more of them in the future but there is another set of method that to some extent has been slightly more successful over the last couple years and those are based on distillation so again you have two encoders it's still a joint Ting productive architecture you have two encoders they kind of share the same weights but not really so the encoder on the right uh gets a version of the weights of the enod on the left that are obtained through a um exponential moving average okay a moving average so basically you force the encoder on the right to uh change its weights more slowly than the one on the left and for some reason that prevents collapse there's some theoretical work on this um in fact uh this one that jum just finished writing um but it's a little bit mysterious why this works and frankly I'm a little uncomfortable with this method but we have to um accept the fact that actually works um if you if you're careful um you know real Engineers buildings without necessarily knowing why they work that's good engineers and then the usual joke in France that everybody here should should learn is that students that come out of e poly technique when they build something it doesn't work but they can tell you why sorry about that um I didn't study here you can tell um okay let me uh switch ahead skip ahead a little bit in interest of time because we wasted a bit of time um okay so there's a particular way of implementing this AIO distillation called IA there's another one called called Dino or Dino uh which I I skipped a little bit um and um so Dino um is V2 people are working on on V3 this is a method produced by some some of my colleagues at at Fair Paris um team led by Max Maximo cab um and then a slight different version um called IA V JEA by also Fair people in in Montreal and Paris mostly so no need for negative samples there and those those kind of those systems learn generic features that you can then learn for any Downstream task and the features are really good um so this works really well I'm not going to bore you with details because I don't have time uh more recently we worked on a version of this for video so this is a system that takes a a chunk of 16 frames from video and you corrupt you you take those 16 frames run them to an encoder and then you corrupt those 16 frames by masking some parts of it run them to the same encoder and then train a predictor to predict the U representation of a full video from the one that is partially masked or corrupted and the U so again this is group of researchers at at Fair in Paris and Montreal um and this works really well in the sense that uh you learn features that you can then feed to A system that can classify actions in videos and you get really good results with the with this these these methods again I'm not going to bore you with details but here is a really interesting thing this is a paper that we just submitted um if you show that system um videos where something really strange happens that system actually is capable of telling you my prediction error is going through the roof there is something strange going on in that window so you you take a you take a video and you take the 16 video Frame Window you slide it over the video and you measure the prediction error of the system and if something really strange happen like an object spontaneously disappears or change shape um the prediction error shoots up so what that tells you is that that system despite its Simplicity has learned some level of Common Sense he can tell you if something really strange in the world is happening um lots of experiments to show this in various contexts for various types of intuitive physics but I'm not going to I'm to skip to this uh latest work uh D Dino World model um so this is using Dino features and then training a predictor on top of it which is action condition so that it's a world model that we can use for planning um and this is a a paper that is on archive there's a website also that you can uh you can look at the URL is at the top here so basically uh train a predictor using you know a picture of the world that you run through a dino encoder and then an action that maybe a robot um takes so you get the next frame uh of that of that video next image from the world run this to the dino encoder and then train your predictor to just predict what's going to happen given the action that was taken okay very simple to do planning um You observe an initial state run into the doo encoder then run your world model multiple time steps with imagined actions um then you have a Target state which is represented by a Target image for example you run it to the encoder and then you compute the distance in state space between the predicted State and the the the state representing the the target image and the planning consists in just through optimization finding a sequence of actions that minimizes that cost at runtime okay reference time you know people are excited about um um you know test time computation and blah blah blah as if it was something new this is completely classical in optimal control this is called Model preductive control it's been around with us for about the same time that I've been around all right um the first paper is on you know planning using using models of this type using optimization are from the early 60s um the the ones that actually learned the model are more recent they're more from the 70s from France actually um it's called edcom um some people in optimal control might know about this um but you know it's very simple concept this works amazingly well so let me skip to the video because okay so let's say you have this uh Little T shape and you want to push it into a particular um position and so you know which position it has to go to because you put an image of that position run to the enod and that gives you a Target state in representation space um let me play that video again okay so at the top you see what actually happens in the real world when you take a sequence of actions that is planned and what you see at the bottom is the internal mental prediction of what the system of the sequence of actions the system was planning and this is run to a decoder that produces a pictorial representation of the internal state but that is trained separately there's no image generation um let me skip to the more interesting one so here is one where you have an initial state which is a bunch of Blue Chips randomly thrown on the floor and the target state is at the top and what you see here are the actions that are resulted from planning and the robot like accomplishing those actions the Dynamics of this environment is actually fairly complicated because those blue Chiefs kind of interact with each other and and everything um the system has just learned this through you know observing a bunch of uh uh State action next state um and this works in a lot of situations for you know arms and moving through mazes and pushing a te around and and things like that so um okay and I'm not sure where I came back um we've applied kind of similar idea to navigation but interest of time I'm just going to skip um so this is you know basically sequences the videos where a frame is uh is taken at one time and then the robot moves and you know through odometry you know by how much the robot has moved you get the next frame and so you just train a system to predict what the world is going to look like if you take a particular motion uh action and what you can do next is you can tell a system like you know navigate to that point um and it it will it will do it and you know avoid obstacles on the way this is a very new work but let me go to the conclusion so I'm having a number of uh recommendations abandon generative models the most popular method today that everybody is working on startop working on this you work on jads those are not generative models they predict in representation space probably seek models because it's intractable use energy based models uh M have had like a 20 year contentious discussion about this um abandon contractive methods in favor of those regularized methods abandon reinforcement learning but that I've been saying for a long time we know it's inefficient um you have to use reinforcement learning really as a last result when your model is inaccurate or or your cost function is inaccurate um but if you are interested in human level AI just don't work on llm there's no point I mean in fact if you are in Academia don't work on LM because you're in competition with like hundreds of people with tens of thousands of gpus like there's nothing you can bring to the table do something else um there's a number of problems to solve U training those things with you know large scale data blah blah blah planning algorithms are kind of inefficient we have to come up with better methods so if you are like into optimization applied math it's great um J with latent variables planning under uncertainty hierarchical planning which is completely unsolved um learning cost module because probably most of them you can't build by hand you need to learn them and then there is issues exploration Etc okay so in the future we'll have Universal virtual assistants they'll be with us at all times they will mediate all our interaction with the digital world we cannot afford to have those systems come from a handful of companies from the west coast of the US or China uh which means the platforms on top of which we build those systems need to be open source and widely available they are expensive to train but once you have a foundation model fun tuning it for a particular application is relatively cheap and a lot of people afford to do this so the platforms need to be shared they need to speak all the the world languages understand all the world's cultures all the value systems all the centers of Interest no single entity in the world can train a foundational model of this type this probably will have to be done in a collaborative fashion or distributed fashion again some work for Applied mathematicians who are interested in distributed algorithms for large scale optimization um and so open source AI platforms are necessary the danger I see um in Europe and in other places is that geopolitical rivalry will U entice governments to basically make the release of Open Source model illegal because there are under the impression that a country will stay ahead if he keeps uh its science secret that's that would be a huge mistake when you do research in secret you fall behind that's inevitable what will happen is that the rest of the world we go up and and will overtake you that's currently what's what's happening the open source models are overtaking uh slowly but surely uh proprietary models thank you very much",
    "text_length": 40636,
    "word_count": 7587
  },
  "segments": [
    {
      "start": 0.44,
      "duration": 6.68,
      "text": "I'd like to uh welcome our second and",
      "timestamp": "00:00"
    },
    {
      "start": 2.8,
      "duration": 7.64,
      "text": "final uh plenary uh to the stage um up",
      "timestamp": "00:02"
    },
    {
      "start": 7.12,
      "duration": 7.2,
      "text": "next is Yan lukan uh he's a chief AI",
      "timestamp": "00:07"
    },
    {
      "start": 10.44,
      "duration": 6.999,
      "text": "scientist at meta and professor at",
      "timestamp": "00:10"
    },
    {
      "start": 14.32,
      "duration": 5.92,
      "text": "NYU now Yan was the founding director of",
      "timestamp": "00:14"
    },
    {
      "start": 17.439,
      "duration": 5.68,
      "text": "meta and of the NYU uh Center I should",
      "timestamp": "00:17"
    },
    {
      "start": 20.24,
      "duration": 5.32,
      "text": "say for data science he works Prim",
      "timestamp": "00:20"
    },
    {
      "start": 23.119,
      "duration": 4.761,
      "text": "primarily in a number of fields machine",
      "timestamp": "00:23"
    },
    {
      "start": 25.56,
      "duration": 6.16,
      "text": "learning computer vision uh mobile",
      "timestamp": "00:25"
    },
    {
      "start": 27.88,
      "duration": 7.199,
      "text": "Robotics and computational Euro science",
      "timestamp": "00:27"
    },
    {
      "start": 31.72,
      "duration": 5.96,
      "text": "in 2019 Yan won the prestigious ACM",
      "timestamp": "00:31"
    },
    {
      "start": 35.079,
      "duration": 5.241,
      "text": "touring award for his work on AI and",
      "timestamp": "00:35"
    },
    {
      "start": 37.68,
      "duration": 5.84,
      "text": "he's of course a member of uh the US",
      "timestamp": "00:37"
    },
    {
      "start": 40.32,
      "duration": 5.04,
      "text": "nationaly and the French Academy the",
      "timestamp": "00:40"
    },
    {
      "start": 43.52,
      "duration": 2.55,
      "text": "sance a warm welcome to you Yan good to",
      "timestamp": "00:43"
    },
    {
      "start": 45.36,
      "duration": 3.91,
      "text": "have",
      "timestamp": "00:45"
    },
    {
      "start": 52.48,
      "duration": 5.04,
      "text": "you thank you very much a real pleasure",
      "timestamp": "00:52"
    },
    {
      "start": 54.92,
      "duration": 6.279,
      "text": "to be here uh last time must have been",
      "timestamp": "00:54"
    },
    {
      "start": 57.52,
      "duration": 5.6,
      "text": "before covid or something um",
      "timestamp": "00:57"
    },
    {
      "start": 61.199,
      "duration": 4.0,
      "text": "okay um there's going to be some uh",
      "timestamp": "01:01"
    },
    {
      "start": 63.12,
      "duration": 5.56,
      "text": "connection a little bit with what",
      "timestamp": "01:03"
    },
    {
      "start": 65.199,
      "duration": 5.521,
      "text": "Bernard just talked about um and what",
      "timestamp": "01:05"
    },
    {
      "start": 68.68,
      "duration": 4.96,
      "text": "I'm going to talk about is all the stuff",
      "timestamp": "01:08"
    },
    {
      "start": 70.72,
      "duration": 6.48,
      "text": "that Mark Jordan earlier today told you",
      "timestamp": "01:10"
    },
    {
      "start": 73.64,
      "duration": 3.56,
      "text": "you shouldn't be working",
      "timestamp": "01:13"
    },
    {
      "start": 77.4,
      "duration": 5.16,
      "text": "on um so as a matter of fact we do need",
      "timestamp": "01:17"
    },
    {
      "start": 81.119,
      "duration": 4.601,
      "text": "human level",
      "timestamp": "01:21"
    },
    {
      "start": 82.56,
      "duration": 5.199,
      "text": "AI um and it's not just because it's an",
      "timestamp": "01:22"
    },
    {
      "start": 85.72,
      "duration": 5.16,
      "text": "interesting scientific question it's",
      "timestamp": "01:25"
    },
    {
      "start": 87.759,
      "duration": 7.0,
      "text": "also sort of a product need um we are",
      "timestamp": "01:27"
    },
    {
      "start": 90.88,
      "duration": 5.44,
      "text": "going to be uh wearing smart devices",
      "timestamp": "01:30"
    },
    {
      "start": 94.759,
      "duration": 5.961,
      "text": "like smart glasses and things of that",
      "timestamp": "01:34"
    },
    {
      "start": 96.32,
      "duration": 8.04,
      "text": "type in the future and in in those smart",
      "timestamp": "01:36"
    },
    {
      "start": 100.72,
      "duration": 5.32,
      "text": "U devices we'll be able to um access AI",
      "timestamp": "01:40"
    },
    {
      "start": 104.36,
      "duration": 4.16,
      "text": "assistants that will be with us at all",
      "timestamp": "01:44"
    },
    {
      "start": 106.04,
      "duration": 5.92,
      "text": "times and we'll be interacting with them",
      "timestamp": "01:46"
    },
    {
      "start": 108.52,
      "duration": 8.08,
      "text": "either through voice or through U uh",
      "timestamp": "01:48"
    },
    {
      "start": 111.96,
      "duration": 6.28,
      "text": "electron um electrogram CMG um the",
      "timestamp": "01:51"
    },
    {
      "start": 116.6,
      "duration": 4.479,
      "text": "glasses will eventually have displays",
      "timestamp": "01:56"
    },
    {
      "start": 118.24,
      "duration": 5.12,
      "text": "although currently they don't",
      "timestamp": "01:58"
    },
    {
      "start": 121.079,
      "duration": 4.441,
      "text": "and",
      "timestamp": "02:01"
    },
    {
      "start": 123.36,
      "duration": 3.96,
      "text": "um and we need those system to have",
      "timestamp": "02:03"
    },
    {
      "start": 125.52,
      "duration": 4.84,
      "text": "human level intelligence because that's",
      "timestamp": "02:05"
    },
    {
      "start": 127.32,
      "duration": 5.24,
      "text": "what we're the most familiar um um",
      "timestamp": "02:07"
    },
    {
      "start": 130.36,
      "duration": 5.159,
      "text": "interacting with we're familiar with",
      "timestamp": "02:10"
    },
    {
      "start": 132.56,
      "duration": 4.72,
      "text": "interacting with other humans uh we are",
      "timestamp": "02:12"
    },
    {
      "start": 135.519,
      "duration": 5.72,
      "text": "familiar with the level of intelligence",
      "timestamp": "02:15"
    },
    {
      "start": 137.28,
      "duration": 6.84,
      "text": "that we expect in a in a human and uh it",
      "timestamp": "02:17"
    },
    {
      "start": 141.239,
      "duration": 4.801,
      "text": "would be more you know easier to",
      "timestamp": "02:21"
    },
    {
      "start": 144.12,
      "duration": 3.199,
      "text": "interact with systems that have kind of",
      "timestamp": "02:24"
    },
    {
      "start": 146.04,
      "duration": 4.279,
      "text": "similar forms of",
      "timestamp": "02:26"
    },
    {
      "start": 147.319,
      "duration": 5.361,
      "text": "intelligence um so you know those",
      "timestamp": "02:27"
    },
    {
      "start": 150.319,
      "duration": 4.161,
      "text": "ubiquitous assistants um are going to",
      "timestamp": "02:30"
    },
    {
      "start": 152.68,
      "duration": 5.32,
      "text": "mediate all of our interactions with the",
      "timestamp": "02:32"
    },
    {
      "start": 154.48,
      "duration": 6.119,
      "text": "digital world and um that that's why",
      "timestamp": "02:34"
    },
    {
      "start": 158.0,
      "duration": 5.72,
      "text": "that's why we we we need them to be easy",
      "timestamp": "02:38"
    },
    {
      "start": 160.599,
      "duration": 6.28,
      "text": "to use for a wide population that is not",
      "timestamp": "02:40"
    },
    {
      "start": 163.72,
      "duration": 5.0,
      "text": "necessarily familiar with um using",
      "timestamp": "02:43"
    },
    {
      "start": 166.879,
      "duration": 5.28,
      "text": "technology okay but the problem is",
      "timestamp": "02:46"
    },
    {
      "start": 168.72,
      "duration": 5.96,
      "text": "machine learning sucks compared to what",
      "timestamp": "02:48"
    },
    {
      "start": 172.159,
      "duration": 4.601,
      "text": "we observe in humans and animals uh we",
      "timestamp": "02:52"
    },
    {
      "start": 174.68,
      "duration": 6.16,
      "text": "don't really have the techniques that",
      "timestamp": "02:54"
    },
    {
      "start": 176.76,
      "duration": 7.039,
      "text": "would um allow us to build machines that",
      "timestamp": "02:56"
    },
    {
      "start": 180.84,
      "duration": 6.6,
      "text": "have the the same type of",
      "timestamp": "03:00"
    },
    {
      "start": 183.799,
      "duration": 6.8,
      "text": "uh learning abilities and Common Sense",
      "timestamp": "03:03"
    },
    {
      "start": 187.44,
      "duration": 5.76,
      "text": "and understanding of the physical world",
      "timestamp": "03:07"
    },
    {
      "start": 190.599,
      "duration": 5.2,
      "text": "um so animals and humans um have",
      "timestamp": "03:10"
    },
    {
      "start": 193.2,
      "duration": 6.48,
      "text": "background knowledge that allows them to",
      "timestamp": "03:13"
    },
    {
      "start": 195.799,
      "duration": 6.36,
      "text": "um learn new tasks extremely quickly",
      "timestamp": "03:15"
    },
    {
      "start": 199.68,
      "duration": 5.6,
      "text": "understand how the world Works um being",
      "timestamp": "03:19"
    },
    {
      "start": 202.159,
      "duration": 4.961,
      "text": "able to reason and plan and that's based",
      "timestamp": "03:22"
    },
    {
      "start": 205.28,
      "duration": 5.56,
      "text": "on what we call common sense it's not a",
      "timestamp": "03:25"
    },
    {
      "start": 207.12,
      "duration": 5.88,
      "text": "very well- defined concept um and and",
      "timestamp": "03:27"
    },
    {
      "start": 210.84,
      "duration": 5.88,
      "text": "our behavior and behaviors of animals",
      "timestamp": "03:30"
    },
    {
      "start": 213.0,
      "duration": 5.84,
      "text": "are driven by objectives",
      "timestamp": "03:33"
    },
    {
      "start": 216.72,
      "duration": 3.84,
      "text": "essentially",
      "timestamp": "03:36"
    },
    {
      "start": 218.84,
      "duration": 4.64,
      "text": "um",
      "timestamp": "03:38"
    },
    {
      "start": 220.56,
      "duration": 4.959,
      "text": "so I'm going to argue that the type of",
      "timestamp": "03:40"
    },
    {
      "start": 223.48,
      "duration": 5.36,
      "text": "AI systems that we uh we have at the",
      "timestamp": "03:43"
    },
    {
      "start": 225.519,
      "duration": 4.92,
      "text": "moment um or or that everybody is you",
      "timestamp": "03:45"
    },
    {
      "start": 228.84,
      "duration": 4.119,
      "text": "know playing with almost everybody is",
      "timestamp": "03:48"
    },
    {
      "start": 230.439,
      "duration": 5.08,
      "text": "playing with uh do not have the right",
      "timestamp": "03:50"
    },
    {
      "start": 232.959,
      "duration": 4.321,
      "text": "characteristics uh for for what we",
      "timestamp": "03:52"
    },
    {
      "start": 235.519,
      "duration": 6.28,
      "text": "want",
      "timestamp": "03:55"
    },
    {
      "start": 237.28,
      "duration": 7.799,
      "text": "um and the reason is uh they basically",
      "timestamp": "03:57"
    },
    {
      "start": 241.799,
      "duration": 5.44,
      "text": "um produce one token after the other",
      "timestamp": "04:01"
    },
    {
      "start": 245.079,
      "duration": 5.041,
      "text": "autor regressively right so you have a",
      "timestamp": "04:05"
    },
    {
      "start": 247.239,
      "duration": 4.401,
      "text": "sequence of tokens which are subo units",
      "timestamp": "04:07"
    },
    {
      "start": 250.12,
      "duration": 3.92,
      "text": "but it doesn't matter what they are a",
      "timestamp": "04:10"
    },
    {
      "start": 251.64,
      "duration": 4.4,
      "text": "sequence of symbols and then you have a",
      "timestamp": "04:11"
    },
    {
      "start": 254.04,
      "duration": 4.4,
      "text": "predictor that is repeated over the",
      "timestamp": "04:14"
    },
    {
      "start": 256.04,
      "duration": 4.84,
      "text": "sequence that Bic basically take a",
      "timestamp": "04:16"
    },
    {
      "start": 258.44,
      "duration": 3.96,
      "text": "window of previous tokens and predict",
      "timestamp": "04:18"
    },
    {
      "start": 260.88,
      "duration": 3.64,
      "text": "the next",
      "timestamp": "04:20"
    },
    {
      "start": 262.4,
      "duration": 3.68,
      "text": "token um and the way you train those",
      "timestamp": "04:22"
    },
    {
      "start": 264.52,
      "duration": 3.56,
      "text": "system is that you put the sequence at",
      "timestamp": "04:24"
    },
    {
      "start": 266.08,
      "duration": 5.28,
      "text": "the at the input and I really apologize",
      "timestamp": "04:26"
    },
    {
      "start": 268.08,
      "duration": 4.92,
      "text": "for this I'm going to perhaps",
      "timestamp": "04:28"
    },
    {
      "start": 271.36,
      "duration": 4.64,
      "text": "change the",
      "timestamp": "04:31"
    },
    {
      "start": 273.0,
      "duration": 5.0,
      "text": "resolution of the",
      "timestamp": "04:33"
    },
    {
      "start": 276.0,
      "duration": 6.08,
      "text": "screen so",
      "timestamp": "04:36"
    },
    {
      "start": 278.0,
      "duration": 4.08,
      "text": "that we don't have this constant",
      "timestamp": "04:38"
    },
    {
      "start": 288.68,
      "duration": 4.959,
      "text": "flashing hang on just one second",
      "timestamp": "04:48"
    },
    {
      "start": 316.72,
      "duration": 4.479,
      "text": "okay not sure this is better but",
      "timestamp": "05:16"
    },
    {
      "start": 326.44,
      "duration": 6.68,
      "text": "hopefully all right um so",
      "timestamp": "05:26"
    },
    {
      "start": 330.919,
      "duration": 4.161,
      "text": "so so the way those things are trained",
      "timestamp": "05:30"
    },
    {
      "start": 333.12,
      "duration": 3.48,
      "text": "is you take a sequence and you basically",
      "timestamp": "05:33"
    },
    {
      "start": 335.08,
      "duration": 3.559,
      "text": "train the system to just reproduce its",
      "timestamp": "05:35"
    },
    {
      "start": 336.6,
      "duration": 5.159,
      "text": "input on its output and because it has a",
      "timestamp": "05:36"
    },
    {
      "start": 338.639,
      "duration": 5.361,
      "text": "causal structure um it cannot cheat and",
      "timestamp": "05:38"
    },
    {
      "start": 341.759,
      "duration": 3.72,
      "text": "use a particular input to predict itself",
      "timestamp": "05:41"
    },
    {
      "start": 344.0,
      "duration": 2.96,
      "text": "it has to only look at the symbols that",
      "timestamp": "05:44"
    },
    {
      "start": 345.479,
      "duration": 2.44,
      "text": "are to the left of it that's called",
      "timestamp": "05:45"
    },
    {
      "start": 346.96,
      "duration": 4.16,
      "text": "causal",
      "timestamp": "05:46"
    },
    {
      "start": 347.919,
      "duration": 5.4,
      "text": "architecture um so that's very efficient",
      "timestamp": "05:47"
    },
    {
      "start": 351.12,
      "duration": 4.16,
      "text": "this is you know what people people call",
      "timestamp": "05:51"
    },
    {
      "start": 353.319,
      "duration": 3.361,
      "text": "a GPT general purpose Transformer but",
      "timestamp": "05:53"
    },
    {
      "start": 355.28,
      "duration": 5.24,
      "text": "you don't have to put Transformers in it",
      "timestamp": "05:55"
    },
    {
      "start": 356.68,
      "duration": 6.56,
      "text": "this could be anything it's just a caal",
      "timestamp": "05:56"
    },
    {
      "start": 360.52,
      "duration": 6.079,
      "text": "architecture and I'm afraid I haven't",
      "timestamp": "06:00"
    },
    {
      "start": 363.24,
      "duration": 5.519,
      "text": "fixed the flashing anyway um so the the",
      "timestamp": "06:03"
    },
    {
      "start": 366.599,
      "duration": 4.081,
      "text": "the way you train the uh those systems",
      "timestamp": "06:06"
    },
    {
      "start": 368.759,
      "duration": 4.121,
      "text": "uh then you can use it to generate text",
      "timestamp": "06:08"
    },
    {
      "start": 370.68,
      "duration": 3.919,
      "text": "by just Auto aggressively producing a",
      "timestamp": "06:10"
    },
    {
      "start": 372.88,
      "duration": 3.84,
      "text": "token shifting it into the input and",
      "timestamp": "06:12"
    },
    {
      "start": 374.599,
      "duration": 5.081,
      "text": "then producing the second token shifting",
      "timestamp": "06:14"
    },
    {
      "start": 376.72,
      "duration": 5.68,
      "text": "that in ETC that's Auto prediction Not A",
      "timestamp": "06:16"
    },
    {
      "start": 379.68,
      "duration": 4.72,
      "text": "New Concept at all obviously um and",
      "timestamp": "06:19"
    },
    {
      "start": 382.4,
      "duration": 4.12,
      "text": "there's an issue with this which is that",
      "timestamp": "06:22"
    },
    {
      "start": 384.4,
      "duration": 5.919,
      "text": "um the",
      "timestamp": "06:24"
    },
    {
      "start": 386.52,
      "duration": 6.119,
      "text": "U the that process is basically",
      "timestamp": "06:26"
    },
    {
      "start": 390.319,
      "duration": 4.201,
      "text": "Divergent every time you produce a token",
      "timestamp": "06:30"
    },
    {
      "start": 392.639,
      "duration": 4.921,
      "text": "there is some chance that the token is",
      "timestamp": "06:32"
    },
    {
      "start": 394.52,
      "duration": 4.72,
      "text": "not within the set of reasonable answers",
      "timestamp": "06:34"
    },
    {
      "start": 397.56,
      "duration": 3.72,
      "text": "and take you outside a set of reasonable",
      "timestamp": "06:37"
    },
    {
      "start": 399.24,
      "duration": 5.239,
      "text": "answers and if it does that there is no",
      "timestamp": "06:39"
    },
    {
      "start": 401.28,
      "duration": 4.52,
      "text": "way to fix it afterwards um and if there",
      "timestamp": "06:41"
    },
    {
      "start": 404.479,
      "duration": 3.72,
      "text": "is if you assume there is some",
      "timestamp": "06:44"
    },
    {
      "start": 405.8,
      "duration": 4.44,
      "text": "probability for that you know wrong",
      "timestamp": "06:45"
    },
    {
      "start": 408.199,
      "duration": 4.0,
      "text": "token uh for wrong tokens to be",
      "timestamp": "06:48"
    },
    {
      "start": 410.24,
      "duration": 4.239,
      "text": "generated and the errors are independent",
      "timestamp": "06:50"
    },
    {
      "start": 412.199,
      "duration": 4.921,
      "text": "which of course they're not um then you",
      "timestamp": "06:52"
    },
    {
      "start": 414.479,
      "duration": 5.12,
      "text": "get exponential Divergence uh which is",
      "timestamp": "06:54"
    },
    {
      "start": 417.12,
      "duration": 4.0,
      "text": "why you know we have with those models",
      "timestamp": "06:57"
    },
    {
      "start": 419.599,
      "duration": 4.521,
      "text": "hallucination",
      "timestamp": "06:59"
    },
    {
      "start": 421.12,
      "duration": 5.28,
      "text": "issues um but we're missing something",
      "timestamp": "07:01"
    },
    {
      "start": 424.12,
      "duration": 3.56,
      "text": "really big because uh you know never",
      "timestamp": "07:04"
    },
    {
      "start": 426.4,
      "duration": 3.04,
      "text": "mind trying to reproduce human",
      "timestamp": "07:06"
    },
    {
      "start": 427.68,
      "duration": 3.56,
      "text": "intelligence we can even reproduce cat",
      "timestamp": "07:07"
    },
    {
      "start": 429.44,
      "duration": 4.0,
      "text": "intelligence or rat intelligence let",
      "timestamp": "07:09"
    },
    {
      "start": 431.24,
      "duration": 3.56,
      "text": "alone dog intelligence they can do",
      "timestamp": "07:11"
    },
    {
      "start": 433.44,
      "duration": 4.879,
      "text": "amazing feits they understand the",
      "timestamp": "07:13"
    },
    {
      "start": 434.8,
      "duration": 6.239,
      "text": "physical world um um you know any house",
      "timestamp": "07:14"
    },
    {
      "start": 438.319,
      "duration": 5.72,
      "text": "cat can plan very highly complex um",
      "timestamp": "07:18"
    },
    {
      "start": 441.039,
      "duration": 5.84,
      "text": "actions um and they have causal models",
      "timestamp": "07:21"
    },
    {
      "start": 444.039,
      "duration": 5.72,
      "text": "of of the world some of them know how to",
      "timestamp": "07:24"
    },
    {
      "start": 446.879,
      "duration": 5.88,
      "text": "open doors and and Taps and things of",
      "timestamp": "07:26"
    },
    {
      "start": 449.759,
      "duration": 5.361,
      "text": "that type um and in humans you know a",
      "timestamp": "07:29"
    },
    {
      "start": 452.759,
      "duration": 4.28,
      "text": "10-year-old can clear up the dinner",
      "timestamp": "07:32"
    },
    {
      "start": 455.12,
      "duration": 3.479,
      "text": "table and fill up the dishwasher without",
      "timestamp": "07:35"
    },
    {
      "start": 457.039,
      "duration": 3.88,
      "text": "learning zero shot the first time you",
      "timestamp": "07:37"
    },
    {
      "start": 458.599,
      "duration": 4.521,
      "text": "ask a 10-year-old to do it um yeah she",
      "timestamp": "07:38"
    },
    {
      "start": 460.919,
      "duration": 4.68,
      "text": "will do it any 17-year-old can learn to",
      "timestamp": "07:40"
    },
    {
      "start": 463.12,
      "duration": 4.68,
      "text": "drive a car in 20 hours of practice but",
      "timestamp": "07:43"
    },
    {
      "start": 465.599,
      "duration": 4.44,
      "text": "we still don't have robots that can act",
      "timestamp": "07:45"
    },
    {
      "start": 467.8,
      "duration": 3.959,
      "text": "like a cat we don't have domestic robots",
      "timestamp": "07:47"
    },
    {
      "start": 470.039,
      "duration": 4.16,
      "text": "that can clear up the dinner table and",
      "timestamp": "07:50"
    },
    {
      "start": 471.759,
      "duration": 5.041,
      "text": "we don't have level five cell driving",
      "timestamp": "07:51"
    },
    {
      "start": 474.199,
      "duration": 4.241,
      "text": "cars despite the fact that we have",
      "timestamp": "07:54"
    },
    {
      "start": 476.8,
      "duration": 4.839,
      "text": "hundreds of thousands if not millions of",
      "timestamp": "07:56"
    },
    {
      "start": 478.44,
      "duration": 4.56,
      "text": "hours of supervis training data okay so",
      "timestamp": "07:58"
    },
    {
      "start": 481.639,
      "duration": 2.28,
      "text": "that tells you we're missing something",
      "timestamp": "08:01"
    },
    {
      "start": 483.0,
      "duration": 3.8,
      "text": "really",
      "timestamp": "08:03"
    },
    {
      "start": 483.919,
      "duration": 5.12,
      "text": "big um yet we have systems that can pass",
      "timestamp": "08:03"
    },
    {
      "start": 486.8,
      "duration": 3.839,
      "text": "the bar exam do math problems prove",
      "timestamp": "08:06"
    },
    {
      "start": 489.039,
      "duration": 4.761,
      "text": "theorems",
      "timestamp": "08:09"
    },
    {
      "start": 490.639,
      "duration": 5.0,
      "text": "but no domestic robots so we keep",
      "timestamp": "08:10"
    },
    {
      "start": 493.8,
      "duration": 3.48,
      "text": "bumping into this Paradox called Mor",
      "timestamp": "08:13"
    },
    {
      "start": 495.639,
      "duration": 4.68,
      "text": "Paradox right things that we take for",
      "timestamp": "08:15"
    },
    {
      "start": 497.28,
      "duration": 4.68,
      "text": "granted um because humans and animals",
      "timestamp": "08:17"
    },
    {
      "start": 500.319,
      "duration": 3.481,
      "text": "can do it we think it's not complicated",
      "timestamp": "08:20"
    },
    {
      "start": 501.96,
      "duration": 3.6,
      "text": "it's actually very complicated and the",
      "timestamp": "08:21"
    },
    {
      "start": 503.8,
      "duration": 3.119,
      "text": "stuff that we think is uniquely human",
      "timestamp": "08:23"
    },
    {
      "start": 505.56,
      "duration": 3.28,
      "text": "like manipulating and generating",
      "timestamp": "08:25"
    },
    {
      "start": 506.919,
      "duration": 3.4,
      "text": "language playing chess playing go",
      "timestamp": "08:26"
    },
    {
      "start": 508.84,
      "duration": 4.16,
      "text": "playing poker",
      "timestamp": "08:28"
    },
    {
      "start": 510.319,
      "duration": 5.16,
      "text": "producing poetry and this kind of stuff",
      "timestamp": "08:30"
    },
    {
      "start": 513.0,
      "duration": 4.519,
      "text": "turn that to be easy",
      "timestamp": "08:33"
    },
    {
      "start": 515.479,
      "duration": 4.841,
      "text": "relatively okay and perhaps the reason",
      "timestamp": "08:35"
    },
    {
      "start": 517.519,
      "duration": 5.281,
      "text": "for this is this very simple calculation",
      "timestamp": "08:37"
    },
    {
      "start": 520.32,
      "duration": 6.12,
      "text": "um a typical llm nowadays is trained on",
      "timestamp": "08:40"
    },
    {
      "start": 522.8,
      "duration": 5.96,
      "text": "on the order of 30 trillion tokens three",
      "timestamp": "08:42"
    },
    {
      "start": 526.44,
      "duration": 5.16,
      "text": "10 to the 13 uh",
      "timestamp": "08:46"
    },
    {
      "start": 528.76,
      "duration": 6.0,
      "text": "tokens that's two to the 13 words",
      "timestamp": "08:48"
    },
    {
      "start": 531.6,
      "duration": 5.96,
      "text": "roughly each token is about three bytes",
      "timestamp": "08:51"
    },
    {
      "start": 534.76,
      "duration": 4.92,
      "text": "um so the data volume is roughly 10 to",
      "timestamp": "08:54"
    },
    {
      "start": 537.56,
      "duration": 4.24,
      "text": "the 14 bytes",
      "timestamp": "08:57"
    },
    {
      "start": 539.68,
      "duration": 4.36,
      "text": "uh it would take any of us uh almost",
      "timestamp": "08:59"
    },
    {
      "start": 541.8,
      "duration": 4.24,
      "text": "half a million years to read through all",
      "timestamp": "09:01"
    },
    {
      "start": 544.04,
      "duration": 3.919,
      "text": "that material it's basically all the",
      "timestamp": "09:04"
    },
    {
      "start": 546.04,
      "duration": 5.52,
      "text": "publicly available text on the",
      "timestamp": "09:06"
    },
    {
      "start": 547.959,
      "duration": 5.841,
      "text": "internet now consider her human child a",
      "timestamp": "09:07"
    },
    {
      "start": 551.56,
      "duration": 5.24,
      "text": "four-year-old has been awake a total of",
      "timestamp": "09:11"
    },
    {
      "start": 553.8,
      "duration": 4.44,
      "text": "16,000 hours which by the way is only 30",
      "timestamp": "09:13"
    },
    {
      "start": 556.8,
      "duration": 4.12,
      "text": "minutes of YouTube",
      "timestamp": "09:16"
    },
    {
      "start": 558.24,
      "duration": 5.32,
      "text": "uploads um we have 2 million optical",
      "timestamp": "09:18"
    },
    {
      "start": 560.92,
      "duration": 4.64,
      "text": "nerve fibers Each of which carries about",
      "timestamp": "09:20"
    },
    {
      "start": 563.56,
      "duration": 4.56,
      "text": "1 B per second maybe a bit less but it",
      "timestamp": "09:23"
    },
    {
      "start": 565.56,
      "duration": 5.44,
      "text": "doesn't matter so the data volume is",
      "timestamp": "09:25"
    },
    {
      "start": 568.12,
      "duration": 6.76,
      "text": "about 10 to the 14 in four years a",
      "timestamp": "09:28"
    },
    {
      "start": 571.0,
      "duration": 6.8,
      "text": "four-year-old child has seen as much",
      "timestamp": "09:31"
    },
    {
      "start": 574.88,
      "duration": 5.8,
      "text": "data as the biggest llm in the form of",
      "timestamp": "09:34"
    },
    {
      "start": 577.8,
      "duration": 6.039,
      "text": "visual perception and for blind children",
      "timestamp": "09:37"
    },
    {
      "start": 580.68,
      "duration": 6.56,
      "text": "is touch it's the same kind of uh",
      "timestamp": "09:40"
    },
    {
      "start": 583.839,
      "duration": 5.521,
      "text": "bandwidth uh that tells you a number of",
      "timestamp": "09:43"
    },
    {
      "start": 587.24,
      "duration": 3.599,
      "text": "things we're never going to get to human",
      "timestamp": "09:47"
    },
    {
      "start": 589.36,
      "duration": 4.12,
      "text": "level intelligence by just turning on",
      "timestamp": "09:49"
    },
    {
      "start": 590.839,
      "duration": 5.281,
      "text": "text it's not just not",
      "timestamp": "09:50"
    },
    {
      "start": 593.48,
      "duration": 4.599,
      "text": "happening despite what you know some",
      "timestamp": "09:53"
    },
    {
      "start": 596.12,
      "duration": 3.48,
      "text": "people who are have a vested interest in",
      "timestamp": "09:56"
    },
    {
      "start": 598.079,
      "duration": 2.961,
      "text": "this happening are telling us we're",
      "timestamp": "09:58"
    },
    {
      "start": 599.6,
      "duration": 3.84,
      "text": "going to reach you know PhD level",
      "timestamp": "09:59"
    },
    {
      "start": 601.04,
      "duration": 4.84,
      "text": "intelligence by next year it's just not",
      "timestamp": "10:01"
    },
    {
      "start": 603.44,
      "duration": 8.12,
      "text": "happening we might have PhD level in",
      "timestamp": "10:03"
    },
    {
      "start": 605.88,
      "duration": 8.079,
      "text": "some subfield in some area some uh um",
      "timestamp": "10:05"
    },
    {
      "start": 611.56,
      "duration": 6.399,
      "text": "problems like chess playing you know but",
      "timestamp": "10:11"
    },
    {
      "start": 613.959,
      "duration": 6.0,
      "text": "more of them um as long as we train",
      "timestamp": "10:13"
    },
    {
      "start": 617.959,
      "duration": 5.401,
      "text": "those systems specifically for for those",
      "timestamp": "10:17"
    },
    {
      "start": 619.959,
      "duration": 6.041,
      "text": "problems as um as Bernard was explaining",
      "timestamp": "10:19"
    },
    {
      "start": 623.36,
      "duration": 3.919,
      "text": "with the visual Illusions um there are a",
      "timestamp": "10:23"
    },
    {
      "start": 626.0,
      "duration": 3.04,
      "text": "lot of problems of this type when you",
      "timestamp": "10:26"
    },
    {
      "start": 627.279,
      "duration": 2.56,
      "text": "formulate a problem you pose a problem",
      "timestamp": "10:27"
    },
    {
      "start": 629.04,
      "duration": 3.64,
      "text": "to",
      "timestamp": "10:29"
    },
    {
      "start": 629.839,
      "duration": 4.921,
      "text": "an llm and if the problem is kind of a",
      "timestamp": "10:29"
    },
    {
      "start": 632.68,
      "duration": 4.159,
      "text": "standard puzzle the answer will be",
      "timestamp": "10:32"
    },
    {
      "start": 634.76,
      "duration": 4.12,
      "text": "regurgitated in just a few seconds if",
      "timestamp": "10:34"
    },
    {
      "start": 636.839,
      "duration": 3.201,
      "text": "you change the statement of the problem",
      "timestamp": "10:36"
    },
    {
      "start": 638.88,
      "duration": 2.72,
      "text": "a little bit the system will still",
      "timestamp": "10:38"
    },
    {
      "start": 640.04,
      "duration": 3.76,
      "text": "produce the same answer that it had",
      "timestamp": "10:40"
    },
    {
      "start": 641.6,
      "duration": 5.2,
      "text": "before because it has no real mental",
      "timestamp": "10:41"
    },
    {
      "start": 643.8,
      "duration": 8.68,
      "text": "model what goes on um in the in the",
      "timestamp": "10:43"
    },
    {
      "start": 646.8,
      "duration": 8.64,
      "text": "puzzle so how do um humans infants learn",
      "timestamp": "10:46"
    },
    {
      "start": 652.48,
      "duration": 4.359,
      "text": "how the world works and you know infants",
      "timestamp": "10:52"
    },
    {
      "start": 655.44,
      "duration": 2.6,
      "text": "accumulate a huge amount of background",
      "timestamp": "10:55"
    },
    {
      "start": 656.839,
      "duration": 3.281,
      "text": "knowledge about the world in the first",
      "timestamp": "10:56"
    },
    {
      "start": 658.04,
      "duration": 6.039,
      "text": "few months of life",
      "timestamp": "10:58"
    },
    {
      "start": 660.12,
      "duration": 7.12,
      "text": "um Notions like object permanence um",
      "timestamp": "11:00"
    },
    {
      "start": 664.079,
      "duration": 5.641,
      "text": "solidity rigidity natural categories of",
      "timestamp": "11:04"
    },
    {
      "start": 667.24,
      "duration": 4.08,
      "text": "objects before children understand",
      "timestamp": "11:07"
    },
    {
      "start": 669.72,
      "duration": 2.84,
      "text": "language they do understand the",
      "timestamp": "11:09"
    },
    {
      "start": 671.32,
      "duration": 4.199,
      "text": "difference between the table and the",
      "timestamp": "11:11"
    },
    {
      "start": 672.56,
      "duration": 5.88,
      "text": "chair um that kind of develops",
      "timestamp": "11:12"
    },
    {
      "start": 675.519,
      "duration": 5.161,
      "text": "naturally and they understand intuitive",
      "timestamp": "11:15"
    },
    {
      "start": 678.44,
      "duration": 4.12,
      "text": "physics notion like gravity inertia and",
      "timestamp": "11:18"
    },
    {
      "start": 680.68,
      "duration": 2.959,
      "text": "things of that type around the age of",
      "timestamp": "11:20"
    },
    {
      "start": 682.56,
      "duration": 3.959,
      "text": "nine",
      "timestamp": "11:22"
    },
    {
      "start": 683.639,
      "duration": 6.32,
      "text": "months um so it takes a long time uh",
      "timestamp": "11:23"
    },
    {
      "start": 686.519,
      "duration": 5.041,
      "text": "observation mostly um until four months",
      "timestamp": "11:26"
    },
    {
      "start": 689.959,
      "duration": 3.921,
      "text": "because babies don't really have any",
      "timestamp": "11:29"
    },
    {
      "start": 691.56,
      "duration": 7.44,
      "text": "influence on the on the world before",
      "timestamp": "11:31"
    },
    {
      "start": 693.88,
      "duration": 6.399,
      "text": "that um but then uh through interactions",
      "timestamp": "11:33"
    },
    {
      "start": 699.0,
      "duration": 3.72,
      "text": "but the amount of interaction that's",
      "timestamp": "11:39"
    },
    {
      "start": 700.279,
      "duration": 4.24,
      "text": "that's required is astonishingly",
      "timestamp": "11:40"
    },
    {
      "start": 702.72,
      "duration": 6.359,
      "text": "small",
      "timestamp": "11:42"
    },
    {
      "start": 704.519,
      "duration": 6.681,
      "text": "so if we want um AI system that can",
      "timestamp": "11:44"
    },
    {
      "start": 709.079,
      "duration": 5.361,
      "text": "reach eventually reach human level might",
      "timestamp": "11:49"
    },
    {
      "start": 711.2,
      "duration": 4.84,
      "text": "take a while um we call this Advanced",
      "timestamp": "11:51"
    },
    {
      "start": 714.44,
      "duration": 3.6,
      "text": "machine intelligence at meta we don't",
      "timestamp": "11:54"
    },
    {
      "start": 716.04,
      "duration": 3.64,
      "text": "like the term AGI artificial general",
      "timestamp": "11:56"
    },
    {
      "start": 718.04,
      "duration": 3.64,
      "text": "intelligence the reason being that that",
      "timestamp": "11:58"
    },
    {
      "start": 719.68,
      "duration": 4.68,
      "text": "human intelligence is actually quite",
      "timestamp": "11:59"
    },
    {
      "start": 721.68,
      "duration": 3.48,
      "text": "specialized and so calling it AGI is",
      "timestamp": "12:01"
    },
    {
      "start": 724.36,
      "duration": 3.96,
      "text": "kind of a",
      "timestamp": "12:04"
    },
    {
      "start": 725.16,
      "duration": 5.04,
      "text": "misnomer um so we call this Ami we",
      "timestamp": "12:05"
    },
    {
      "start": 728.32,
      "duration": 5.72,
      "text": "actually pronounce it Ami which means",
      "timestamp": "12:08"
    },
    {
      "start": 730.2,
      "duration": 6.319,
      "text": "friend in French um so we need systems",
      "timestamp": "12:10"
    },
    {
      "start": 734.04,
      "duration": 4.4,
      "text": "that um learn well models from sensory",
      "timestamp": "12:14"
    },
    {
      "start": 736.519,
      "duration": 3.721,
      "text": "input basically mental models of how the",
      "timestamp": "12:16"
    },
    {
      "start": 738.44,
      "duration": 4.88,
      "text": "world works that you can manipulate in",
      "timestamp": "12:18"
    },
    {
      "start": 740.24,
      "duration": 4.839,
      "text": "your mind learning 2D physics um from",
      "timestamp": "12:20"
    },
    {
      "start": 743.32,
      "duration": 4.68,
      "text": "video let's say systems that have",
      "timestamp": "12:23"
    },
    {
      "start": 745.079,
      "duration": 5.081,
      "text": "persistent memory systems that can plan",
      "timestamp": "12:25"
    },
    {
      "start": 748.0,
      "duration": 4.16,
      "text": "actions uh possibly",
      "timestamp": "12:28"
    },
    {
      "start": 750.16,
      "duration": 4.239,
      "text": "hierarchically so as to fulfill an",
      "timestamp": "12:30"
    },
    {
      "start": 752.16,
      "duration": 4.359,
      "text": "objective and systems that can",
      "timestamp": "12:32"
    },
    {
      "start": 754.399,
      "duration": 5.761,
      "text": "reason um and then systems that are",
      "timestamp": "12:34"
    },
    {
      "start": 756.519,
      "duration": 5.841,
      "text": "controllable and safe by Design not by",
      "timestamp": "12:36"
    },
    {
      "start": 760.16,
      "duration": 5.44,
      "text": "fine-tuning which is the the case for",
      "timestamp": "12:40"
    },
    {
      "start": 762.36,
      "duration": 5.039,
      "text": "llms now the only way I know to build",
      "timestamp": "12:42"
    },
    {
      "start": 765.6,
      "duration": 6.56,
      "text": "systems of this type is to change the",
      "timestamp": "12:45"
    },
    {
      "start": 767.399,
      "duration": 8.481,
      "text": "type of of inference um that um current",
      "timestamp": "12:47"
    },
    {
      "start": 772.16,
      "duration": 7.0,
      "text": "uh AI systems perform so right now the",
      "timestamp": "12:52"
    },
    {
      "start": 775.88,
      "duration": 5.44,
      "text": "way an llm uh performs inference is by",
      "timestamp": "12:55"
    },
    {
      "start": 779.16,
      "duration": 4.28,
      "text": "running through a fixed number of layers",
      "timestamp": "12:59"
    },
    {
      "start": 781.32,
      "duration": 4.04,
      "text": "of anet a transformer then producing a",
      "timestamp": "13:01"
    },
    {
      "start": 783.44,
      "duration": 3.0,
      "text": "token injecting that token on the input",
      "timestamp": "13:03"
    },
    {
      "start": 785.36,
      "duration": 3.36,
      "text": "and then running through a fixed number",
      "timestamp": "13:05"
    },
    {
      "start": 786.44,
      "duration": 5.28,
      "text": "of layers again and the problem with",
      "timestamp": "13:06"
    },
    {
      "start": 788.72,
      "duration": 4.64,
      "text": "this is that if you ask a simple",
      "timestamp": "13:08"
    },
    {
      "start": 791.72,
      "duration": 4.679,
      "text": "question or complex question and you ask",
      "timestamp": "13:11"
    },
    {
      "start": 793.36,
      "duration": 6.64,
      "text": "the system to answer by yes or no like",
      "timestamp": "13:13"
    },
    {
      "start": 796.399,
      "duration": 5.841,
      "text": "does 2 and two equal four yes or no or",
      "timestamp": "13:16"
    },
    {
      "start": 800.0,
      "duration": 4.24,
      "text": "does p equal NP yes or no it's going to",
      "timestamp": "13:20"
    },
    {
      "start": 802.24,
      "duration": 3.599,
      "text": "spend the exact same amount of",
      "timestamp": "13:22"
    },
    {
      "start": 804.24,
      "duration": 3.279,
      "text": "computation to answer those two",
      "timestamp": "13:24"
    },
    {
      "start": 805.839,
      "duration": 3.521,
      "text": "questions so people have been kind of",
      "timestamp": "13:25"
    },
    {
      "start": 807.519,
      "duration": 4.12,
      "text": "cheating and telling the system system",
      "timestamp": "13:27"
    },
    {
      "start": 809.36,
      "duration": 4.36,
      "text": "will explain you know the Chain of",
      "timestamp": "13:29"
    },
    {
      "start": 811.639,
      "duration": 3.681,
      "text": "Thought trick you you basically have the",
      "timestamp": "13:31"
    },
    {
      "start": 813.72,
      "duration": 2.72,
      "text": "system produce more tokens so that is",
      "timestamp": "13:33"
    },
    {
      "start": 815.32,
      "duration": 2.639,
      "text": "going to spend more competition",
      "timestamp": "13:35"
    },
    {
      "start": 816.44,
      "duration": 5.759,
      "text": "answering the question but that's kind",
      "timestamp": "13:36"
    },
    {
      "start": 817.959,
      "duration": 5.641,
      "text": "of a hack the way um a lot of inference",
      "timestamp": "13:37"
    },
    {
      "start": 822.199,
      "duration": 4.161,
      "text": "in statistics for example that's going",
      "timestamp": "13:42"
    },
    {
      "start": 823.6,
      "duration": 6.039,
      "text": "to make Mike happy actually um the way",
      "timestamp": "13:43"
    },
    {
      "start": 826.36,
      "duration": 6.279,
      "text": "inference works is is not that way in uh",
      "timestamp": "13:46"
    },
    {
      "start": 829.639,
      "duration": 4.961,
      "text": "In classical AI in statistics uh in",
      "timestamp": "13:49"
    },
    {
      "start": 832.639,
      "duration": 4.401,
      "text": "structure prediction a lot of different",
      "timestamp": "13:52"
    },
    {
      "start": 834.6,
      "duration": 4.72,
      "text": "domains the way it works is that you",
      "timestamp": "13:54"
    },
    {
      "start": 837.04,
      "duration": 4.159,
      "text": "have a function that measures the degree",
      "timestamp": "13:57"
    },
    {
      "start": 839.32,
      "duration": 4.12,
      "text": "of compatibility or incompatibility",
      "timestamp": "13:59"
    },
    {
      "start": 841.199,
      "duration": 4.481,
      "text": "between your observation and a proposed",
      "timestamp": "14:01"
    },
    {
      "start": 843.44,
      "duration": 4.8,
      "text": "output and then the inference process",
      "timestamp": "14:03"
    },
    {
      "start": 845.68,
      "duration": 5.279,
      "text": "consist in finding the value of an",
      "timestamp": "14:05"
    },
    {
      "start": 848.24,
      "duration": 4.8,
      "text": "output that minimizes this",
      "timestamp": "14:08"
    },
    {
      "start": 850.959,
      "duration": 3.8,
      "text": "incompatibility measure okay let's call",
      "timestamp": "14:10"
    },
    {
      "start": 853.04,
      "duration": 4.64,
      "text": "it an energy function so you have an",
      "timestamp": "14:13"
    },
    {
      "start": 854.759,
      "duration": 5.961,
      "text": "energy function okay represented by the",
      "timestamp": "14:14"
    },
    {
      "start": 857.68,
      "duration": 6.719,
      "text": "square box here on the right um when it",
      "timestamp": "14:17"
    },
    {
      "start": 860.72,
      "duration": 6.32,
      "text": "doesn't disappear and and the system",
      "timestamp": "14:20"
    },
    {
      "start": 864.399,
      "duration": 4.88,
      "text": "just do performs optimization for doing",
      "timestamp": "14:24"
    },
    {
      "start": 867.04,
      "duration": 4.159,
      "text": "inference now if the inference uh",
      "timestamp": "14:27"
    },
    {
      "start": 869.279,
      "duration": 3.601,
      "text": "problem is more difficult the system",
      "timestamp": "14:29"
    },
    {
      "start": 871.199,
      "duration": 3.521,
      "text": "will just spend more time performing",
      "timestamp": "14:31"
    },
    {
      "start": 872.88,
      "duration": 4.48,
      "text": "inference in other words they will think",
      "timestamp": "14:32"
    },
    {
      "start": 874.72,
      "duration": 4.679,
      "text": "about complex problems for longer than",
      "timestamp": "14:34"
    },
    {
      "start": 877.36,
      "duration": 3.24,
      "text": "simple ones for which the answer is",
      "timestamp": "14:37"
    },
    {
      "start": 879.399,
      "duration": 3.56,
      "text": "pretty",
      "timestamp": "14:39"
    },
    {
      "start": 880.6,
      "duration": 4.2,
      "text": "obvious um and this is really a very",
      "timestamp": "14:40"
    },
    {
      "start": 882.959,
      "duration": 4.401,
      "text": "classical thing to do in classical",
      "timestamp": "14:42"
    },
    {
      "start": 884.8,
      "duration": 5.8,
      "text": "classical AI is all about reasoning and",
      "timestamp": "14:44"
    },
    {
      "start": 887.36,
      "duration": 6.24,
      "text": "uh search and therefore optimization",
      "timestamp": "14:47"
    },
    {
      "start": 890.6,
      "duration": 4.679,
      "text": "pretty much any computational problem",
      "timestamp": "14:50"
    },
    {
      "start": 893.6,
      "duration": 3.88,
      "text": "can be reduce an optimization problem",
      "timestamp": "14:53"
    },
    {
      "start": 895.279,
      "duration": 5.161,
      "text": "essentially or search problem uh it's",
      "timestamp": "14:55"
    },
    {
      "start": 897.48,
      "duration": 4.359,
      "text": "also very classical in probabilistic",
      "timestamp": "14:57"
    },
    {
      "start": 900.44,
      "duration": 4.56,
      "text": "modeling like probabilistic graphical",
      "timestamp": "15:00"
    },
    {
      "start": 901.839,
      "duration": 5.8,
      "text": "models and things of that type so this",
      "timestamp": "15:01"
    },
    {
      "start": 905.0,
      "duration": 5.88,
      "text": "type of inference would be more akin to",
      "timestamp": "15:05"
    },
    {
      "start": 907.639,
      "duration": 6.281,
      "text": "what psychologists call system two in uh",
      "timestamp": "15:07"
    },
    {
      "start": 910.88,
      "duration": 7.639,
      "text": "sort of human U mind if you want system",
      "timestamp": "15:10"
    },
    {
      "start": 913.92,
      "duration": 5.96,
      "text": "two is when you think about what action",
      "timestamp": "15:13"
    },
    {
      "start": 918.519,
      "duration": 3.601,
      "text": "or sequence of actions you're going to",
      "timestamp": "15:18"
    },
    {
      "start": 919.88,
      "duration": 3.8,
      "text": "take before you you you take them you",
      "timestamp": "15:19"
    },
    {
      "start": 922.12,
      "duration": 3.0,
      "text": "think about something before doing it",
      "timestamp": "15:22"
    },
    {
      "start": 923.68,
      "duration": 3.12,
      "text": "and the system one is when you can do",
      "timestamp": "15:23"
    },
    {
      "start": 925.12,
      "duration": 4.639,
      "text": "the thing without thinking about it you",
      "timestamp": "15:25"
    },
    {
      "start": 926.8,
      "duration": 5.32,
      "text": "know it becomes sort of subconscious so",
      "timestamp": "15:26"
    },
    {
      "start": 929.759,
      "duration": 5.721,
      "text": "llms are system one what I'm proposing",
      "timestamp": "15:29"
    },
    {
      "start": 932.12,
      "duration": 6.6,
      "text": "is system two um and then the",
      "timestamp": "15:32"
    },
    {
      "start": 935.48,
      "duration": 5.96,
      "text": "appropriate um sort of semi theoretical",
      "timestamp": "15:35"
    },
    {
      "start": 938.72,
      "duration": 4.32,
      "text": "framework to um explain this is energy",
      "timestamp": "15:38"
    },
    {
      "start": 941.44,
      "duration": 3.879,
      "text": "based models which I'm not going to have",
      "timestamp": "15:41"
    },
    {
      "start": 943.04,
      "duration": 3.799,
      "text": "time to get into too much detail but",
      "timestamp": "15:43"
    },
    {
      "start": 945.319,
      "duration": 3.921,
      "text": "basically you capture the dependency",
      "timestamp": "15:45"
    },
    {
      "start": 946.839,
      "duration": 7.0,
      "text": "between variables let's say observations",
      "timestamp": "15:46"
    },
    {
      "start": 949.24,
      "duration": 7.159,
      "text": "X and uh outputs uh y through an energy",
      "timestamp": "15:49"
    },
    {
      "start": 953.839,
      "duration": 4.201,
      "text": "function that takes low value where when",
      "timestamp": "15:53"
    },
    {
      "start": 956.399,
      "duration": 4.041,
      "text": "X and Y are compatible and then larger",
      "timestamp": "15:56"
    },
    {
      "start": 958.04,
      "duration": 4.719,
      "text": "values when X and why are not compatible",
      "timestamp": "15:58"
    },
    {
      "start": 960.44,
      "duration": 4.56,
      "text": "you don't want to just compute y from X",
      "timestamp": "16:00"
    },
    {
      "start": 962.759,
      "duration": 4.52,
      "text": "as we just saw you just want an energy",
      "timestamp": "16:02"
    },
    {
      "start": 965.0,
      "duration": 4.24,
      "text": "function that measures the degree of",
      "timestamp": "16:05"
    },
    {
      "start": 967.279,
      "duration": 4.881,
      "text": "incompatibility and then you know given",
      "timestamp": "16:07"
    },
    {
      "start": 969.24,
      "duration": 5.12,
      "text": "an X find a y that has low energy for",
      "timestamp": "16:09"
    },
    {
      "start": 972.16,
      "duration": 2.2,
      "text": "that",
      "timestamp": "16:12"
    },
    {
      "start": 974.48,
      "duration": 5.599,
      "text": "X okay so now let's go a little bit into",
      "timestamp": "16:14"
    },
    {
      "start": 978.56,
      "duration": 4.639,
      "text": "the details of how this type of",
      "timestamp": "16:18"
    },
    {
      "start": 980.079,
      "duration": 7.161,
      "text": "architecture can be built so essentially",
      "timestamp": "16:20"
    },
    {
      "start": 983.199,
      "duration": 6.281,
      "text": "and how it kind of relates to um uh",
      "timestamp": "16:23"
    },
    {
      "start": 987.24,
      "duration": 4.76,
      "text": "thinking or planning",
      "timestamp": "16:27"
    },
    {
      "start": 989.48,
      "duration": 4.839,
      "text": "uh so a system would look like this um",
      "timestamp": "16:29"
    },
    {
      "start": 992.0,
      "duration": 3.92,
      "text": "you you get observation from the world",
      "timestamp": "16:32"
    },
    {
      "start": 994.319,
      "duration": 3.801,
      "text": "it go through a perception module that",
      "timestamp": "16:34"
    },
    {
      "start": 995.92,
      "duration": 4.479,
      "text": "produces an estimate about the state of",
      "timestamp": "16:35"
    },
    {
      "start": 998.12,
      "duration": 3.68,
      "text": "the world but of course the state of the",
      "timestamp": "16:38"
    },
    {
      "start": 1000.399,
      "duration": 3.481,
      "text": "world is not completely observable so",
      "timestamp": "16:40"
    },
    {
      "start": 1001.8,
      "duration": 4.2,
      "text": "you may have to combine this with a",
      "timestamp": "16:41"
    },
    {
      "start": 1003.88,
      "duration": 3.959,
      "text": "memory the content of a memory that",
      "timestamp": "16:43"
    },
    {
      "start": 1006.0,
      "duration": 3.88,
      "text": "constit you know contains your idea of",
      "timestamp": "16:46"
    },
    {
      "start": 1007.839,
      "duration": 3.12,
      "text": "the state of the world you don't uh",
      "timestamp": "16:47"
    },
    {
      "start": 1009.88,
      "duration": 3.959,
      "text": "currently",
      "timestamp": "16:49"
    },
    {
      "start": 1010.959,
      "duration": 5.721,
      "text": "perceive um and the combination of those",
      "timestamp": "16:50"
    },
    {
      "start": 1013.839,
      "duration": 5.721,
      "text": "two goes into a world model so what is a",
      "timestamp": "16:53"
    },
    {
      "start": 1016.68,
      "duration": 4.639,
      "text": "world model World model is given given a",
      "timestamp": "16:56"
    },
    {
      "start": 1019.56,
      "duration": 4.6,
      "text": "current estimate of the state of the",
      "timestamp": "16:59"
    },
    {
      "start": 1021.319,
      "duration": 6.201,
      "text": "world which is in an abstract",
      "timestamp": "17:01"
    },
    {
      "start": 1024.16,
      "duration": 5.56,
      "text": "representation space and given an action",
      "timestamp": "17:04"
    },
    {
      "start": 1027.52,
      "duration": 5.679,
      "text": "sequence that you imagine",
      "timestamp": "17:07"
    },
    {
      "start": 1029.72,
      "duration": 5.64,
      "text": "taking uh your world model predicts the",
      "timestamp": "17:09"
    },
    {
      "start": 1033.199,
      "duration": 5.041,
      "text": "the resulting state of the world that",
      "timestamp": "17:13"
    },
    {
      "start": 1035.36,
      "duration": 4.839,
      "text": "will um occur after you take that",
      "timestamp": "17:15"
    },
    {
      "start": 1038.24,
      "duration": 4.64,
      "text": "sequence of actions okay that's what a",
      "timestamp": "17:18"
    },
    {
      "start": 1040.199,
      "duration": 5.081,
      "text": "world model is if I tell you imagine a",
      "timestamp": "17:20"
    },
    {
      "start": 1042.88,
      "duration": 4.439,
      "text": "cube floating in the air in front of you",
      "timestamp": "17:22"
    },
    {
      "start": 1045.28,
      "duration": 4.48,
      "text": "okay now rotate this Cube by 90 degrees",
      "timestamp": "17:25"
    },
    {
      "start": 1047.319,
      "duration": 4.281,
      "text": "around a vertical axis",
      "timestamp": "17:27"
    },
    {
      "start": 1049.76,
      "duration": 3.56,
      "text": "um what does it look like it's very easy",
      "timestamp": "17:29"
    },
    {
      "start": 1051.6,
      "duration": 5.36,
      "text": "for you to kind of have this metal model",
      "timestamp": "17:31"
    },
    {
      "start": 1053.32,
      "duration": 3.64,
      "text": "of a cube rotating",
      "timestamp": "17:33"
    },
    {
      "start": 1058.52,
      "duration": 4.0,
      "text": "um okay",
      "timestamp": "17:38"
    },
    {
      "start": 1097.0,
      "duration": 4.0,
      "text": "okay okay",
      "timestamp": "18:17"
    },
    {
      "start": 1111.0,
      "duration": 2.2,
      "text": "okay",
      "timestamp": "18:31"
    },
    {
      "start": 1113.24,
      "duration": 5.96,
      "text": "hopefully all",
      "timestamp": "18:33"
    },
    {
      "start": 1116.159,
      "duration": 5.601,
      "text": "right let's hope this will be more",
      "timestamp": "18:36"
    },
    {
      "start": 1119.2,
      "duration": 6.8,
      "text": "stable",
      "timestamp": "18:39"
    },
    {
      "start": 1121.76,
      "duration": 9.279,
      "text": "okay um 50 Herz not 60",
      "timestamp": "18:41"
    },
    {
      "start": 1126.0,
      "duration": 7.6,
      "text": "HZ okay so uh what you can do now is uh",
      "timestamp": "18:46"
    },
    {
      "start": 1131.039,
      "duration": 7.921,
      "text": "feed okay hang",
      "timestamp": "18:51"
    },
    {
      "start": 1133.6,
      "duration": 5.36,
      "text": "on make a more radical Choice here",
      "timestamp": "18:53"
    },
    {
      "start": 1153.36,
      "duration": 3.319,
      "text": "okay this doesn't look like it was a",
      "timestamp": "19:13"
    },
    {
      "start": 1154.559,
      "duration": 2.12,
      "text": "good",
      "timestamp": "19:14"
    },
    {
      "start": 1158.2,
      "duration": 4.56,
      "text": "idea oh I know what I",
      "timestamp": "19:18"
    },
    {
      "start": 1179.2,
      "duration": 2.32,
      "text": "that's",
      "timestamp": "19:39"
    },
    {
      "start": 1187.88,
      "duration": 4.24,
      "text": "nice okay I think we're going to have",
      "timestamp": "19:47"
    },
    {
      "start": 1190.52,
      "duration": 4.76,
      "text": "human level intelligence before we have",
      "timestamp": "19:50"
    },
    {
      "start": 1192.12,
      "duration": 3.16,
      "text": "audio video that actually",
      "timestamp": "19:52"
    },
    {
      "start": 1196.08,
      "duration": 7.32,
      "text": "works okay um so so if we have this",
      "timestamp": "19:56"
    },
    {
      "start": 1199.84,
      "duration": 5.24,
      "text": "world model which is able to predict the",
      "timestamp": "19:59"
    },
    {
      "start": 1203.4,
      "duration": 4.92,
      "text": "result of a sequence of",
      "timestamp": "20:03"
    },
    {
      "start": 1205.08,
      "duration": 4.92,
      "text": "actions um we can feed it to an",
      "timestamp": "20:05"
    },
    {
      "start": 1208.32,
      "duration": 3.92,
      "text": "objective which is a task objective that",
      "timestamp": "20:08"
    },
    {
      "start": 1210.0,
      "duration": 5.6,
      "text": "measure to what extent the predicted",
      "timestamp": "20:10"
    },
    {
      "start": 1212.24,
      "duration": 5.84,
      "text": "final State U satisfies a goal that we",
      "timestamp": "20:12"
    },
    {
      "start": 1215.6,
      "duration": 5.319,
      "text": "set for ourselves it's just a cost",
      "timestamp": "20:15"
    },
    {
      "start": 1218.08,
      "duration": 5.56,
      "text": "function um and we also can set some uh",
      "timestamp": "20:18"
    },
    {
      "start": 1220.919,
      "duration": 4.921,
      "text": "guardrail objectives think of them as",
      "timestamp": "20:20"
    },
    {
      "start": 1223.64,
      "duration": 5.2,
      "text": "constraints that need to be satisfied",
      "timestamp": "20:23"
    },
    {
      "start": 1225.84,
      "duration": 5.04,
      "text": "for the system to behave in a safe",
      "timestamp": "20:25"
    },
    {
      "start": 1228.84,
      "duration": 4.88,
      "text": "manner right so those guardes will be",
      "timestamp": "20:28"
    },
    {
      "start": 1230.88,
      "duration": 5.0,
      "text": "explicitly implemented and the way the",
      "timestamp": "20:30"
    },
    {
      "start": 1233.72,
      "duration": 4.199,
      "text": "system proceeds is by optimization it's",
      "timestamp": "20:33"
    },
    {
      "start": 1235.88,
      "duration": 6.039,
      "text": "looking for an action sequence that",
      "timestamp": "20:35"
    },
    {
      "start": 1237.919,
      "duration": 6.481,
      "text": "minimizes the task objective and the uh",
      "timestamp": "20:37"
    },
    {
      "start": 1241.919,
      "duration": 3.721,
      "text": "guard rail objectives at runtime okay",
      "timestamp": "20:41"
    },
    {
      "start": 1244.4,
      "duration": 3.12,
      "text": "we're not talking about learning here",
      "timestamp": "20:44"
    },
    {
      "start": 1245.64,
      "duration": 4.44,
      "text": "we're just talking about",
      "timestamp": "20:45"
    },
    {
      "start": 1247.52,
      "duration": 4.72,
      "text": "inference um and that will guarantee the",
      "timestamp": "20:47"
    },
    {
      "start": 1250.08,
      "duration": 3.839,
      "text": "safety of the system because uh the",
      "timestamp": "20:50"
    },
    {
      "start": 1252.24,
      "duration": 3.48,
      "text": "guard rails guarantee safety and there",
      "timestamp": "20:52"
    },
    {
      "start": 1253.919,
      "duration": 4.12,
      "text": "is no way you can Jailbreak that system",
      "timestamp": "20:53"
    },
    {
      "start": 1255.72,
      "duration": 3.76,
      "text": "by giving it a prompt that will you know",
      "timestamp": "20:55"
    },
    {
      "start": 1258.039,
      "duration": 3.041,
      "text": "have it ES Escape its guardwire",
      "timestamp": "20:58"
    },
    {
      "start": 1259.48,
      "duration": 2.88,
      "text": "objectives the guard objectives would be",
      "timestamp": "20:59"
    },
    {
      "start": 1261.08,
      "duration": 4.28,
      "text": "just",
      "timestamp": "21:01"
    },
    {
      "start": 1262.36,
      "duration": 6.08,
      "text": "hardwired they might be trained but",
      "timestamp": "21:02"
    },
    {
      "start": 1265.36,
      "duration": 5.52,
      "text": "hardwired now a sequence of actions",
      "timestamp": "21:05"
    },
    {
      "start": 1268.44,
      "duration": 4.719,
      "text": "should probably use a single World model",
      "timestamp": "21:08"
    },
    {
      "start": 1270.88,
      "duration": 4.36,
      "text": "that you repeat you use repeatedly over",
      "timestamp": "21:10"
    },
    {
      "start": 1273.159,
      "duration": 3.961,
      "text": "multiple time steps okay so you have a",
      "timestamp": "21:13"
    },
    {
      "start": 1275.24,
      "duration": 3.28,
      "text": "one model if you did the first action it",
      "timestamp": "21:15"
    },
    {
      "start": 1277.12,
      "duration": 3.36,
      "text": "predicts the next state and the second",
      "timestamp": "21:17"
    },
    {
      "start": 1278.52,
      "duration": 4.8,
      "text": "action predicts the second next state",
      "timestamp": "21:18"
    },
    {
      "start": 1280.48,
      "duration": 6.4,
      "text": "you can have guard R cost and objective",
      "timestamp": "21:20"
    },
    {
      "start": 1283.32,
      "duration": 6.08,
      "text": "uh task uh task objectives along the",
      "timestamp": "21:23"
    },
    {
      "start": 1286.88,
      "duration": 4.56,
      "text": "trajectory the ad specifying what",
      "timestamp": "21:26"
    },
    {
      "start": 1289.4,
      "duration": 3.519,
      "text": "optimization algorithm we can use it",
      "timestamp": "21:29"
    },
    {
      "start": 1291.44,
      "duration": 4.56,
      "text": "doesn't really matter for the discussion",
      "timestamp": "21:31"
    },
    {
      "start": 1292.919,
      "duration": 4.76,
      "text": "that we have um if the world happens not",
      "timestamp": "21:32"
    },
    {
      "start": 1296.0,
      "duration": 4.039,
      "text": "to be completely deterministic and",
      "timestamp": "21:36"
    },
    {
      "start": 1297.679,
      "duration": 4.801,
      "text": "predictable the world model may need to",
      "timestamp": "21:37"
    },
    {
      "start": 1300.039,
      "duration": 3.841,
      "text": "have latent variables to account for all",
      "timestamp": "21:40"
    },
    {
      "start": 1302.48,
      "duration": 4.6,
      "text": "the things about the world that we do",
      "timestamp": "21:42"
    },
    {
      "start": 1303.88,
      "duration": 6.6,
      "text": "not observe and that uh you know makes",
      "timestamp": "21:43"
    },
    {
      "start": 1307.08,
      "duration": 5.0,
      "text": "our prediction basically um inexact and",
      "timestamp": "21:47"
    },
    {
      "start": 1310.48,
      "duration": 3.559,
      "text": "ultimately what we want is a system that",
      "timestamp": "21:50"
    },
    {
      "start": 1312.08,
      "duration": 4.199,
      "text": "can plan hierarchically so something",
      "timestamp": "21:52"
    },
    {
      "start": 1314.039,
      "duration": 6.12,
      "text": "that may have several levels of",
      "timestamp": "21:54"
    },
    {
      "start": 1316.279,
      "duration": 6.52,
      "text": "abstraction in such a way that um at the",
      "timestamp": "21:56"
    },
    {
      "start": 1320.159,
      "duration": 4.281,
      "text": "low level we plan low level actions like",
      "timestamp": "22:00"
    },
    {
      "start": 1322.799,
      "duration": 5.681,
      "text": "basically muscle control but at a high",
      "timestamp": "22:02"
    },
    {
      "start": 1324.44,
      "duration": 5.8,
      "text": "level we can plan abstract macro action",
      "timestamp": "22:04"
    },
    {
      "start": 1328.48,
      "duration": 4.04,
      "text": "where the world model predicts at longer",
      "timestamp": "22:08"
    },
    {
      "start": 1330.24,
      "duration": 4.08,
      "text": "time steps but in a representation space",
      "timestamp": "22:10"
    },
    {
      "start": 1332.52,
      "duration": 3.96,
      "text": "that is more abstract and therefore",
      "timestamp": "22:12"
    },
    {
      "start": 1334.32,
      "duration": 4.68,
      "text": "contains fewer detail so if I want if",
      "timestamp": "22:14"
    },
    {
      "start": 1336.48,
      "duration": 5.84,
      "text": "I'm sitting at my office at NYU and I",
      "timestamp": "22:16"
    },
    {
      "start": 1339.0,
      "duration": 5.279,
      "text": "decide to go to Paris um I can decompose",
      "timestamp": "22:19"
    },
    {
      "start": 1342.32,
      "duration": 3.359,
      "text": "that task into two sub tasks go to the",
      "timestamp": "22:22"
    },
    {
      "start": 1344.279,
      "duration": 3.52,
      "text": "airport and catch a",
      "timestamp": "22:24"
    },
    {
      "start": 1345.679,
      "duration": 4.0,
      "text": "plane okay now I have a sub goal going",
      "timestamp": "22:25"
    },
    {
      "start": 1347.799,
      "duration": 3.441,
      "text": "to the airport",
      "timestamp": "22:27"
    },
    {
      "start": 1349.679,
      "duration": 3.841,
      "text": "um I'm in New York city so going to the",
      "timestamp": "22:29"
    },
    {
      "start": 1351.24,
      "duration": 4.559,
      "text": "airport consist in going down on the",
      "timestamp": "22:31"
    },
    {
      "start": 1353.52,
      "duration": 5.2,
      "text": "street and haing a taxi how do I go down",
      "timestamp": "22:33"
    },
    {
      "start": 1355.799,
      "duration": 5.281,
      "text": "in the street well I need to uh get to",
      "timestamp": "22:35"
    },
    {
      "start": 1358.72,
      "duration": 3.76,
      "text": "the elevator push the button go down go",
      "timestamp": "22:38"
    },
    {
      "start": 1361.08,
      "duration": 3.599,
      "text": "out the building how do I go to the",
      "timestamp": "22:41"
    },
    {
      "start": 1362.48,
      "duration": 4.48,
      "text": "elevator well I need to stand up for my",
      "timestamp": "22:42"
    },
    {
      "start": 1364.679,
      "duration": 4.561,
      "text": "chair pick up my bag open the door walk",
      "timestamp": "22:44"
    },
    {
      "start": 1366.96,
      "duration": 3.959,
      "text": "to the elevator avoid all the obstacles",
      "timestamp": "22:46"
    },
    {
      "start": 1369.24,
      "duration": 3.48,
      "text": "and then at some point I get to a level",
      "timestamp": "22:49"
    },
    {
      "start": 1370.919,
      "duration": 5.081,
      "text": "where I don't need to plan I can just",
      "timestamp": "22:50"
    },
    {
      "start": 1372.72,
      "duration": 5.04,
      "text": "take the actions um but we do those type",
      "timestamp": "22:52"
    },
    {
      "start": 1376.0,
      "duration": 4.159,
      "text": "of this type of hierarchical planning",
      "timestamp": "22:56"
    },
    {
      "start": 1377.76,
      "duration": 4.2,
      "text": "absolutely all the time and I tell you",
      "timestamp": "22:57"
    },
    {
      "start": 1380.159,
      "duration": 3.281,
      "text": "we have no idea how to do this with",
      "timestamp": "23:00"
    },
    {
      "start": 1381.96,
      "duration": 3.52,
      "text": "learning",
      "timestamp": "23:01"
    },
    {
      "start": 1383.44,
      "duration": 4.2,
      "text": "machines almost every robot does",
      "timestamp": "23:03"
    },
    {
      "start": 1385.48,
      "duration": 3.88,
      "text": "hierarchical planning but the the",
      "timestamp": "23:05"
    },
    {
      "start": 1387.64,
      "duration": 3.72,
      "text": "representations at every level of the",
      "timestamp": "23:07"
    },
    {
      "start": 1389.36,
      "duration": 5.0,
      "text": "hierarchy are hand",
      "timestamp": "23:09"
    },
    {
      "start": 1391.36,
      "duration": 4.52,
      "text": "handcrafted what we need is to train an",
      "timestamp": "23:11"
    },
    {
      "start": 1394.36,
      "duration": 4.16,
      "text": "architecture perhaps of the type that",
      "timestamp": "23:14"
    },
    {
      "start": 1395.88,
      "duration": 5.08,
      "text": "I'm describing here so that it can learn",
      "timestamp": "23:15"
    },
    {
      "start": 1398.52,
      "duration": 4.759,
      "text": "repres abstract representations not just",
      "timestamp": "23:18"
    },
    {
      "start": 1400.96,
      "duration": 3.92,
      "text": "of the state of the world but also",
      "timestamp": "23:20"
    },
    {
      "start": 1403.279,
      "duration": 3.961,
      "text": "prediction World models that predict",
      "timestamp": "23:23"
    },
    {
      "start": 1404.88,
      "duration": 4.84,
      "text": "what's going to happen but also abstract",
      "timestamp": "23:24"
    },
    {
      "start": 1407.24,
      "duration": 4.6,
      "text": "actions at levels of abstraction so we",
      "timestamp": "23:27"
    },
    {
      "start": 1409.72,
      "duration": 4.88,
      "text": "can do this hierarchical planning",
      "timestamp": "23:29"
    },
    {
      "start": 1411.84,
      "duration": 6.4,
      "text": "animals do this",
      "timestamp": "23:31"
    },
    {
      "start": 1414.6,
      "duration": 6.52,
      "text": "okay humans do this very well we're",
      "timestamp": "23:34"
    },
    {
      "start": 1418.24,
      "duration": 6.439,
      "text": "completely incapable of doing this withm",
      "timestamp": "23:38"
    },
    {
      "start": 1421.12,
      "duration": 7.679,
      "text": "today if you're starting a PhD great",
      "timestamp": "23:41"
    },
    {
      "start": 1424.679,
      "duration": 4.12,
      "text": "topic might take more than three",
      "timestamp": "23:44"
    },
    {
      "start": 1428.919,
      "duration": 5.401,
      "text": "years",
      "timestamp": "23:48"
    },
    {
      "start": 1430.44,
      "duration": 6.359,
      "text": "um so I with all those Reflections about",
      "timestamp": "23:50"
    },
    {
      "start": 1434.32,
      "duration": 4.56,
      "text": "3 years ago I wrote a long paper where I",
      "timestamp": "23:54"
    },
    {
      "start": 1436.799,
      "duration": 4.201,
      "text": "kind of explained sort of where where I",
      "timestamp": "23:56"
    },
    {
      "start": 1438.88,
      "duration": 4.36,
      "text": "think AI research should be focusing on",
      "timestamp": "23:58"
    },
    {
      "start": 1441.0,
      "duration": 4.88,
      "text": "so this so before the whole GP CH GPT",
      "timestamp": "24:01"
    },
    {
      "start": 1443.24,
      "duration": 4.64,
      "text": "craze um I haven't changed my mind about",
      "timestamp": "24:03"
    },
    {
      "start": 1445.88,
      "duration": 4.159,
      "text": "this CH GPT hasn't Chang anything we",
      "timestamp": "24:05"
    },
    {
      "start": 1447.88,
      "duration": 5.0,
      "text": "wereing Els before that so we knew what",
      "timestamp": "24:07"
    },
    {
      "start": 1450.039,
      "duration": 4.721,
      "text": "was coming anyway um this is the paper",
      "timestamp": "24:10"
    },
    {
      "start": 1452.88,
      "duration": 3.88,
      "text": "um a path towards autonomous machine",
      "timestamp": "24:12"
    },
    {
      "start": 1454.76,
      "duration": 3.48,
      "text": "intelligence that we now call Advanced",
      "timestamp": "24:14"
    },
    {
      "start": 1456.76,
      "duration": 4.159,
      "text": "machine intelligence because autonomous",
      "timestamp": "24:16"
    },
    {
      "start": 1458.24,
      "duration": 4.08,
      "text": "just scares people um and it's on open",
      "timestamp": "24:18"
    },
    {
      "start": 1460.919,
      "duration": 3.561,
      "text": "review it's not on",
      "timestamp": "24:20"
    },
    {
      "start": 1462.32,
      "duration": 4.28,
      "text": "archive and there's various versions of",
      "timestamp": "24:22"
    },
    {
      "start": 1464.48,
      "duration": 4.4,
      "text": "this talk that I've I've given various",
      "timestamp": "24:24"
    },
    {
      "start": 1466.6,
      "duration": 3.72,
      "text": "ways okay so very natural idea for for",
      "timestamp": "24:26"
    },
    {
      "start": 1468.88,
      "duration": 2.32,
      "text": "getting systems to understand how the",
      "timestamp": "24:28"
    },
    {
      "start": 1470.32,
      "duration": 5.239,
      "text": "world",
      "timestamp": "24:30"
    },
    {
      "start": 1471.2,
      "duration": 6.24,
      "text": "works is um using the same process that",
      "timestamp": "24:31"
    },
    {
      "start": 1475.559,
      "duration": 4.441,
      "text": "we used to",
      "timestamp": "24:35"
    },
    {
      "start": 1477.44,
      "duration": 4.16,
      "text": "um to to train system for natural",
      "timestamp": "24:37"
    },
    {
      "start": 1480.0,
      "duration": 4.6,
      "text": "language and apply this to let's say",
      "timestamp": "24:40"
    },
    {
      "start": 1481.6,
      "duration": 4.24,
      "text": "video okay if a system is capable of",
      "timestamp": "24:41"
    },
    {
      "start": 1484.6,
      "duration": 3.12,
      "text": "predicting what's going to happen in a",
      "timestamp": "24:44"
    },
    {
      "start": 1485.84,
      "duration": 3.199,
      "text": "video you show it A short segment of",
      "timestamp": "24:45"
    },
    {
      "start": 1487.72,
      "duration": 3.199,
      "text": "video and you ask it to predict what's",
      "timestamp": "24:47"
    },
    {
      "start": 1489.039,
      "duration": 5.681,
      "text": "going to happen next presumably it would",
      "timestamp": "24:49"
    },
    {
      "start": 1490.919,
      "duration": 6.721,
      "text": "have understood the underlying structure",
      "timestamp": "24:50"
    },
    {
      "start": 1494.72,
      "duration": 4.72,
      "text": "of the world um and so training it to",
      "timestamp": "24:54"
    },
    {
      "start": 1497.64,
      "duration": 3.039,
      "text": "make that prediction might actually",
      "timestamp": "24:57"
    },
    {
      "start": 1499.44,
      "duration": 3.44,
      "text": "cause the system to understand the",
      "timestamp": "24:59"
    },
    {
      "start": 1500.679,
      "duration": 4.36,
      "text": "annoing structure of the",
      "timestamp": "25:00"
    },
    {
      "start": 1502.88,
      "duration": 5.0,
      "text": "world it works for",
      "timestamp": "25:02"
    },
    {
      "start": 1505.039,
      "duration": 5.401,
      "text": "text because predicting words is",
      "timestamp": "25:05"
    },
    {
      "start": 1507.88,
      "duration": 5.08,
      "text": "relatively simple why is predicting",
      "timestamp": "25:07"
    },
    {
      "start": 1510.44,
      "duration": 4.04,
      "text": "words simple because words um there's",
      "timestamp": "25:10"
    },
    {
      "start": 1512.96,
      "duration": 3.24,
      "text": "only a finite number of possible words",
      "timestamp": "25:12"
    },
    {
      "start": 1514.48,
      "duration": 4.28,
      "text": "certainly a finite number of possible",
      "timestamp": "25:14"
    },
    {
      "start": 1516.2,
      "duration": 5.32,
      "text": "tokens and so we can't predict exactly",
      "timestamp": "25:16"
    },
    {
      "start": 1518.76,
      "duration": 4.32,
      "text": "which word will follow another word or",
      "timestamp": "25:18"
    },
    {
      "start": 1521.52,
      "duration": 3.2,
      "text": "what what word is missing in the text",
      "timestamp": "25:21"
    },
    {
      "start": 1523.08,
      "duration": 3.839,
      "text": "but we can produce a probability",
      "timestamp": "25:23"
    },
    {
      "start": 1524.72,
      "duration": 4.839,
      "text": "distribution or score for every possible",
      "timestamp": "25:24"
    },
    {
      "start": 1526.919,
      "duration": 6.081,
      "text": "word in the dictionary we cannot do this",
      "timestamp": "25:26"
    },
    {
      "start": 1529.559,
      "duration": 4.72,
      "text": "for images for video frames we do not",
      "timestamp": "25:29"
    },
    {
      "start": 1533.0,
      "duration": 2.84,
      "text": "have good ways of representing",
      "timestamp": "25:33"
    },
    {
      "start": 1534.279,
      "duration": 5.361,
      "text": "distributions of our video",
      "timestamp": "25:34"
    },
    {
      "start": 1535.84,
      "duration": 5.52,
      "text": "frames um every attempt to do this uh",
      "timestamp": "25:35"
    },
    {
      "start": 1539.64,
      "duration": 3.24,
      "text": "basically bumps into mathematical",
      "timestamp": "25:39"
    },
    {
      "start": 1541.36,
      "duration": 5.199,
      "text": "intract",
      "timestamp": "25:41"
    },
    {
      "start": 1542.88,
      "duration": 5.84,
      "text": "abilities um and so you could try to get",
      "timestamp": "25:42"
    },
    {
      "start": 1546.559,
      "duration": 4.281,
      "text": "around the problem using you know um",
      "timestamp": "25:46"
    },
    {
      "start": 1548.72,
      "duration": 4.959,
      "text": "statistics and and the math that was",
      "timestamp": "25:48"
    },
    {
      "start": 1550.84,
      "duration": 5.199,
      "text": "invented by by physicists you know vial",
      "timestamp": "25:50"
    },
    {
      "start": 1553.679,
      "duration": 3.641,
      "text": "inference and all that stuff but in fact",
      "timestamp": "25:53"
    },
    {
      "start": 1556.039,
      "duration": 3.321,
      "text": "it's better to just throw away the",
      "timestamp": "25:56"
    },
    {
      "start": 1557.32,
      "duration": 4.239,
      "text": "entire idea of doing probabilistic",
      "timestamp": "25:57"
    },
    {
      "start": 1559.36,
      "duration": 3.72,
      "text": "modeling and just just say I just want",
      "timestamp": "25:59"
    },
    {
      "start": 1561.559,
      "duration": 3.881,
      "text": "to learn this energy function that tells",
      "timestamp": "26:01"
    },
    {
      "start": 1563.08,
      "duration": 4.24,
      "text": "me whether my output is compatible with",
      "timestamp": "26:03"
    },
    {
      "start": 1565.44,
      "duration": 4.839,
      "text": "my input and I don't care if this energy",
      "timestamp": "26:05"
    },
    {
      "start": 1567.32,
      "duration": 5.239,
      "text": "function is a negative log of some",
      "timestamp": "26:07"
    },
    {
      "start": 1570.279,
      "duration": 3.64,
      "text": "distribution um and so the reason we",
      "timestamp": "26:10"
    },
    {
      "start": 1572.559,
      "duration": 3.201,
      "text": "need to do this of course is because we",
      "timestamp": "26:12"
    },
    {
      "start": 1573.919,
      "duration": 3.681,
      "text": "cannot predict exactly what's going to",
      "timestamp": "26:13"
    },
    {
      "start": 1575.76,
      "duration": 3.639,
      "text": "happen in the world there is a whole set",
      "timestamp": "26:15"
    },
    {
      "start": 1577.6,
      "duration": 3.52,
      "text": "of possible things that may happen and",
      "timestamp": "26:17"
    },
    {
      "start": 1579.399,
      "duration": 4.721,
      "text": "if we train a system to just predict one",
      "timestamp": "26:19"
    },
    {
      "start": 1581.12,
      "duration": 5.2,
      "text": "frame it's not going to do a good job um",
      "timestamp": "26:21"
    },
    {
      "start": 1584.12,
      "duration": 4.2,
      "text": "so the solution to that problem is an AR",
      "timestamp": "26:24"
    },
    {
      "start": 1586.32,
      "duration": 3.88,
      "text": "a new architecture I call John tedding",
      "timestamp": "26:26"
    },
    {
      "start": 1588.32,
      "duration": 4.599,
      "text": "predictive architecture or",
      "timestamp": "26:28"
    },
    {
      "start": 1590.2,
      "duration": 6.24,
      "text": "jepa and that's because generative",
      "timestamp": "26:30"
    },
    {
      "start": 1592.919,
      "duration": 6.081,
      "text": "architecture simply do not work for",
      "timestamp": "26:32"
    },
    {
      "start": 1596.44,
      "duration": 4.959,
      "text": "producing videos you may have seen video",
      "timestamp": "26:36"
    },
    {
      "start": 1599.0,
      "duration": 4.08,
      "text": "generation systems that produce pretty",
      "timestamp": "26:39"
    },
    {
      "start": 1601.399,
      "duration": 4.0,
      "text": "amazing stuff there's a lot of hacks",
      "timestamp": "26:41"
    },
    {
      "start": 1603.08,
      "duration": 4.12,
      "text": "that go be Beyond them uh behind them",
      "timestamp": "26:43"
    },
    {
      "start": 1605.399,
      "duration": 3.921,
      "text": "and they don't really understand",
      "timestamp": "26:45"
    },
    {
      "start": 1607.2,
      "duration": 4.04,
      "text": "physics um they don't need to they just",
      "timestamp": "26:47"
    },
    {
      "start": 1609.32,
      "duration": 3.52,
      "text": "need to to predict pretty pictures they",
      "timestamp": "26:49"
    },
    {
      "start": 1611.24,
      "duration": 3.439,
      "text": "don't need to actually have kind of",
      "timestamp": "26:51"
    },
    {
      "start": 1612.84,
      "duration": 4.68,
      "text": "accurate model of the world okay so",
      "timestamp": "26:52"
    },
    {
      "start": 1614.679,
      "duration": 5.801,
      "text": "here's what the JEA is the idea is that",
      "timestamp": "26:54"
    },
    {
      "start": 1617.52,
      "duration": 5.96,
      "text": "you run both the observation and the",
      "timestamp": "26:57"
    },
    {
      "start": 1620.48,
      "duration": 6.4,
      "text": "output which is the next observation",
      "timestamp": "27:00"
    },
    {
      "start": 1623.48,
      "duration": 6.84,
      "text": "into an encoder so that the prediction",
      "timestamp": "27:03"
    },
    {
      "start": 1626.88,
      "duration": 5.519,
      "text": "does not consist in predicting pixels",
      "timestamp": "27:06"
    },
    {
      "start": 1630.32,
      "duration": 4.4,
      "text": "but basically predicting an abstract",
      "timestamp": "27:10"
    },
    {
      "start": 1632.399,
      "duration": 5.601,
      "text": "representations of what goes on in the",
      "timestamp": "27:12"
    },
    {
      "start": 1634.72,
      "duration": 6.04,
      "text": "video video or anything okay so let's",
      "timestamp": "27:14"
    },
    {
      "start": 1638.0,
      "duration": 4.559,
      "text": "compare those two architectures on the",
      "timestamp": "27:18"
    },
    {
      "start": 1640.76,
      "duration": 4.24,
      "text": "left you have generative",
      "timestamp": "27:20"
    },
    {
      "start": 1642.559,
      "duration": 4.321,
      "text": "architectures you run X the observation",
      "timestamp": "27:22"
    },
    {
      "start": 1645.0,
      "duration": 4.44,
      "text": "to an encoder and perhaps to a predictor",
      "timestamp": "27:25"
    },
    {
      "start": 1646.88,
      "duration": 5.24,
      "text": "or decoder and you make a prediction for",
      "timestamp": "27:26"
    },
    {
      "start": 1649.44,
      "duration": 4.719,
      "text": "y okay that straightforward",
      "timestamp": "27:29"
    },
    {
      "start": 1652.12,
      "duration": 4.12,
      "text": "prediction and then on the right this",
      "timestamp": "27:32"
    },
    {
      "start": 1654.159,
      "duration": 3.841,
      "text": "jeta architecture you run both X and Y",
      "timestamp": "27:34"
    },
    {
      "start": 1656.24,
      "duration": 3.4,
      "text": "through and codos which may be identical",
      "timestamp": "27:36"
    },
    {
      "start": 1658.0,
      "duration": 4.159,
      "text": "or",
      "timestamp": "27:38"
    },
    {
      "start": 1659.64,
      "duration": 3.879,
      "text": "different and then you predict the",
      "timestamp": "27:39"
    },
    {
      "start": 1662.159,
      "duration": 3.36,
      "text": "representation of Y from the",
      "timestamp": "27:42"
    },
    {
      "start": 1663.519,
      "duration": 4.801,
      "text": "representation of X in this abstract",
      "timestamp": "27:43"
    },
    {
      "start": 1665.519,
      "duration": 5.481,
      "text": "space what this will cause the system to",
      "timestamp": "27:45"
    },
    {
      "start": 1668.32,
      "duration": 4.719,
      "text": "basically learn an encoder that",
      "timestamp": "27:48"
    },
    {
      "start": 1671.0,
      "duration": 4.279,
      "text": "eliminates all the stuff you cannot",
      "timestamp": "27:51"
    },
    {
      "start": 1673.039,
      "duration": 5.161,
      "text": "predict and this is really what we do",
      "timestamp": "27:53"
    },
    {
      "start": 1675.279,
      "duration": 4.921,
      "text": "there's no way that you know if if I",
      "timestamp": "27:55"
    },
    {
      "start": 1678.2,
      "duration": 4.04,
      "text": "observe the left part of this room here",
      "timestamp": "27:58"
    },
    {
      "start": 1680.2,
      "duration": 4.64,
      "text": "and I kind of pan the camera towards the",
      "timestamp": "28:00"
    },
    {
      "start": 1682.24,
      "duration": 4.319,
      "text": "right there's no way any video",
      "timestamp": "28:02"
    },
    {
      "start": 1684.84,
      "duration": 3.6,
      "text": "prediction system including humans can",
      "timestamp": "28:04"
    },
    {
      "start": 1686.559,
      "duration": 3.96,
      "text": "predict what every one of you looks like",
      "timestamp": "28:06"
    },
    {
      "start": 1688.44,
      "duration": 5.04,
      "text": "or predict the texture on the wall or",
      "timestamp": "28:08"
    },
    {
      "start": 1690.519,
      "duration": 5.121,
      "text": "the texture of the wood U on the on the",
      "timestamp": "28:10"
    },
    {
      "start": 1693.48,
      "duration": 3.84,
      "text": "hardwood floor um there's a lot of",
      "timestamp": "28:13"
    },
    {
      "start": 1695.64,
      "duration": 4.039,
      "text": "things that we just simply cannot",
      "timestamp": "28:15"
    },
    {
      "start": 1697.32,
      "duration": 4.4,
      "text": "predict and so instead of insisting that",
      "timestamp": "28:17"
    },
    {
      "start": 1699.679,
      "duration": 3.921,
      "text": "we should make a probabilistic",
      "timestamp": "28:19"
    },
    {
      "start": 1701.72,
      "duration": 4.92,
      "text": "prediction about stuff that we cannot",
      "timestamp": "28:21"
    },
    {
      "start": 1703.6,
      "duration": 4.76,
      "text": "predict let's just not predict it learn",
      "timestamp": "28:23"
    },
    {
      "start": 1706.64,
      "duration": 3.48,
      "text": "a representation in which all of those",
      "timestamp": "28:26"
    },
    {
      "start": 1708.36,
      "duration": 3.64,
      "text": "details are essentially eliminated so",
      "timestamp": "28:28"
    },
    {
      "start": 1710.12,
      "duration": 5.88,
      "text": "that the prediction is much simpler it",
      "timestamp": "28:30"
    },
    {
      "start": 1712.0,
      "duration": 6.12,
      "text": "may still we need to be uh non-",
      "timestamp": "28:32"
    },
    {
      "start": 1716.0,
      "duration": 4.36,
      "text": "deterministic but at least we simplify",
      "timestamp": "28:36"
    },
    {
      "start": 1718.12,
      "duration": 4.36,
      "text": "the problem so there's various flavors",
      "timestamp": "28:38"
    },
    {
      "start": 1720.36,
      "duration": 4.52,
      "text": "of those jads which I'm not going to go",
      "timestamp": "28:40"
    },
    {
      "start": 1722.48,
      "duration": 4.039,
      "text": "into some of which have latent variables",
      "timestamp": "28:42"
    },
    {
      "start": 1724.88,
      "duration": 3.039,
      "text": "some of which have are action",
      "timestamp": "28:44"
    },
    {
      "start": 1726.519,
      "duration": 3.76,
      "text": "conditioned so I'm going to talk about",
      "timestamp": "28:46"
    },
    {
      "start": 1727.919,
      "duration": 3.76,
      "text": "the action condition because that's uh",
      "timestamp": "28:47"
    },
    {
      "start": 1730.279,
      "duration": 3.201,
      "text": "the the most interesting one because",
      "timestamp": "28:50"
    },
    {
      "start": 1731.679,
      "duration": 3.84,
      "text": "they really are World models right so",
      "timestamp": "28:51"
    },
    {
      "start": 1733.48,
      "duration": 4.919,
      "text": "you have an encoder X is current state",
      "timestamp": "28:53"
    },
    {
      "start": 1735.519,
      "duration": 5.0,
      "text": "of the world or current observation XX",
      "timestamp": "28:55"
    },
    {
      "start": 1738.399,
      "duration": 3.801,
      "text": "is current state of the world you feel",
      "timestamp": "28:58"
    },
    {
      "start": 1740.519,
      "duration": 3.801,
      "text": "an action to a predictor which you",
      "timestamp": "29:00"
    },
    {
      "start": 1742.2,
      "duration": 3.92,
      "text": "imagine taking and the predictor which",
      "timestamp": "29:02"
    },
    {
      "start": 1744.32,
      "duration": 4.12,
      "text": "is a world model predicts the",
      "timestamp": "29:04"
    },
    {
      "start": 1746.12,
      "duration": 4.88,
      "text": "representation of the next state of the",
      "timestamp": "29:06"
    },
    {
      "start": 1748.44,
      "duration": 5.64,
      "text": "world um and that's how you can do",
      "timestamp": "29:08"
    },
    {
      "start": 1751.0,
      "duration": 4.559,
      "text": "planning okay so um you need to we need",
      "timestamp": "29:11"
    },
    {
      "start": 1754.08,
      "duration": 2.839,
      "text": "to train those systems and we need to",
      "timestamp": "29:14"
    },
    {
      "start": 1755.559,
      "duration": 3.24,
      "text": "figure out how to train those jepa",
      "timestamp": "29:15"
    },
    {
      "start": 1756.919,
      "duration": 5.401,
      "text": "architectures and tells that to not be",
      "timestamp": "29:16"
    },
    {
      "start": 1758.799,
      "duration": 5.76,
      "text": "completely trivial because you need to",
      "timestamp": "29:18"
    },
    {
      "start": 1762.32,
      "duration": 4.839,
      "text": "train the the cost function in this JEA",
      "timestamp": "29:22"
    },
    {
      "start": 1764.559,
      "duration": 4.921,
      "text": "architecture that measures the the",
      "timestamp": "29:24"
    },
    {
      "start": 1767.159,
      "duration": 4.64,
      "text": "Divergence between the representation of",
      "timestamp": "29:27"
    },
    {
      "start": 1769.48,
      "duration": 5.88,
      "text": "Y and the predicted representation of Y",
      "timestamp": "29:29"
    },
    {
      "start": 1771.799,
      "duration": 6.12,
      "text": "we need this to be low on the training",
      "timestamp": "29:31"
    },
    {
      "start": 1775.36,
      "duration": 5.6,
      "text": "data but we need also needed to be large",
      "timestamp": "29:35"
    },
    {
      "start": 1777.919,
      "duration": 4.521,
      "text": "outside the training set okay so this is",
      "timestamp": "29:37"
    },
    {
      "start": 1780.96,
      "duration": 4.559,
      "text": "you know this kind of energy function",
      "timestamp": "29:40"
    },
    {
      "start": 1782.44,
      "duration": 5.92,
      "text": "here that has kind of uh Contours of",
      "timestamp": "29:42"
    },
    {
      "start": 1785.519,
      "duration": 5.28,
      "text": "equal equal energy we need to make sure",
      "timestamp": "29:45"
    },
    {
      "start": 1788.36,
      "duration": 5.039,
      "text": "the energy is high outside of the",
      "timestamp": "29:48"
    },
    {
      "start": 1790.799,
      "duration": 4.441,
      "text": "manifold of data and I only know two",
      "timestamp": "29:50"
    },
    {
      "start": 1793.399,
      "duration": 4.041,
      "text": "classes of methods for this one set of",
      "timestamp": "29:53"
    },
    {
      "start": 1795.24,
      "duration": 4.84,
      "text": "method is called contrastive it consists",
      "timestamp": "29:55"
    },
    {
      "start": 1797.44,
      "duration": 6.0,
      "text": "in um having uh data points which are",
      "timestamp": "29:57"
    },
    {
      "start": 1800.08,
      "duration": 5.64,
      "text": "those those blue dark blue dots pushing",
      "timestamp": "30:00"
    },
    {
      "start": 1803.44,
      "duration": 4.079,
      "text": "the down the energy of those and then",
      "timestamp": "30:03"
    },
    {
      "start": 1805.72,
      "duration": 4.12,
      "text": "generating you know those flashing green",
      "timestamp": "30:05"
    },
    {
      "start": 1807.519,
      "duration": 3.961,
      "text": "dots and then pushing the energy up the",
      "timestamp": "30:07"
    },
    {
      "start": 1809.84,
      "duration": 3.28,
      "text": "problem with this type of method Contra",
      "timestamp": "30:09"
    },
    {
      "start": 1811.48,
      "duration": 3.679,
      "text": "method is that they don't scale very",
      "timestamp": "30:11"
    },
    {
      "start": 1813.12,
      "duration": 3.88,
      "text": "well in high dimension if you have too",
      "timestamp": "30:13"
    },
    {
      "start": 1815.159,
      "duration": 3.201,
      "text": "many dimensions in your space of Y",
      "timestamp": "30:15"
    },
    {
      "start": 1817.0,
      "duration": 5.44,
      "text": "you're going to need to push up in lots",
      "timestamp": "30:17"
    },
    {
      "start": 1818.36,
      "duration": 5.6,
      "text": "of different places and um it it doesn't",
      "timestamp": "30:18"
    },
    {
      "start": 1822.44,
      "duration": 3.599,
      "text": "work so well you need a lot of",
      "timestamp": "30:22"
    },
    {
      "start": 1823.96,
      "duration": 4.16,
      "text": "contrastive samples for this to work",
      "timestamp": "30:23"
    },
    {
      "start": 1826.039,
      "duration": 3.48,
      "text": "there's another set of method that um",
      "timestamp": "30:26"
    },
    {
      "start": 1828.12,
      "duration": 4.0,
      "text": "called regularized method and what they",
      "timestamp": "30:28"
    },
    {
      "start": 1829.519,
      "duration": 6.561,
      "text": "do is they use a regularizer on the",
      "timestamp": "30:29"
    },
    {
      "start": 1832.12,
      "duration": 7.24,
      "text": "energy so as to minimize the volume of",
      "timestamp": "30:32"
    },
    {
      "start": 1836.08,
      "duration": 4.599,
      "text": "space that can take low energy okay so",
      "timestamp": "30:36"
    },
    {
      "start": 1839.36,
      "duration": 3.52,
      "text": "that leads to two",
      "timestamp": "30:39"
    },
    {
      "start": 1840.679,
      "duration": 3.681,
      "text": "different types of learning procedure",
      "timestamp": "30:40"
    },
    {
      "start": 1842.88,
      "duration": 2.96,
      "text": "one one learning procedure which is",
      "timestamp": "30:42"
    },
    {
      "start": 1844.36,
      "duration": 2.76,
      "text": "contrastive you need to generate those",
      "timestamp": "30:44"
    },
    {
      "start": 1845.84,
      "duration": 4.12,
      "text": "contrastive points and then push their",
      "timestamp": "30:45"
    },
    {
      "start": 1847.12,
      "duration": 4.84,
      "text": "energy up to some loss function and the",
      "timestamp": "30:47"
    },
    {
      "start": 1849.96,
      "duration": 4.48,
      "text": "other one is some regularizer that is",
      "timestamp": "30:49"
    },
    {
      "start": 1851.96,
      "duration": 5.28,
      "text": "going to sort of shrink wrap the the",
      "timestamp": "30:51"
    },
    {
      "start": 1854.44,
      "duration": 5.119,
      "text": "manifold of data um so as to make sure",
      "timestamp": "30:54"
    },
    {
      "start": 1857.24,
      "duration": 3.559,
      "text": "that the energy is Tire outside so",
      "timestamp": "30:57"
    },
    {
      "start": 1859.559,
      "duration": 3.561,
      "text": "there's a number of techniques to do",
      "timestamp": "30:59"
    },
    {
      "start": 1860.799,
      "duration": 5.281,
      "text": "this um I'll describe just just a",
      "timestamp": "31:00"
    },
    {
      "start": 1863.12,
      "duration": 7.799,
      "text": "handful and the way um we we started",
      "timestamp": "31:03"
    },
    {
      "start": 1866.08,
      "duration": 8.92,
      "text": "testing them several years ago um maybe",
      "timestamp": "31:06"
    },
    {
      "start": 1870.919,
      "duration": 6.681,
      "text": "five six years ago was um to train them",
      "timestamp": "31:10"
    },
    {
      "start": 1875.0,
      "duration": 5.919,
      "text": "to learn representations of images so",
      "timestamp": "31:15"
    },
    {
      "start": 1877.6,
      "duration": 5.36,
      "text": "you take one image you corrupt it or",
      "timestamp": "31:17"
    },
    {
      "start": 1880.919,
      "duration": 3.521,
      "text": "transform it in some ways and you run",
      "timestamp": "31:20"
    },
    {
      "start": 1882.96,
      "duration": 4.199,
      "text": "the original image and the corrupted",
      "timestamp": "31:22"
    },
    {
      "start": 1884.44,
      "duration": 4.0,
      "text": "version in identical encoders and you",
      "timestamp": "31:24"
    },
    {
      "start": 1887.159,
      "duration": 2.76,
      "text": "train a predictor to predict the",
      "timestamp": "31:27"
    },
    {
      "start": 1888.44,
      "duration": 4.32,
      "text": "representation of the original image",
      "timestamp": "31:28"
    },
    {
      "start": 1889.919,
      "duration": 5.36,
      "text": "from the corrupted one once you're done",
      "timestamp": "31:29"
    },
    {
      "start": 1892.76,
      "duration": 4.48,
      "text": "training the system you remove the",
      "timestamp": "31:32"
    },
    {
      "start": 1895.279,
      "duration": 4.321,
      "text": "predictor and you use a representation",
      "timestamp": "31:35"
    },
    {
      "start": 1897.24,
      "duration": 6.0,
      "text": "at the output of the encoder as input to",
      "timestamp": "31:37"
    },
    {
      "start": 1899.6,
      "duration": 5.0,
      "text": "a simple um like a linear classifier or",
      "timestamp": "31:39"
    },
    {
      "start": 1903.24,
      "duration": 4.48,
      "text": "something of that type that you train",
      "timestamp": "31:43"
    },
    {
      "start": 1904.6,
      "duration": 4.439,
      "text": "supervised uh so as to verify that the",
      "timestamp": "31:44"
    },
    {
      "start": 1907.72,
      "duration": 2.919,
      "text": "representations that are learned are",
      "timestamp": "31:47"
    },
    {
      "start": 1909.039,
      "duration": 5.081,
      "text": "good and this idea is very old it goes",
      "timestamp": "31:49"
    },
    {
      "start": 1910.639,
      "duration": 6.52,
      "text": "back to the 198 90s and things like uh",
      "timestamp": "31:50"
    },
    {
      "start": 1914.12,
      "duration": 4.64,
      "text": "we used to call SES networks um and some",
      "timestamp": "31:54"
    },
    {
      "start": 1917.159,
      "duration": 3.681,
      "text": "more recent work on on those joint",
      "timestamp": "31:57"
    },
    {
      "start": 1918.76,
      "duration": 4.12,
      "text": "embedding architectures and then adding",
      "timestamp": "31:58"
    },
    {
      "start": 1920.84,
      "duration": 5.6,
      "text": "the predictor is more is more",
      "timestamp": "32:00"
    },
    {
      "start": 1922.88,
      "duration": 5.799,
      "text": "recent um so s clear which is from from",
      "timestamp": "32:02"
    },
    {
      "start": 1926.44,
      "duration": 3.64,
      "text": "Google is a contrastive method derived",
      "timestamp": "32:06"
    },
    {
      "start": 1928.679,
      "duration": 4.24,
      "text": "from s",
      "timestamp": "32:08"
    },
    {
      "start": 1930.08,
      "duration": 6.04,
      "text": "Nets um but again the dimension is is",
      "timestamp": "32:10"
    },
    {
      "start": 1932.919,
      "duration": 5.76,
      "text": "restricted so the regularized method uh",
      "timestamp": "32:12"
    },
    {
      "start": 1936.12,
      "duration": 4.6,
      "text": "worked the following way you try to",
      "timestamp": "32:16"
    },
    {
      "start": 1938.679,
      "duration": 3.6,
      "text": "estimate have some sort of estimate of",
      "timestamp": "32:18"
    },
    {
      "start": 1940.72,
      "duration": 4.72,
      "text": "the information content coming out of",
      "timestamp": "32:20"
    },
    {
      "start": 1942.279,
      "duration": 5.681,
      "text": "the encoders and what you need to do is",
      "timestamp": "32:22"
    },
    {
      "start": 1945.44,
      "duration": 4.76,
      "text": "prevent the encoder from collapsing this",
      "timestamp": "32:25"
    },
    {
      "start": 1947.96,
      "duration": 4.64,
      "text": "a trivial solution of training a a",
      "timestamp": "32:27"
    },
    {
      "start": 1950.2,
      "duration": 4.24,
      "text": "Jeeter architecture where the encoder",
      "timestamp": "32:30"
    },
    {
      "start": 1952.6,
      "duration": 3.16,
      "text": "basically ignores the input produces a",
      "timestamp": "32:32"
    },
    {
      "start": 1954.44,
      "duration": 3.16,
      "text": "constant output and another the",
      "timestamp": "32:34"
    },
    {
      "start": 1955.76,
      "duration": 4.24,
      "text": "prodction error is zero all the time",
      "timestamp": "32:35"
    },
    {
      "start": 1957.6,
      "duration": 4.88,
      "text": "okay and obviously that's a collapsed",
      "timestamp": "32:37"
    },
    {
      "start": 1960.0,
      "duration": 3.919,
      "text": "solution that is uh not interesting so",
      "timestamp": "32:40"
    },
    {
      "start": 1962.48,
      "duration": 4.799,
      "text": "you need a system you need to prevent",
      "timestamp": "32:42"
    },
    {
      "start": 1963.919,
      "duration": 5.041,
      "text": "the system from collapsing and which is",
      "timestamp": "32:43"
    },
    {
      "start": 1967.279,
      "duration": 3.201,
      "text": "the regularization method I was talking",
      "timestamp": "32:47"
    },
    {
      "start": 1968.96,
      "duration": 4.719,
      "text": "about earlier and an indirect way of",
      "timestamp": "32:48"
    },
    {
      "start": 1970.48,
      "duration": 5.84,
      "text": "doing this is maintain the information",
      "timestamp": "32:50"
    },
    {
      "start": 1973.679,
      "duration": 4.921,
      "text": "content coming out of the",
      "timestamp": "32:53"
    },
    {
      "start": 1976.32,
      "duration": 4.719,
      "text": "encoder Okay so so you're going to have",
      "timestamp": "32:56"
    },
    {
      "start": 1978.6,
      "duration": 5.039,
      "text": "a training objective function which is a",
      "timestamp": "32:58"
    },
    {
      "start": 1981.039,
      "duration": 4.161,
      "text": "negative information content if you want",
      "timestamp": "33:01"
    },
    {
      "start": 1983.639,
      "duration": 2.361,
      "text": "because we minimize in machine learning",
      "timestamp": "33:03"
    },
    {
      "start": 1985.2,
      "duration": 4.12,
      "text": "we don't",
      "timestamp": "33:05"
    },
    {
      "start": 1986.0,
      "duration": 6.32,
      "text": "maximize uh one way to do this is to",
      "timestamp": "33:06"
    },
    {
      "start": 1989.32,
      "duration": 5.8,
      "text": "basically take the",
      "timestamp": "33:09"
    },
    {
      "start": 1992.32,
      "duration": 6.44,
      "text": "um vectors representation vectors that",
      "timestamp": "33:12"
    },
    {
      "start": 1995.12,
      "duration": 6.679,
      "text": "come out of the encoder over a batch of",
      "timestamp": "33:15"
    },
    {
      "start": 1998.76,
      "duration": 4.72,
      "text": "samples um and make sure they contain",
      "timestamp": "33:18"
    },
    {
      "start": 2001.799,
      "duration": 4.401,
      "text": "information how you can you do this you",
      "timestamp": "33:21"
    },
    {
      "start": 2003.48,
      "duration": 5.559,
      "text": "can take that Matrix of representation",
      "timestamp": "33:23"
    },
    {
      "start": 2006.2,
      "duration": 6.04,
      "text": "vectors and compute the product of that",
      "timestamp": "33:26"
    },
    {
      "start": 2009.039,
      "duration": 5.721,
      "text": "matrix by its transposed you get aarian",
      "timestamp": "33:29"
    },
    {
      "start": 2012.24,
      "duration": 4.559,
      "text": "Matrix and you try to make that coari",
      "timestamp": "33:32"
    },
    {
      "start": 2014.76,
      "duration": 4.24,
      "text": "Matrix equal to",
      "timestamp": "33:34"
    },
    {
      "start": 2016.799,
      "duration": 4.88,
      "text": "Identity um",
      "timestamp": "33:36"
    },
    {
      "start": 2019.0,
      "duration": 4.36,
      "text": "so there's a bad news with this which is",
      "timestamp": "33:39"
    },
    {
      "start": 2021.679,
      "duration": 3.921,
      "text": "that this",
      "timestamp": "33:41"
    },
    {
      "start": 2023.36,
      "duration": 4.36,
      "text": "basically approximates the information",
      "timestamp": "33:43"
    },
    {
      "start": 2025.6,
      "duration": 4.4,
      "text": "content by making very strong",
      "timestamp": "33:45"
    },
    {
      "start": 2027.72,
      "duration": 4.16,
      "text": "assumptions about the the nature of the",
      "timestamp": "33:47"
    },
    {
      "start": 2030.0,
      "duration": 3.76,
      "text": "dependencies between the variables and",
      "timestamp": "33:50"
    },
    {
      "start": 2031.88,
      "duration": 3.36,
      "text": "in fact it's an upper bound on",
      "timestamp": "33:51"
    },
    {
      "start": 2033.76,
      "duration": 4.039,
      "text": "information content and we're pushing it",
      "timestamp": "33:53"
    },
    {
      "start": 2035.24,
      "duration": 4.279,
      "text": "up crossing our fingers that the actual",
      "timestamp": "33:55"
    },
    {
      "start": 2037.799,
      "duration": 5.681,
      "text": "information contain which is below is",
      "timestamp": "33:57"
    },
    {
      "start": 2039.519,
      "duration": 7.64,
      "text": "going to follow okay so it's slightly uh",
      "timestamp": "33:59"
    },
    {
      "start": 2043.48,
      "duration": 7.08,
      "text": "uh irregular uh theoretically but but it",
      "timestamp": "34:03"
    },
    {
      "start": 2047.159,
      "duration": 5.641,
      "text": "works all right so again uh you have a",
      "timestamp": "34:07"
    },
    {
      "start": 2050.56,
      "duration": 4.72,
      "text": "matrix coming out of your encoder it's",
      "timestamp": "34:10"
    },
    {
      "start": 2052.8,
      "duration": 4.48,
      "text": "got a number of samples um and each",
      "timestamp": "34:12"
    },
    {
      "start": 2055.28,
      "duration": 3.799,
      "text": "Vector is a separate variable what we're",
      "timestamp": "34:15"
    },
    {
      "start": 2057.28,
      "duration": 5.799,
      "text": "going to try to do is going to try to",
      "timestamp": "34:17"
    },
    {
      "start": 2059.079,
      "duration": 5.52,
      "text": "make each variable individually uh",
      "timestamp": "34:19"
    },
    {
      "start": 2063.079,
      "duration": 4.201,
      "text": "informative so we're going to try to",
      "timestamp": "34:23"
    },
    {
      "start": 2064.599,
      "duration": 4.721,
      "text": "prevent the the variance of the variable",
      "timestamp": "34:24"
    },
    {
      "start": 2067.28,
      "duration": 4.0,
      "text": "from going to to zero force it to be one",
      "timestamp": "34:27"
    },
    {
      "start": 2069.32,
      "duration": 3.759,
      "text": "for example and then we're going to",
      "timestamp": "34:29"
    },
    {
      "start": 2071.28,
      "duration": 3.639,
      "text": "decorrelate the variables with each",
      "timestamp": "34:31"
    },
    {
      "start": 2073.079,
      "duration": 4.08,
      "text": "other and that means Computing The",
      "timestamp": "34:33"
    },
    {
      "start": 2074.919,
      "duration": 4.92,
      "text": "coverance Matrix of this Matrix is",
      "timestamp": "34:34"
    },
    {
      "start": 2077.159,
      "duration": 5.44,
      "text": "transpose multiply by itself and then",
      "timestamp": "34:37"
    },
    {
      "start": 2079.839,
      "duration": 5.681,
      "text": "try to make the resulting coar Matrix as",
      "timestamp": "34:39"
    },
    {
      "start": 2082.599,
      "duration": 6.841,
      "text": "close to the identity uh Matrix as",
      "timestamp": "34:42"
    },
    {
      "start": 2085.52,
      "duration": 7.48,
      "text": "possible um there are other methods that",
      "timestamp": "34:45"
    },
    {
      "start": 2089.44,
      "duration": 7.439,
      "text": "try to make the samples uh orthogonal",
      "timestamp": "34:49"
    },
    {
      "start": 2093.0,
      "duration": 5.44,
      "text": "not the not the variables um and those",
      "timestamp": "34:53"
    },
    {
      "start": 2096.879,
      "duration": 3.681,
      "text": "are contrasting sample contrasting",
      "timestamp": "34:56"
    },
    {
      "start": 2098.44,
      "duration": 4.159,
      "text": "methods um but they don't work in high",
      "timestamp": "34:58"
    },
    {
      "start": 2100.56,
      "duration": 4.68,
      "text": "dimension and they require large",
      "timestamp": "35:00"
    },
    {
      "start": 2102.599,
      "duration": 4.401,
      "text": "batches uh so we have um a method of",
      "timestamp": "35:02"
    },
    {
      "start": 2105.24,
      "duration": 3.2,
      "text": "this type called viag that means",
      "timestamp": "35:05"
    },
    {
      "start": 2107.0,
      "duration": 3.32,
      "text": "variance in variance Co variance",
      "timestamp": "35:07"
    },
    {
      "start": 2108.44,
      "duration": 4.32,
      "text": "regularization and it's got particular",
      "timestamp": "35:08"
    },
    {
      "start": 2110.32,
      "duration": 4.16,
      "text": "loss functions for this ciance Matrix um",
      "timestamp": "35:10"
    },
    {
      "start": 2112.76,
      "duration": 6.079,
      "text": "there been kind of similar methods",
      "timestamp": "35:12"
    },
    {
      "start": 2114.48,
      "duration": 7.48,
      "text": "proposed by uh yima and his team called",
      "timestamp": "35:14"
    },
    {
      "start": 2118.839,
      "duration": 6.76,
      "text": "MCR squar and then another method by uh",
      "timestamp": "35:18"
    },
    {
      "start": 2121.96,
      "duration": 6.76,
      "text": "some colleagues from NYU called",
      "timestamp": "35:21"
    },
    {
      "start": 2125.599,
      "duration": 4.641,
      "text": "mmcr from neuroscience",
      "timestamp": "35:25"
    },
    {
      "start": 2128.72,
      "duration": 3.119,
      "text": "so that's one set of methods and I",
      "timestamp": "35:28"
    },
    {
      "start": 2130.24,
      "duration": 3.48,
      "text": "really like those methods and I I think",
      "timestamp": "35:30"
    },
    {
      "start": 2131.839,
      "duration": 4.041,
      "text": "and they work really well I expect to",
      "timestamp": "35:31"
    },
    {
      "start": 2133.72,
      "duration": 3.56,
      "text": "see more of them in the future but there",
      "timestamp": "35:33"
    },
    {
      "start": 2135.88,
      "duration": 3.52,
      "text": "is another set of method that to some",
      "timestamp": "35:35"
    },
    {
      "start": 2137.28,
      "duration": 4.48,
      "text": "extent has been slightly more successful",
      "timestamp": "35:37"
    },
    {
      "start": 2139.4,
      "duration": 3.8,
      "text": "over the last couple years and those are",
      "timestamp": "35:39"
    },
    {
      "start": 2141.76,
      "duration": 3.64,
      "text": "based on distillation so again you have",
      "timestamp": "35:41"
    },
    {
      "start": 2143.2,
      "duration": 3.48,
      "text": "two encoders it's still a joint Ting",
      "timestamp": "35:43"
    },
    {
      "start": 2145.4,
      "duration": 3.199,
      "text": "productive architecture you have two",
      "timestamp": "35:45"
    },
    {
      "start": 2146.68,
      "duration": 4.24,
      "text": "encoders they kind of share the same",
      "timestamp": "35:46"
    },
    {
      "start": 2148.599,
      "duration": 4.801,
      "text": "weights but not really so the encoder on",
      "timestamp": "35:48"
    },
    {
      "start": 2150.92,
      "duration": 4.72,
      "text": "the right uh gets a version of the",
      "timestamp": "35:50"
    },
    {
      "start": 2153.4,
      "duration": 6.8,
      "text": "weights of the enod on the left that are",
      "timestamp": "35:53"
    },
    {
      "start": 2155.64,
      "duration": 7.12,
      "text": "obtained through a um exponential moving",
      "timestamp": "35:55"
    },
    {
      "start": 2160.2,
      "duration": 5.0,
      "text": "average okay a moving average so",
      "timestamp": "36:00"
    },
    {
      "start": 2162.76,
      "duration": 5.2,
      "text": "basically you force the encoder on the",
      "timestamp": "36:02"
    },
    {
      "start": 2165.2,
      "duration": 4.52,
      "text": "right to uh change its weights more",
      "timestamp": "36:05"
    },
    {
      "start": 2167.96,
      "duration": 4.159,
      "text": "slowly than the one on the left and for",
      "timestamp": "36:07"
    },
    {
      "start": 2169.72,
      "duration": 4.56,
      "text": "some reason that prevents collapse",
      "timestamp": "36:09"
    },
    {
      "start": 2172.119,
      "duration": 4.441,
      "text": "there's some theoretical work on this um",
      "timestamp": "36:12"
    },
    {
      "start": 2174.28,
      "duration": 4.64,
      "text": "in fact uh this one that jum just",
      "timestamp": "36:14"
    },
    {
      "start": 2176.56,
      "duration": 4.48,
      "text": "finished writing um but it's a little",
      "timestamp": "36:16"
    },
    {
      "start": 2178.92,
      "duration": 3.84,
      "text": "bit mysterious why this works and",
      "timestamp": "36:18"
    },
    {
      "start": 2181.04,
      "duration": 4.48,
      "text": "frankly I'm a little uncomfortable with",
      "timestamp": "36:21"
    },
    {
      "start": 2182.76,
      "duration": 5.2,
      "text": "this method but we have",
      "timestamp": "36:22"
    },
    {
      "start": 2185.52,
      "duration": 4.839,
      "text": "to um accept the fact that actually",
      "timestamp": "36:25"
    },
    {
      "start": 2187.96,
      "duration": 6.84,
      "text": "works um if you if you're",
      "timestamp": "36:27"
    },
    {
      "start": 2190.359,
      "duration": 6.48,
      "text": "careful um you know real Engineers",
      "timestamp": "36:30"
    },
    {
      "start": 2194.8,
      "duration": 4.88,
      "text": "buildings without necessarily knowing",
      "timestamp": "36:34"
    },
    {
      "start": 2196.839,
      "duration": 4.841,
      "text": "why they work that's good",
      "timestamp": "36:36"
    },
    {
      "start": 2199.68,
      "duration": 3.72,
      "text": "engineers and then the usual joke in",
      "timestamp": "36:39"
    },
    {
      "start": 2201.68,
      "duration": 4.8,
      "text": "France that everybody here should should",
      "timestamp": "36:41"
    },
    {
      "start": 2203.4,
      "duration": 5.24,
      "text": "learn is that students that come out of",
      "timestamp": "36:43"
    },
    {
      "start": 2206.48,
      "duration": 3.44,
      "text": "e poly technique when they build",
      "timestamp": "36:46"
    },
    {
      "start": 2208.64,
      "duration": 2.36,
      "text": "something it doesn't work but they can",
      "timestamp": "36:48"
    },
    {
      "start": 2209.92,
      "duration": 4.32,
      "text": "tell you",
      "timestamp": "36:49"
    },
    {
      "start": 2211.0,
      "duration": 8.52,
      "text": "why sorry about that",
      "timestamp": "36:51"
    },
    {
      "start": 2214.24,
      "duration": 8.68,
      "text": "um I didn't study here you can tell um",
      "timestamp": "36:54"
    },
    {
      "start": 2219.52,
      "duration": 5.0,
      "text": "okay let me uh switch ahead skip ahead a",
      "timestamp": "36:59"
    },
    {
      "start": 2222.92,
      "duration": 4.919,
      "text": "little bit in interest of time because",
      "timestamp": "37:02"
    },
    {
      "start": 2224.52,
      "duration": 4.92,
      "text": "we wasted a bit of time um okay so",
      "timestamp": "37:04"
    },
    {
      "start": 2227.839,
      "duration": 3.52,
      "text": "there's a particular way of implementing",
      "timestamp": "37:07"
    },
    {
      "start": 2229.44,
      "duration": 5.879,
      "text": "this AIO distillation called IA there's",
      "timestamp": "37:09"
    },
    {
      "start": 2231.359,
      "duration": 7.081,
      "text": "another one called called Dino or Dino",
      "timestamp": "37:11"
    },
    {
      "start": 2235.319,
      "duration": 7.121,
      "text": "uh which I I skipped a little bit um and",
      "timestamp": "37:15"
    },
    {
      "start": 2238.44,
      "duration": 7.0,
      "text": "um so Dino um is V2 people are working",
      "timestamp": "37:18"
    },
    {
      "start": 2242.44,
      "duration": 4.679,
      "text": "on on V3 this is a method produced by",
      "timestamp": "37:22"
    },
    {
      "start": 2245.44,
      "duration": 3.36,
      "text": "some some of my colleagues at at Fair",
      "timestamp": "37:25"
    },
    {
      "start": 2247.119,
      "duration": 5.121,
      "text": "Paris",
      "timestamp": "37:27"
    },
    {
      "start": 2248.8,
      "duration": 5.76,
      "text": "um team led by Max Maximo cab um and",
      "timestamp": "37:28"
    },
    {
      "start": 2252.24,
      "duration": 3.839,
      "text": "then a slight different version um",
      "timestamp": "37:32"
    },
    {
      "start": 2254.56,
      "duration": 6.0,
      "text": "called IA V",
      "timestamp": "37:34"
    },
    {
      "start": 2256.079,
      "duration": 7.921,
      "text": "JEA by also Fair people in in Montreal",
      "timestamp": "37:36"
    },
    {
      "start": 2260.56,
      "duration": 6.36,
      "text": "and Paris mostly so no need for negative",
      "timestamp": "37:40"
    },
    {
      "start": 2264.0,
      "duration": 4.56,
      "text": "samples there and those those kind of",
      "timestamp": "37:44"
    },
    {
      "start": 2266.92,
      "duration": 3.399,
      "text": "those systems learn generic features",
      "timestamp": "37:46"
    },
    {
      "start": 2268.56,
      "duration": 3.16,
      "text": "that you can then learn for any",
      "timestamp": "37:48"
    },
    {
      "start": 2270.319,
      "duration": 4.081,
      "text": "Downstream task and the features are",
      "timestamp": "37:50"
    },
    {
      "start": 2271.72,
      "duration": 3.84,
      "text": "really good um so this works really well",
      "timestamp": "37:51"
    },
    {
      "start": 2274.4,
      "duration": 2.719,
      "text": "I'm not going to bore you with details",
      "timestamp": "37:54"
    },
    {
      "start": 2275.56,
      "duration": 3.039,
      "text": "because I don't have time uh more",
      "timestamp": "37:55"
    },
    {
      "start": 2277.119,
      "duration": 3.681,
      "text": "recently we worked on a version of this",
      "timestamp": "37:57"
    },
    {
      "start": 2278.599,
      "duration": 5.041,
      "text": "for video so this is a system that takes",
      "timestamp": "37:58"
    },
    {
      "start": 2280.8,
      "duration": 4.76,
      "text": "a a chunk of 16 frames from video and",
      "timestamp": "38:00"
    },
    {
      "start": 2283.64,
      "duration": 3.08,
      "text": "you corrupt you you take those 16 frames",
      "timestamp": "38:03"
    },
    {
      "start": 2285.56,
      "duration": 3.2,
      "text": "run them to an encoder and then you",
      "timestamp": "38:05"
    },
    {
      "start": 2286.72,
      "duration": 4.28,
      "text": "corrupt those 16 frames by masking some",
      "timestamp": "38:06"
    },
    {
      "start": 2288.76,
      "duration": 4.28,
      "text": "parts of it run them to the same encoder",
      "timestamp": "38:08"
    },
    {
      "start": 2291.0,
      "duration": 4.2,
      "text": "and then train a predictor to predict",
      "timestamp": "38:11"
    },
    {
      "start": 2293.04,
      "duration": 4.96,
      "text": "the U representation of a full video",
      "timestamp": "38:13"
    },
    {
      "start": 2295.2,
      "duration": 6.919,
      "text": "from the one that is partially masked or",
      "timestamp": "38:15"
    },
    {
      "start": 2298.0,
      "duration": 7.04,
      "text": "corrupted and the U so again this",
      "timestamp": "38:18"
    },
    {
      "start": 2302.119,
      "duration": 5.48,
      "text": "is group of researchers at at Fair in",
      "timestamp": "38:22"
    },
    {
      "start": 2305.04,
      "duration": 3.84,
      "text": "Paris and Montreal",
      "timestamp": "38:25"
    },
    {
      "start": 2307.599,
      "duration": 3.201,
      "text": "um and this works really well in the",
      "timestamp": "38:27"
    },
    {
      "start": 2308.88,
      "duration": 4.28,
      "text": "sense that uh you learn features that",
      "timestamp": "38:28"
    },
    {
      "start": 2310.8,
      "duration": 4.4,
      "text": "you can then feed to A system that can",
      "timestamp": "38:30"
    },
    {
      "start": 2313.16,
      "duration": 3.88,
      "text": "classify actions in videos and you get",
      "timestamp": "38:33"
    },
    {
      "start": 2315.2,
      "duration": 3.8,
      "text": "really good results with the with this",
      "timestamp": "38:35"
    },
    {
      "start": 2317.04,
      "duration": 3.76,
      "text": "these these methods again I'm not going",
      "timestamp": "38:37"
    },
    {
      "start": 2319.0,
      "duration": 3.24,
      "text": "to bore you with details but here is a",
      "timestamp": "38:39"
    },
    {
      "start": 2320.8,
      "duration": 4.76,
      "text": "really interesting thing this is a paper",
      "timestamp": "38:40"
    },
    {
      "start": 2322.24,
      "duration": 4.119,
      "text": "that we just submitted um if you show",
      "timestamp": "38:42"
    },
    {
      "start": 2325.56,
      "duration": 5.12,
      "text": "that",
      "timestamp": "38:45"
    },
    {
      "start": 2326.359,
      "duration": 5.72,
      "text": "system um videos where something really",
      "timestamp": "38:46"
    },
    {
      "start": 2330.68,
      "duration": 3.52,
      "text": "strange",
      "timestamp": "38:50"
    },
    {
      "start": 2332.079,
      "duration": 3.721,
      "text": "happens that system actually is capable",
      "timestamp": "38:52"
    },
    {
      "start": 2334.2,
      "duration": 2.96,
      "text": "of telling you my prediction error is",
      "timestamp": "38:54"
    },
    {
      "start": 2335.8,
      "duration": 3.16,
      "text": "going through the roof there is",
      "timestamp": "38:55"
    },
    {
      "start": 2337.16,
      "duration": 3.48,
      "text": "something strange going on in that",
      "timestamp": "38:57"
    },
    {
      "start": 2338.96,
      "duration": 4.32,
      "text": "window so you you take a you take a",
      "timestamp": "38:58"
    },
    {
      "start": 2340.64,
      "duration": 4.439,
      "text": "video and you take the 16 video Frame",
      "timestamp": "39:00"
    },
    {
      "start": 2343.28,
      "duration": 4.72,
      "text": "Window you slide it over the video and",
      "timestamp": "39:03"
    },
    {
      "start": 2345.079,
      "duration": 5.681,
      "text": "you measure the prediction error of the",
      "timestamp": "39:05"
    },
    {
      "start": 2348.0,
      "duration": 4.4,
      "text": "system and if something really strange",
      "timestamp": "39:08"
    },
    {
      "start": 2350.76,
      "duration": 3.16,
      "text": "happen like an object spontaneously",
      "timestamp": "39:10"
    },
    {
      "start": 2352.4,
      "duration": 4.959,
      "text": "disappears or change",
      "timestamp": "39:12"
    },
    {
      "start": 2353.92,
      "duration": 5.28,
      "text": "shape um the prediction error shoots up",
      "timestamp": "39:13"
    },
    {
      "start": 2357.359,
      "duration": 3.681,
      "text": "so what that tells you is that that",
      "timestamp": "39:17"
    },
    {
      "start": 2359.2,
      "duration": 3.8,
      "text": "system despite its Simplicity has",
      "timestamp": "39:19"
    },
    {
      "start": 2361.04,
      "duration": 3.559,
      "text": "learned some level of Common Sense he",
      "timestamp": "39:21"
    },
    {
      "start": 2363.0,
      "duration": 3.24,
      "text": "can tell you if something really strange",
      "timestamp": "39:23"
    },
    {
      "start": 2364.599,
      "duration": 3.841,
      "text": "in the world is",
      "timestamp": "39:24"
    },
    {
      "start": 2366.24,
      "duration": 4.359,
      "text": "happening um",
      "timestamp": "39:26"
    },
    {
      "start": 2368.44,
      "duration": 3.8,
      "text": "lots of experiments to show this in",
      "timestamp": "39:28"
    },
    {
      "start": 2370.599,
      "duration": 3.24,
      "text": "various contexts for various types of",
      "timestamp": "39:30"
    },
    {
      "start": 2372.24,
      "duration": 6.119,
      "text": "intuitive physics but I'm not going to",
      "timestamp": "39:32"
    },
    {
      "start": 2373.839,
      "duration": 8.321,
      "text": "I'm to skip to this uh latest work uh D",
      "timestamp": "39:33"
    },
    {
      "start": 2378.359,
      "duration": 5.321,
      "text": "Dino World model um so this is using",
      "timestamp": "39:38"
    },
    {
      "start": 2382.16,
      "duration": 3.24,
      "text": "Dino features and then training a",
      "timestamp": "39:42"
    },
    {
      "start": 2383.68,
      "duration": 3.399,
      "text": "predictor on top of it which is action",
      "timestamp": "39:43"
    },
    {
      "start": 2385.4,
      "duration": 2.88,
      "text": "condition so that it's a world model",
      "timestamp": "39:45"
    },
    {
      "start": 2387.079,
      "duration": 3.76,
      "text": "that we can use for",
      "timestamp": "39:47"
    },
    {
      "start": 2388.28,
      "duration": 4.48,
      "text": "planning um and this is a a paper that",
      "timestamp": "39:48"
    },
    {
      "start": 2390.839,
      "duration": 4.121,
      "text": "is on archive there's a website also",
      "timestamp": "39:50"
    },
    {
      "start": 2392.76,
      "duration": 4.88,
      "text": "that you can uh you can look at the URL",
      "timestamp": "39:52"
    },
    {
      "start": 2394.96,
      "duration": 6.72,
      "text": "is at the top here",
      "timestamp": "39:54"
    },
    {
      "start": 2397.64,
      "duration": 5.479,
      "text": "so basically uh train a predictor using",
      "timestamp": "39:57"
    },
    {
      "start": 2401.68,
      "duration": 2.76,
      "text": "you know a picture of the world that you",
      "timestamp": "40:01"
    },
    {
      "start": 2403.119,
      "duration": 4.561,
      "text": "run through a dino",
      "timestamp": "40:03"
    },
    {
      "start": 2404.44,
      "duration": 8.639,
      "text": "encoder and then an action that maybe a",
      "timestamp": "40:04"
    },
    {
      "start": 2407.68,
      "duration": 8.639,
      "text": "robot um takes so you get the next frame",
      "timestamp": "40:07"
    },
    {
      "start": 2413.079,
      "duration": 5.04,
      "text": "uh of that of that video next image from",
      "timestamp": "40:13"
    },
    {
      "start": 2416.319,
      "duration": 3.28,
      "text": "the world run this to the dino encoder",
      "timestamp": "40:16"
    },
    {
      "start": 2418.119,
      "duration": 2.761,
      "text": "and then train your predictor to just",
      "timestamp": "40:18"
    },
    {
      "start": 2419.599,
      "duration": 4.52,
      "text": "predict what's going to happen given the",
      "timestamp": "40:19"
    },
    {
      "start": 2420.88,
      "duration": 6.68,
      "text": "action that was taken okay very simple",
      "timestamp": "40:20"
    },
    {
      "start": 2424.119,
      "duration": 6.361,
      "text": "to do planning um You observe an initial",
      "timestamp": "40:24"
    },
    {
      "start": 2427.56,
      "duration": 4.64,
      "text": "state run into the doo encoder then run",
      "timestamp": "40:27"
    },
    {
      "start": 2430.48,
      "duration": 6.0,
      "text": "your world model multiple time steps",
      "timestamp": "40:30"
    },
    {
      "start": 2432.2,
      "duration": 6.119,
      "text": "with imagined actions um then you have a",
      "timestamp": "40:32"
    },
    {
      "start": 2436.48,
      "duration": 3.52,
      "text": "Target state which is represented by a",
      "timestamp": "40:36"
    },
    {
      "start": 2438.319,
      "duration": 3.201,
      "text": "Target image for example you run it to",
      "timestamp": "40:38"
    },
    {
      "start": 2440.0,
      "duration": 4.24,
      "text": "the encoder and then you compute the",
      "timestamp": "40:40"
    },
    {
      "start": 2441.52,
      "duration": 5.48,
      "text": "distance in state space between the",
      "timestamp": "40:41"
    },
    {
      "start": 2444.24,
      "duration": 4.92,
      "text": "predicted State and the the the state",
      "timestamp": "40:44"
    },
    {
      "start": 2447.0,
      "duration": 5.0,
      "text": "representing the the target",
      "timestamp": "40:47"
    },
    {
      "start": 2449.16,
      "duration": 5.04,
      "text": "image and the planning consists in just",
      "timestamp": "40:49"
    },
    {
      "start": 2452.0,
      "duration": 4.28,
      "text": "through optimization finding a sequence",
      "timestamp": "40:52"
    },
    {
      "start": 2454.2,
      "duration": 4.56,
      "text": "of actions that minimizes that cost at",
      "timestamp": "40:54"
    },
    {
      "start": 2456.28,
      "duration": 5.16,
      "text": "runtime okay reference time you know",
      "timestamp": "40:56"
    },
    {
      "start": 2458.76,
      "duration": 5.44,
      "text": "people are excited about",
      "timestamp": "40:58"
    },
    {
      "start": 2461.44,
      "duration": 4.12,
      "text": "um um you know test time computation and",
      "timestamp": "41:01"
    },
    {
      "start": 2464.2,
      "duration": 4.04,
      "text": "blah blah blah as if it was something",
      "timestamp": "41:04"
    },
    {
      "start": 2465.56,
      "duration": 4.16,
      "text": "new this is completely classical in",
      "timestamp": "41:05"
    },
    {
      "start": 2468.24,
      "duration": 3.64,
      "text": "optimal control this is called Model",
      "timestamp": "41:08"
    },
    {
      "start": 2469.72,
      "duration": 3.639,
      "text": "preductive control it's been around with",
      "timestamp": "41:09"
    },
    {
      "start": 2471.88,
      "duration": 3.84,
      "text": "us",
      "timestamp": "41:11"
    },
    {
      "start": 2473.359,
      "duration": 7.441,
      "text": "for about the same time that I've been",
      "timestamp": "41:13"
    },
    {
      "start": 2475.72,
      "duration": 7.72,
      "text": "around all right um the first paper is",
      "timestamp": "41:15"
    },
    {
      "start": 2480.8,
      "duration": 4.24,
      "text": "on you know planning using using models",
      "timestamp": "41:20"
    },
    {
      "start": 2483.44,
      "duration": 4.48,
      "text": "of this type using optimization are from",
      "timestamp": "41:23"
    },
    {
      "start": 2485.04,
      "duration": 4.36,
      "text": "the early 60s um the the ones that",
      "timestamp": "41:25"
    },
    {
      "start": 2487.92,
      "duration": 3.159,
      "text": "actually learned the model are more",
      "timestamp": "41:27"
    },
    {
      "start": 2489.4,
      "duration": 2.84,
      "text": "recent they're more from the 70s from",
      "timestamp": "41:29"
    },
    {
      "start": 2491.079,
      "duration": 6.52,
      "text": "France",
      "timestamp": "41:31"
    },
    {
      "start": 2492.24,
      "duration": 7.24,
      "text": "actually um it's called edcom um some",
      "timestamp": "41:32"
    },
    {
      "start": 2497.599,
      "duration": 5.401,
      "text": "people in optimal control might know",
      "timestamp": "41:37"
    },
    {
      "start": 2499.48,
      "duration": 5.96,
      "text": "about this um but you know it's very",
      "timestamp": "41:39"
    },
    {
      "start": 2503.0,
      "duration": 5.04,
      "text": "simple concept this works amazingly well",
      "timestamp": "41:43"
    },
    {
      "start": 2505.44,
      "duration": 4.919,
      "text": "so let me skip to the video",
      "timestamp": "41:45"
    },
    {
      "start": 2508.04,
      "duration": 5.12,
      "text": "because okay so let's say you have this",
      "timestamp": "41:48"
    },
    {
      "start": 2510.359,
      "duration": 6.561,
      "text": "uh Little T shape and you want to push",
      "timestamp": "41:50"
    },
    {
      "start": 2513.16,
      "duration": 5.159,
      "text": "it into a particular um position and so",
      "timestamp": "41:53"
    },
    {
      "start": 2516.92,
      "duration": 3.04,
      "text": "you know which position it has to go to",
      "timestamp": "41:56"
    },
    {
      "start": 2518.319,
      "duration": 3.28,
      "text": "because you put an image of that",
      "timestamp": "41:58"
    },
    {
      "start": 2519.96,
      "duration": 3.8,
      "text": "position run to the enod and that gives",
      "timestamp": "41:59"
    },
    {
      "start": 2521.599,
      "duration": 6.961,
      "text": "you a Target state in representation",
      "timestamp": "42:01"
    },
    {
      "start": 2523.76,
      "duration": 7.8,
      "text": "space um let me play that video",
      "timestamp": "42:03"
    },
    {
      "start": 2528.56,
      "duration": 4.48,
      "text": "again okay so at the top you see what",
      "timestamp": "42:08"
    },
    {
      "start": 2531.56,
      "duration": 3.279,
      "text": "actually happens in the real world when",
      "timestamp": "42:11"
    },
    {
      "start": 2533.04,
      "duration": 3.799,
      "text": "you take a sequence of actions that is",
      "timestamp": "42:13"
    },
    {
      "start": 2534.839,
      "duration": 4.561,
      "text": "planned and what you see at the bottom",
      "timestamp": "42:14"
    },
    {
      "start": 2536.839,
      "duration": 4.201,
      "text": "is the internal mental prediction of",
      "timestamp": "42:16"
    },
    {
      "start": 2539.4,
      "duration": 3.6,
      "text": "what the system of the sequence of",
      "timestamp": "42:19"
    },
    {
      "start": 2541.04,
      "duration": 3.88,
      "text": "actions the system was planning and this",
      "timestamp": "42:21"
    },
    {
      "start": 2543.0,
      "duration": 3.68,
      "text": "is run to a decoder that produces a",
      "timestamp": "42:23"
    },
    {
      "start": 2544.92,
      "duration": 3.56,
      "text": "pictorial representation of the internal",
      "timestamp": "42:24"
    },
    {
      "start": 2546.68,
      "duration": 5.08,
      "text": "state but that is trained separately",
      "timestamp": "42:26"
    },
    {
      "start": 2548.48,
      "duration": 5.48,
      "text": "there's no image generation um let me",
      "timestamp": "42:28"
    },
    {
      "start": 2551.76,
      "duration": 3.96,
      "text": "skip to the more interesting one so here",
      "timestamp": "42:31"
    },
    {
      "start": 2553.96,
      "duration": 4.24,
      "text": "is one where you have an initial state",
      "timestamp": "42:33"
    },
    {
      "start": 2555.72,
      "duration": 6.32,
      "text": "which is a bunch of Blue Chips",
      "timestamp": "42:35"
    },
    {
      "start": 2558.2,
      "duration": 5.48,
      "text": "randomly thrown on the floor and the",
      "timestamp": "42:38"
    },
    {
      "start": 2562.04,
      "duration": 4.799,
      "text": "target state is at the top and what you",
      "timestamp": "42:42"
    },
    {
      "start": 2563.68,
      "duration": 5.84,
      "text": "see here are the actions that are",
      "timestamp": "42:43"
    },
    {
      "start": 2566.839,
      "duration": 4.321,
      "text": "resulted from planning and the robot",
      "timestamp": "42:46"
    },
    {
      "start": 2569.52,
      "duration": 3.16,
      "text": "like accomplishing those actions the",
      "timestamp": "42:49"
    },
    {
      "start": 2571.16,
      "duration": 2.959,
      "text": "Dynamics of this environment is actually",
      "timestamp": "42:51"
    },
    {
      "start": 2572.68,
      "duration": 2.96,
      "text": "fairly complicated because those blue",
      "timestamp": "42:52"
    },
    {
      "start": 2574.119,
      "duration": 3.96,
      "text": "Chiefs kind of interact with each other",
      "timestamp": "42:54"
    },
    {
      "start": 2575.64,
      "duration": 3.8,
      "text": "and and everything um the system has",
      "timestamp": "42:55"
    },
    {
      "start": 2578.079,
      "duration": 4.641,
      "text": "just learned this through you know",
      "timestamp": "42:58"
    },
    {
      "start": 2579.44,
      "duration": 5.8,
      "text": "observing a bunch of uh uh State action",
      "timestamp": "42:59"
    },
    {
      "start": 2582.72,
      "duration": 5.0,
      "text": "next state um and this works in a lot of",
      "timestamp": "43:02"
    },
    {
      "start": 2585.24,
      "duration": 4.64,
      "text": "situations for you know arms and moving",
      "timestamp": "43:05"
    },
    {
      "start": 2587.72,
      "duration": 6.2,
      "text": "through mazes and pushing a te around",
      "timestamp": "43:07"
    },
    {
      "start": 2589.88,
      "duration": 7.04,
      "text": "and and things like that so",
      "timestamp": "43:09"
    },
    {
      "start": 2593.92,
      "duration": 5.56,
      "text": "um okay and I'm not sure where I came",
      "timestamp": "43:13"
    },
    {
      "start": 2596.92,
      "duration": 5.04,
      "text": "back um we've applied kind of similar",
      "timestamp": "43:16"
    },
    {
      "start": 2599.48,
      "duration": 6.2,
      "text": "idea to navigation but interest of time",
      "timestamp": "43:19"
    },
    {
      "start": 2601.96,
      "duration": 5.96,
      "text": "I'm just going to skip um so this is you",
      "timestamp": "43:21"
    },
    {
      "start": 2605.68,
      "duration": 5.439,
      "text": "know basically sequences the videos",
      "timestamp": "43:25"
    },
    {
      "start": 2607.92,
      "duration": 5.199,
      "text": "where a frame is uh is taken at one time",
      "timestamp": "43:27"
    },
    {
      "start": 2611.119,
      "duration": 3.44,
      "text": "and then the robot moves and you know",
      "timestamp": "43:31"
    },
    {
      "start": 2613.119,
      "duration": 2.881,
      "text": "through odometry you know by how much",
      "timestamp": "43:33"
    },
    {
      "start": 2614.559,
      "duration": 3.081,
      "text": "the robot has moved you get the next",
      "timestamp": "43:34"
    },
    {
      "start": 2616.0,
      "duration": 2.92,
      "text": "frame and so you just train a system to",
      "timestamp": "43:36"
    },
    {
      "start": 2617.64,
      "duration": 4.16,
      "text": "predict what the world is going to look",
      "timestamp": "43:37"
    },
    {
      "start": 2618.92,
      "duration": 4.84,
      "text": "like if you take a particular motion uh",
      "timestamp": "43:38"
    },
    {
      "start": 2621.8,
      "duration": 4.2,
      "text": "action and what you can do next is you",
      "timestamp": "43:41"
    },
    {
      "start": 2623.76,
      "duration": 6.04,
      "text": "can tell a system like you know navigate",
      "timestamp": "43:43"
    },
    {
      "start": 2626.0,
      "duration": 6.96,
      "text": "to that point um and it it will it will",
      "timestamp": "43:46"
    },
    {
      "start": 2629.8,
      "duration": 5.72,
      "text": "do it and you know avoid obstacles on",
      "timestamp": "43:49"
    },
    {
      "start": 2632.96,
      "duration": 6.24,
      "text": "the way this is a very new",
      "timestamp": "43:52"
    },
    {
      "start": 2635.52,
      "duration": 6.48,
      "text": "work but let me go to the conclusion so",
      "timestamp": "43:55"
    },
    {
      "start": 2639.2,
      "duration": 4.399,
      "text": "I'm having a number of uh",
      "timestamp": "43:59"
    },
    {
      "start": 2642.0,
      "duration": 4.0,
      "text": "recommendations abandon generative",
      "timestamp": "44:02"
    },
    {
      "start": 2643.599,
      "duration": 4.081,
      "text": "models the most popular method today",
      "timestamp": "44:03"
    },
    {
      "start": 2646.0,
      "duration": 3.839,
      "text": "that everybody is working on startop",
      "timestamp": "44:06"
    },
    {
      "start": 2647.68,
      "duration": 3.96,
      "text": "working on this you work on jads those",
      "timestamp": "44:07"
    },
    {
      "start": 2649.839,
      "duration": 4.881,
      "text": "are not generative models they predict",
      "timestamp": "44:09"
    },
    {
      "start": 2651.64,
      "duration": 4.8,
      "text": "in representation space probably seek",
      "timestamp": "44:11"
    },
    {
      "start": 2654.72,
      "duration": 4.52,
      "text": "models because it's",
      "timestamp": "44:14"
    },
    {
      "start": 2656.44,
      "duration": 7.399,
      "text": "intractable use energy based",
      "timestamp": "44:16"
    },
    {
      "start": 2659.24,
      "duration": 7.319,
      "text": "models uh M have had like a 20",
      "timestamp": "44:19"
    },
    {
      "start": 2663.839,
      "duration": 5.561,
      "text": "year contentious discussion about this",
      "timestamp": "44:23"
    },
    {
      "start": 2666.559,
      "duration": 4.361,
      "text": "um abandon contractive methods in favor",
      "timestamp": "44:26"
    },
    {
      "start": 2669.4,
      "duration": 3.28,
      "text": "of those regularized methods abandon",
      "timestamp": "44:29"
    },
    {
      "start": 2670.92,
      "duration": 4.72,
      "text": "reinforcement learning but that I've",
      "timestamp": "44:30"
    },
    {
      "start": 2672.68,
      "duration": 5.48,
      "text": "been saying for a long time we know it's",
      "timestamp": "44:32"
    },
    {
      "start": 2675.64,
      "duration": 4.04,
      "text": "inefficient um you have to use",
      "timestamp": "44:35"
    },
    {
      "start": 2678.16,
      "duration": 4.36,
      "text": "reinforcement learning really as a last",
      "timestamp": "44:38"
    },
    {
      "start": 2679.68,
      "duration": 5.52,
      "text": "result when your model is inaccurate or",
      "timestamp": "44:39"
    },
    {
      "start": 2682.52,
      "duration": 4.12,
      "text": "or your cost function is inaccurate um",
      "timestamp": "44:42"
    },
    {
      "start": 2685.2,
      "duration": 3.32,
      "text": "but if you are interested in human level",
      "timestamp": "44:45"
    },
    {
      "start": 2686.64,
      "duration": 4.32,
      "text": "AI just don't work on llm there's no",
      "timestamp": "44:46"
    },
    {
      "start": 2688.52,
      "duration": 4.72,
      "text": "point I mean in fact if you are in",
      "timestamp": "44:48"
    },
    {
      "start": 2690.96,
      "duration": 4.359,
      "text": "Academia don't work on LM because you're",
      "timestamp": "44:50"
    },
    {
      "start": 2693.24,
      "duration": 5.079,
      "text": "in competition with like hundreds of",
      "timestamp": "44:53"
    },
    {
      "start": 2695.319,
      "duration": 4.081,
      "text": "people with tens of thousands of gpus",
      "timestamp": "44:55"
    },
    {
      "start": 2698.319,
      "duration": 5.121,
      "text": "like there's nothing you can bring to",
      "timestamp": "44:58"
    },
    {
      "start": 2699.4,
      "duration": 6.04,
      "text": "the table do something else um there's a",
      "timestamp": "44:59"
    },
    {
      "start": 2703.44,
      "duration": 3.48,
      "text": "number of problems to solve U training",
      "timestamp": "45:03"
    },
    {
      "start": 2705.44,
      "duration": 3.119,
      "text": "those things with you know large scale",
      "timestamp": "45:05"
    },
    {
      "start": 2706.92,
      "duration": 2.96,
      "text": "data blah blah blah planning algorithms",
      "timestamp": "45:06"
    },
    {
      "start": 2708.559,
      "duration": 3.56,
      "text": "are kind of inefficient we have to come",
      "timestamp": "45:08"
    },
    {
      "start": 2709.88,
      "duration": 4.76,
      "text": "up with better methods so if you are",
      "timestamp": "45:09"
    },
    {
      "start": 2712.119,
      "duration": 4.881,
      "text": "like into optimization applied math it's",
      "timestamp": "45:12"
    },
    {
      "start": 2714.64,
      "duration": 4.8,
      "text": "great um J with latent variables",
      "timestamp": "45:14"
    },
    {
      "start": 2717.0,
      "duration": 4.92,
      "text": "planning under uncertainty hierarchical",
      "timestamp": "45:17"
    },
    {
      "start": 2719.44,
      "duration": 4.28,
      "text": "planning which is completely unsolved um",
      "timestamp": "45:19"
    },
    {
      "start": 2721.92,
      "duration": 3.04,
      "text": "learning cost module because probably",
      "timestamp": "45:21"
    },
    {
      "start": 2723.72,
      "duration": 2.96,
      "text": "most of them you can't build by hand you",
      "timestamp": "45:23"
    },
    {
      "start": 2724.96,
      "duration": 4.32,
      "text": "need to learn them and then there is",
      "timestamp": "45:24"
    },
    {
      "start": 2726.68,
      "duration": 4.96,
      "text": "issues exploration Etc okay so in the",
      "timestamp": "45:26"
    },
    {
      "start": 2729.28,
      "duration": 4.36,
      "text": "future we'll have Universal virtual",
      "timestamp": "45:29"
    },
    {
      "start": 2731.64,
      "duration": 3.16,
      "text": "assistants they'll be with us at all",
      "timestamp": "45:31"
    },
    {
      "start": 2733.64,
      "duration": 3.719,
      "text": "times they will mediate all our",
      "timestamp": "45:33"
    },
    {
      "start": 2734.8,
      "duration": 4.44,
      "text": "interaction with the digital world we",
      "timestamp": "45:34"
    },
    {
      "start": 2737.359,
      "duration": 4.121,
      "text": "cannot afford to have those systems come",
      "timestamp": "45:37"
    },
    {
      "start": 2739.24,
      "duration": 5.119,
      "text": "from a handful of companies from the",
      "timestamp": "45:39"
    },
    {
      "start": 2741.48,
      "duration": 4.72,
      "text": "west coast of the US or China uh which",
      "timestamp": "45:41"
    },
    {
      "start": 2744.359,
      "duration": 3.361,
      "text": "means the platforms on top of which we",
      "timestamp": "45:44"
    },
    {
      "start": 2746.2,
      "duration": 3.68,
      "text": "build those systems need to be open",
      "timestamp": "45:46"
    },
    {
      "start": 2747.72,
      "duration": 4.599,
      "text": "source and widely available they are",
      "timestamp": "45:47"
    },
    {
      "start": 2749.88,
      "duration": 4.439,
      "text": "expensive to train but once you have a",
      "timestamp": "45:49"
    },
    {
      "start": 2752.319,
      "duration": 3.28,
      "text": "foundation model fun tuning it for a",
      "timestamp": "45:52"
    },
    {
      "start": 2754.319,
      "duration": 3.28,
      "text": "particular application is relatively",
      "timestamp": "45:54"
    },
    {
      "start": 2755.599,
      "duration": 4.881,
      "text": "cheap and a lot of people afford to do",
      "timestamp": "45:55"
    },
    {
      "start": 2757.599,
      "duration": 5.121,
      "text": "this so the platforms need to be shared",
      "timestamp": "45:57"
    },
    {
      "start": 2760.48,
      "duration": 4.04,
      "text": "they need to speak all the the world",
      "timestamp": "46:00"
    },
    {
      "start": 2762.72,
      "duration": 4.2,
      "text": "languages understand all the world's",
      "timestamp": "46:02"
    },
    {
      "start": 2764.52,
      "duration": 5.24,
      "text": "cultures all the value systems all the",
      "timestamp": "46:04"
    },
    {
      "start": 2766.92,
      "duration": 4.72,
      "text": "centers of Interest no single entity in",
      "timestamp": "46:06"
    },
    {
      "start": 2769.76,
      "duration": 3.44,
      "text": "the world can train a foundational model",
      "timestamp": "46:09"
    },
    {
      "start": 2771.64,
      "duration": 4.12,
      "text": "of this type this probably will have to",
      "timestamp": "46:11"
    },
    {
      "start": 2773.2,
      "duration": 4.879,
      "text": "be done in a collaborative fashion or",
      "timestamp": "46:13"
    },
    {
      "start": 2775.76,
      "duration": 3.48,
      "text": "distributed fashion again some work for",
      "timestamp": "46:15"
    },
    {
      "start": 2778.079,
      "duration": 3.561,
      "text": "Applied mathematicians who are",
      "timestamp": "46:18"
    },
    {
      "start": 2779.24,
      "duration": 3.52,
      "text": "interested in distributed algorithms for",
      "timestamp": "46:19"
    },
    {
      "start": 2781.64,
      "duration": 4.439,
      "text": "large scale",
      "timestamp": "46:21"
    },
    {
      "start": 2782.76,
      "duration": 4.799,
      "text": "optimization um and so open source AI",
      "timestamp": "46:22"
    },
    {
      "start": 2786.079,
      "duration": 4.801,
      "text": "platforms are necessary",
      "timestamp": "46:26"
    },
    {
      "start": 2787.559,
      "duration": 6.881,
      "text": "the danger I see um in Europe and in",
      "timestamp": "46:27"
    },
    {
      "start": 2790.88,
      "duration": 7.76,
      "text": "other places is that geopolitical",
      "timestamp": "46:30"
    },
    {
      "start": 2794.44,
      "duration": 6.04,
      "text": "rivalry will U entice governments to",
      "timestamp": "46:34"
    },
    {
      "start": 2798.64,
      "duration": 4.24,
      "text": "basically make the release of Open",
      "timestamp": "46:38"
    },
    {
      "start": 2800.48,
      "duration": 4.48,
      "text": "Source model illegal because there are",
      "timestamp": "46:40"
    },
    {
      "start": 2802.88,
      "duration": 4.479,
      "text": "under the impression that a country will",
      "timestamp": "46:42"
    },
    {
      "start": 2804.96,
      "duration": 4.52,
      "text": "stay ahead if he keeps uh its science",
      "timestamp": "46:44"
    },
    {
      "start": 2807.359,
      "duration": 4.401,
      "text": "secret that's that would be a huge",
      "timestamp": "46:47"
    },
    {
      "start": 2809.48,
      "duration": 4.24,
      "text": "mistake when you do research in secret",
      "timestamp": "46:49"
    },
    {
      "start": 2811.76,
      "duration": 4.0,
      "text": "you fall behind that's",
      "timestamp": "46:51"
    },
    {
      "start": 2813.72,
      "duration": 3.879,
      "text": "inevitable what will happen is that the",
      "timestamp": "46:53"
    },
    {
      "start": 2815.76,
      "duration": 3.76,
      "text": "rest of the world we go up and and will",
      "timestamp": "46:55"
    },
    {
      "start": 2817.599,
      "duration": 4.52,
      "text": "overtake you that's currently what's",
      "timestamp": "46:57"
    },
    {
      "start": 2819.52,
      "duration": 4.799,
      "text": "what's happening the open source models",
      "timestamp": "46:59"
    },
    {
      "start": 2822.119,
      "duration": 5.24,
      "text": "are",
      "timestamp": "47:02"
    },
    {
      "start": 2824.319,
      "duration": 5.201,
      "text": "overtaking uh slowly but surely uh",
      "timestamp": "47:04"
    },
    {
      "start": 2827.359,
      "duration": 6.681,
      "text": "proprietary",
      "timestamp": "47:07"
    },
    {
      "start": 2829.52,
      "duration": 4.52,
      "text": "models thank you very much",
      "timestamp": "47:09"
    }
  ],
  "extraction_timestamp": "2025-07-17T17:07:26",
  "processing_type": "single_video"
}