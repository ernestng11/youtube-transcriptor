{
  "video_id": "PbHm2qKnu10",
  "video_title": "Training Agentic Reasoners â€” Will Brown, Prime Intellect",
  "video_url": "https://www.youtube.com/watch?v=PbHm2qKnu10",
  "channel_title": "Unknown",
  "published_at": null,
  "duration_seconds": null,
  "view_count": null,
  "like_count": null,
  "description": "This talk will be a technical deep dive into RL for agentic reasoning via multi-turn tool calling, similar to OpenAI's o3 and Deep Research. In particular, we'll cover:\n\n- When, why, and how\n- GRPO vs PPO vs etc\n- Designing environments and rewards\n- Survey of recent research highlights\n- Results on example tasks\n- Overview of open-source ecosystem (libraries, compute requirements, tradeoffs, etc.)\n\nAbout Will Brown\nWill Brown is a Research Engineering Lead at Prime Intellect, focusing on RL for reasoning and agents. He previously held research roles at Morgan Stanley and AWS, and completed his PhD in Computer Science at Columbia University.\n\nRecorded at the AI Engineer World's Fair in San Francisco. Stay up to date on our upcoming events and content by joining our newsletter here: https://www.ai.engineer/newsletter\n\nTimestamps\n[00:00] Introduction to the idea that reasoning and agents are similar.\n[01:05] The growing effectiveness of Reinforcement Learning (RL) in AI.\n[03:04] The complexities and challenges of implementing RL.\n[04:41] The connection between popular AI products (agents) and RL fine-tuning.\n[07:18] The core process of Reinforcement Learning.\n[10:21] The importance of tools and real-world tasks for agents.\n[12:13] The problem of \"reward hacking\" and how to design better evaluations.\n[14:51] Future directions for agentic systems and a practical toolkit for implementation.",
  "transcript": {
    "language": "en",
    "is_auto_generated": false,
    "total_segments": 541,
    "aggregated_text": "[Music] hi everyone I'm Will Brown i'm at Primeelect uh today I want to talk about training agentic reasoners um just kind of as a very high level overview I think a lot of people here are really excited about reasoning and a lot of people here are really excited about agents but I feel like a lot of the conversations between these two topics are kind of like different where people are like \"Oh reasoning is this one thing and agents are this other thing.\" And the considerations of like reasoning are very different from the considerations of building agents and I think the high level thesis of this talk is like no they're kind of the same thing um and you'll see why as we get into it um first just to start like RL kind of works now um I think for a long time people were like \"Oh is that our going to work is it not going to work how hard is it going to be?\" Um and like DeepSeek I think took a lot of people by surprise for many reasons like the costs or whatever and like how good it is compared to the open models to the closed the big labs as well as just it being fully open um but I think it was also just that it was RL applied at scale working with surprisingly few tweaks needed where you just like have a good setup you have a good signal you have a model that is good enough to do some learning and you see this curve where doing more RL results in the model getting better um and it's also kind of how everyone else is doing it like this is what the big labs are really banking on to drive the next iterations of progress the 03 release is the one that OpenAI is really excited about not GBT 4.5 like they stopped serving the big pre-trained model via API but they have continued to really double down on the scaling direction of doing more and more reinforcement learning and spending more compute on reinforcement learning once you have the right setup to enable progress and 03 to me is like a very naturally agentic model it the chat GBT version has all these tools the kind of selling point of it is not just that it's smarter it's that it's really good at using lots of tools in agentic task settings to solve harder problems that involve interacting with complex systems and that is kind of really the selling point of all of this is that like the more complex your system the more things can go wrong the more that like a generic LM API is going to be brittle and go off the rails after a certain number of steps and RL is kind of the way around it it's the trick you can do to take the system that kind of works maybe it works on small scales but as you go harder it starts going off the rails and train the model to be better at that thing um and so this is a recipe that is still kind of like a research topic that people are not fully sure like the best way to do it especially outside of the big labs but it clearly is moving in a direction where it's becoming more and more reliable more and more accessible and the sort of thing that I think would be silly to disregard as a potential like key piece of the future of agentic software and agentic applications uh but it's also complicated so on the left here this is the like architecture diagram of Veril which is kind of the most popular software people use in the research world for writing papers to uh do RL so if you want to like take a model and go do RL Verl kind of expects that you understand all of this um on the left we have uh uh the right we have gpo as presented in the original deepseek math paper back from early 2024 and like there's a lot of pieces here a lot of like complicated steps going on that I think a lot of people who are used to thinking about APIs used to thinking about building agents kind of like are hoping they don't have to worry about it um and are hoping that like you can just set it aside and like something else will work and we'll just use the APIs and it'll all be great and I think the reality is like somewhere in the middle where like I think it doesn't need to be this complicated but I think you also kind of do have to be aware of it if your goal is really like building the most performant agents not necessarily just like today you need to know about it but as a piece of the toolkit to potentially make really powerful agentic software i think the people who are willing to do this and take the best open models and really RL them for their tasks and can figure out how to do that well are going to have a huge advantage and that's the kind of thing that also allows you to like build a moat beyond just like being a wrapper API and towards something where it's like oh I actually have my own model now but not everyone can be a big lab and so we kind of need to meet in the middle somewhere of like okay how do we make this a thing that starts to become feasible for startups for individual researchers to actually do uh and like at what scale does this become like feasible um and so agents are like the type of product that everyone's excited about we all like love cloud code and Devon and Manis and uh 03 and deep research and like these are the sorts of products that are really capturing people's attention um they're products that in their current iteration happen to work kind of because the models that are being used have like been RL to basically do these kinds of things um like Claude is a very good coding agent probably because it has been RL on a lot of code and so it's like not very surprising that if you plug Claude into essentially a while loop with some tools it's like quite good at doing these things because it's basically most likely been trained in almost that exact setting um same for things like 03 like it can do geogesser and whatever because whether it's literally geoger or something close to it they have talked about training it to do this image cropping trick like that's a a technique that it didn't just know how to do out of the box they said hey let's give it these tools to do that and use reinforcement learning to train it to do that and so that is kind of the recipe that we have seen coming from the big labs as if you want a powerful agent that can do a certain type of task you can use reinforcement learning to train it to do that task better Um and so these are kind of the same thing actually like building an agent uh the pieces of making an agent in terms of the harness the environment the tools and the iteration is essentially the same conceptual framing as canonical reinforcement learning in the sense of policies actions states rewards transition probabilities um and I think the more that we start to view agents as this umbrella which is not just about static chaining of API calls but as this interaction loop with evaluations that framing really is the way to think about RL which is you build a system where a thing is interacting with an environment and you have some way of evaluating how good it's doing and RL is simply an algorithm to improve based on the scores of these evaluations and if you're building agents and you're tuning your prompt and you're fiddling with your harnesses this is kind of like doing RL by hand what you're doing is you're saying like okay currently my evals are saying this let's make sure the eval are like capturing what I want let's look at the data let's see if the data matches what my evals are saying and then oh let's try a new prompt let's try giving it a new tool um let's try uh switching out the model um like this is the process which is also being targeted by reinforcement learning in the general sense beyond individual algorithms um about these algorithms like there's a few of them that are mo very important all of them have like different implementation details but in general the idea is you have a bunch of tasks like versions of your problem which are essentially prompts you have rollouts which are just completions potentially involving many steps of interactions but like one sequence of stuff happening and then you have evaluations potentially interly throughout or at the end of the sequence and what you're estimating is the advantage the advantage here is the idea that uh sometimes your model will be be better than others like these uh LMs are all uh non-deterministic you have temperature above zero you have different things happen in different uh rolls of the dice um and this uh forking process of saying like okay this time it did better than that time why was it different rl is really about saying like okay uh this is the actual thing that changed that resulted in the reward being better the eval being better this is the token at which I went down the good path versus the bad path um and whether you're doing PO or GRPO um like this is the mechanism by which you get the signal of like you have some things that sometimes went better sometimes went worse now you can kind of uh very surgically have the model learn to do more of the good stuff without changing too much overall i think this is also kind of maybe a reason why DPO I think people were hoping DPO would like really work well in my view DPO does not necessarily have this like fine grain advantage estimate like it's not really clear just from like a full good completion and a full bad completion where you're really getting the signal about these complex branching processes uh PO has this but it's also very expensive grpo I think has taken a lot of people kind of uh by storm in terms of like being a very nice like middle ground where it's more computationally efficient it's like simple to implement um but also it does have this kind of forking process that comes just from sampling um there's also just too many papers so like I think a lot of people just see a new paper every day and are like do I have to read this one um and I feel that too i think it's difficult to know upfront like which of these are going to be important which of them are just going to be like noise especially because lots of them have very sensationalist titles like oh Quen doesn't work um or like or everyone everything only works with Quen is like kind of true but like there's also more to the story than that and I think there's like different implementation details of like oh if you change the loss function like this in this experiment then it works and I think for most people it is best to just like kind of set this aside and to not get too caught up in the individual details of individual experiments and individual papers and kind of think more holistically about what is the process of reinforcement learning doing um what implementation details am I willing to kind of leave to other people to figure out and eventually come to me with like software that like has the the knob set correctly um and which pieces are actually important for solving the problems I care about um and so for a lot of people I think the things that are going to be really interesting um are things that are relating to actual software to actual problems that they want to solve in the world and agents I think are kind of the instantiation of that where this makes sense and the thing that makes an agent an agent is tools uh the ability to interact with an environment with a system a lot of people here are like very excited about MCP at the conference like MCP is just tools mcp is about giving your LM the ability to like interact with stuff to go solve problems that involve changing files making requests uh editing code running code um and so I think these are the papers that I get excited about because there feel like like there's parts of the puzzle that are not fully solved yet of like what's the right way to do all of this like there's still some open questions um but I think those are getting kind of refined we're starting to see more and more but like a lot of the code the tools we have out in the wild to like go do this like if you want to like go play around with RL most code bases are like very set up for like either code and math tasks or things that are quite similar to that this is kind of my fault um I had a a snippet go viral that was like here's how you do RL on like GSMK which is like a kind of easy math data set um and then I think I've seen a lot of people like stick with this as like oh we're gonna RL on math and I like this is also just like math is easy to evaluate um and I think people are eval parallel to this about like how to build a good eval um and so I think a lot of researchers gravitate towards things that like look like the benchmarks that are also really easy to eval because there's like a very clear signal of like okay this thing is like right this thing is wrong good okay we're doing RL um but like real world tasks are messier than that um we are not going to like get great software systems just by like hill climbing on whatever question answer benchmark is popular today um what we're going to do is we're going to have to do is start thinking about like the actual systems at hand and the challenges that emerge when we're trying to design these rewards and so like reward hacking is like a real thing um I think this is one of the lessons that like Rall works but also it's not like always going to work there are things that can go wrong and to me reward hacking is really a message about the difficulty of building good evals like uh what you really want with an eval is for it to be easier for your model to do the task than to hack the eval you want to build a reward signal that actually captures what you care about where uh gaming it is like more difficult than not gaming it if you can if the model can learn to do the task directly just by doing what you want it to do uh in the spirit of the task then like that is what will happen it will flow in the path of least resistance this is like models just want to learn but they want to learn to do better on reward signals and so your reward signals have to point in the direction of the thing you actually care about um otherwise like models will find cheats um and I think thinking about these things in combination kind of points a little bit towards a direction that I think is going to be very promising and there's some very early signs that like this actually can work um which is like when R1 came out I was kind of like speculating like what's next what are the things that are going to unlock this sort of technique being used more generally um and you people talk a lot about like generator verifier gaps like what are the differences between like solving a problem versus checking if you have a solution and a lot of problems like are much easier to check than solve but this isn't like a binary thing this is a spectrum of how difficult is it to verify a thing but um there's some kind of signs that you kind of can do evaluations on more ambiguous tasks by just breaking them down into smaller pieces and by using LMS as sub routines in your evaluations like LM judge on steroids where maybe you want to actually like train a specialized LM who is really good at doing these fine grain evaluations i like using the term rubric as a conceptual general umbrella around reward models reward functions alm as judge setups like the criteria on which you are evaluating a thing there's a cool paper from deepseek that I was thought found very exciting when it came out a couple months ago about like how to train reward models that like generate these rubrics on the fly there was a paper very recently that does this for creative writing and kind of found that like yes you actually can train reward models that will come up with nuanced fine-rain evaluation criteria for a task on the fly given the actual problem and this gives you something that results in a very like fine grain score that allows you to actually do RL and like keep getting better um and I think like this is an area that I'm really excited about to keep watching um but also like multi-turn multi-turn is probably where we're headed we want to do a jetic search we want to do tool calls software games long horizon planning computer use memory scaling on tool calls let you solve harder problems um and so how do we actually like do this what's the uh way to go about building multi- aent or multi-turn agentic systems to do and that we can use RL with um and I think the conceptual pieces here are environments are basically harnesses rewards are basically eval tasks are just prompts and your policy in the RL sense hopefully should just be as simple as like an LM API the I think the programming interface that makes sense for a lot of people is to have an API that you're writing code as if it's just a normal agent in a loop but then this is a thing that you can use to go do RL and so that's what I've been building over the past couple months um I maintain a repo called verifiers um it's finally uh on pip uh out in the world you can just install it but it's been a long time coming um and what it really is is a toolkit of these pieces to make it so that building an agent that you can actually train with RL feels just like building an agent um so the interaction protocol here is like quite simple like this is the entire roll out function on the left of like what happens in the code when you're running an agent to do RL which is that you kind of set up some initial state stuff have a while loop for is it done yet if it's not done do a turn and the thing you're passing here is a client object that's just an OpenAI compatible API and I think this is the kind of interface that you really want if you want people to be able to go from their agent applications to something that's trainable to something they can use with RL um it's been a lot of fun thinking about like what are the abstractions what are the pieces here and so like there's things like parsers and rubrics that I think are like nice building blocks that you sometimes want to use you can also like not use them if you don't want to but like I tried to make it fun and user friendly um the other day I like was like let's train a Wordle agent i think this was like a fun little toy problem where it's like it's not that hard of like a game for us as humans but like it's actually like kind of tricky to get your code to be this sort of thing where you have this like multi-turn interaction protocol that you actually can do learning with um but now it's like much easier like the code to do these things is like quite simple and the reward functions can kind of be relatively simple for this sort of setup where it's like okay you want to reward it for like uh solving the thing eventually but also like give it more rewards for doing it in less turns and like this is a 7B model like works reasonably well but one of the reasons it works um which I'll talk about in a sec is uh SF warm-up as a way of kind of lowering the barrier of entry like this the code as it is is very much set up so that like your environments for RL are also just like synthetic data loops or evals where you can plug in claude or deepseek or open AAI and like test so you don't have to like do RL to debug you can like debug with an API in terms of seeing is this a good eval is this a good reward once you're kind of comfortable with it you can like use whatever API you like that you are allowed to use and make synthetic data do some SFT on it and now you can start doing RL and this like helps a lot with small models um I think there's a lot of efficiency challenges that are like I've been kind of hard at work trying to solve in terms of like having all of your computation be utilized effectively having everything be like fully async so you don't have to worry about like batching um and that your trainer and your inference can kind of go at the same time you can be like a little bit off policy um a lot of engineering that I'm hoping like if you want to worry about that great dig into it fork the repo mess with things if you don't want to you shouldn't have to um and like the idea here is that this should become something that more people are trying out more people are having fun with with exploring and getting a feel for it um because if it's going to be a thing we have to worry about if this is the future of building better agent models uh for your applications like now's a good time to start um and so this stuff is set up so you can like on a couple GPUs like uh do a lot of interesting research like the barrier of entry is like much lower now than it used to be um I have a lot of fun doing this on like a couple GPUs uh we sell GPUs by the way um thanks everybody uh I don't think we have time for questions but uh yeah [Music]",
    "text_length": 20644,
    "word_count": 4028
  },
  "segments": [
    {
      "start": 0.27,
      "duration": 7.03,
      "text": "[Music]",
      "timestamp": "00:00"
    },
    {
      "start": 14.96,
      "duration": 1.52,
      "text": "hi everyone I'm Will Brown i'm at",
      "timestamp": "00:14"
    },
    {
      "start": 16.48,
      "duration": 1.92,
      "text": "Primeelect uh today I want to talk about",
      "timestamp": "00:16"
    },
    {
      "start": 18.4,
      "duration": 2.799,
      "text": "training agentic reasoners um just kind",
      "timestamp": "00:18"
    },
    {
      "start": 21.199,
      "duration": 2.561,
      "text": "of as a very high level overview I think",
      "timestamp": "00:21"
    },
    {
      "start": 23.76,
      "duration": 1.359,
      "text": "a lot of people here are really excited",
      "timestamp": "00:23"
    },
    {
      "start": 25.119,
      "duration": 1.761,
      "text": "about reasoning and a lot of people here",
      "timestamp": "00:25"
    },
    {
      "start": 26.88,
      "duration": 1.36,
      "text": "are really excited about agents but I",
      "timestamp": "00:26"
    },
    {
      "start": 28.24,
      "duration": 1.199,
      "text": "feel like a lot of the conversations",
      "timestamp": "00:28"
    },
    {
      "start": 29.439,
      "duration": 1.521,
      "text": "between these two topics are kind of",
      "timestamp": "00:29"
    },
    {
      "start": 30.96,
      "duration": 1.84,
      "text": "like different where people are like \"Oh",
      "timestamp": "00:30"
    },
    {
      "start": 32.8,
      "duration": 2.0,
      "text": "reasoning is this one thing and agents",
      "timestamp": "00:32"
    },
    {
      "start": 34.8,
      "duration": 1.2,
      "text": "are this other thing.\" And the",
      "timestamp": "00:34"
    },
    {
      "start": 36.0,
      "duration": 1.92,
      "text": "considerations of like reasoning are",
      "timestamp": "00:36"
    },
    {
      "start": 37.92,
      "duration": 1.12,
      "text": "very different from the considerations",
      "timestamp": "00:37"
    },
    {
      "start": 39.04,
      "duration": 1.519,
      "text": "of building agents and I think the high",
      "timestamp": "00:39"
    },
    {
      "start": 40.559,
      "duration": 1.441,
      "text": "level thesis of this talk is like no",
      "timestamp": "00:40"
    },
    {
      "start": 42.0,
      "duration": 2.32,
      "text": "they're kind of the same thing um and",
      "timestamp": "00:42"
    },
    {
      "start": 44.32,
      "duration": 2.8,
      "text": "you'll see why as we get into it um",
      "timestamp": "00:44"
    },
    {
      "start": 47.12,
      "duration": 1.599,
      "text": "first just to start like RL kind of",
      "timestamp": "00:47"
    },
    {
      "start": 48.719,
      "duration": 1.601,
      "text": "works now um I think for a long time",
      "timestamp": "00:48"
    },
    {
      "start": 50.32,
      "duration": 1.12,
      "text": "people were like \"Oh is that our going",
      "timestamp": "00:50"
    },
    {
      "start": 51.44,
      "duration": 1.36,
      "text": "to work is it not going to work how hard",
      "timestamp": "00:51"
    },
    {
      "start": 52.8,
      "duration": 2.56,
      "text": "is it going to be?\" Um and like DeepSeek",
      "timestamp": "00:52"
    },
    {
      "start": 55.36,
      "duration": 1.359,
      "text": "I think took a lot of people by surprise",
      "timestamp": "00:55"
    },
    {
      "start": 56.719,
      "duration": 1.601,
      "text": "for many reasons like the costs or",
      "timestamp": "00:56"
    },
    {
      "start": 58.32,
      "duration": 1.68,
      "text": "whatever and like how good it is",
      "timestamp": "00:58"
    },
    {
      "start": 60.0,
      "duration": 2.16,
      "text": "compared to the open models to the",
      "timestamp": "01:00"
    },
    {
      "start": 62.16,
      "duration": 1.92,
      "text": "closed the big labs as well as just it",
      "timestamp": "01:02"
    },
    {
      "start": 64.08,
      "duration": 2.0,
      "text": "being fully open um but I think it was",
      "timestamp": "01:04"
    },
    {
      "start": 66.08,
      "duration": 2.719,
      "text": "also just that it was RL applied at",
      "timestamp": "01:06"
    },
    {
      "start": 68.799,
      "duration": 3.041,
      "text": "scale working with surprisingly few",
      "timestamp": "01:08"
    },
    {
      "start": 71.84,
      "duration": 2.48,
      "text": "tweaks needed where you just like have a",
      "timestamp": "01:11"
    },
    {
      "start": 74.32,
      "duration": 1.52,
      "text": "good setup you have a good signal you",
      "timestamp": "01:14"
    },
    {
      "start": 75.84,
      "duration": 1.919,
      "text": "have a model that is good enough to do",
      "timestamp": "01:15"
    },
    {
      "start": 77.759,
      "duration": 2.641,
      "text": "some learning and you see this curve",
      "timestamp": "01:17"
    },
    {
      "start": 80.4,
      "duration": 2.88,
      "text": "where doing more RL results in the model",
      "timestamp": "01:20"
    },
    {
      "start": 83.28,
      "duration": 2.64,
      "text": "getting better um",
      "timestamp": "01:23"
    },
    {
      "start": 85.92,
      "duration": 1.44,
      "text": "and it's also kind of how everyone else",
      "timestamp": "01:25"
    },
    {
      "start": 87.36,
      "duration": 1.36,
      "text": "is doing it like this is what the big",
      "timestamp": "01:27"
    },
    {
      "start": 88.72,
      "duration": 2.56,
      "text": "labs are really banking on to drive the",
      "timestamp": "01:28"
    },
    {
      "start": 91.28,
      "duration": 2.479,
      "text": "next iterations of progress the 03",
      "timestamp": "01:31"
    },
    {
      "start": 93.759,
      "duration": 1.68,
      "text": "release is the one that OpenAI is really",
      "timestamp": "01:33"
    },
    {
      "start": 95.439,
      "duration": 2.0,
      "text": "excited about not GBT 4.5 like they",
      "timestamp": "01:35"
    },
    {
      "start": 97.439,
      "duration": 2.081,
      "text": "stopped serving the big pre-trained",
      "timestamp": "01:37"
    },
    {
      "start": 99.52,
      "duration": 2.4,
      "text": "model via API but they have continued to",
      "timestamp": "01:39"
    },
    {
      "start": 101.92,
      "duration": 1.44,
      "text": "really double down on the scaling",
      "timestamp": "01:41"
    },
    {
      "start": 103.36,
      "duration": 2.24,
      "text": "direction of doing more and more",
      "timestamp": "01:43"
    },
    {
      "start": 105.6,
      "duration": 1.44,
      "text": "reinforcement learning and spending more",
      "timestamp": "01:45"
    },
    {
      "start": 107.04,
      "duration": 2.56,
      "text": "compute on reinforcement learning once",
      "timestamp": "01:47"
    },
    {
      "start": 109.6,
      "duration": 1.6,
      "text": "you have the right setup to enable",
      "timestamp": "01:49"
    },
    {
      "start": 111.2,
      "duration": 2.879,
      "text": "progress and 03 to me is like a very",
      "timestamp": "01:51"
    },
    {
      "start": 114.079,
      "duration": 2.481,
      "text": "naturally agentic model it the chat GBT",
      "timestamp": "01:54"
    },
    {
      "start": 116.56,
      "duration": 2.4,
      "text": "version has all these tools the kind of",
      "timestamp": "01:56"
    },
    {
      "start": 118.96,
      "duration": 1.68,
      "text": "selling point of it is not just that",
      "timestamp": "01:58"
    },
    {
      "start": 120.64,
      "duration": 1.839,
      "text": "it's smarter it's that it's really good",
      "timestamp": "02:00"
    },
    {
      "start": 122.479,
      "duration": 2.96,
      "text": "at using lots of tools in agentic task",
      "timestamp": "02:02"
    },
    {
      "start": 125.439,
      "duration": 2.32,
      "text": "settings to solve harder problems that",
      "timestamp": "02:05"
    },
    {
      "start": 127.759,
      "duration": 2.64,
      "text": "involve interacting with complex systems",
      "timestamp": "02:07"
    },
    {
      "start": 130.399,
      "duration": 2.001,
      "text": "and that is kind of really the selling",
      "timestamp": "02:10"
    },
    {
      "start": 132.4,
      "duration": 2.0,
      "text": "point of all of this is that like the",
      "timestamp": "02:12"
    },
    {
      "start": 134.4,
      "duration": 2.16,
      "text": "more complex your system the more things",
      "timestamp": "02:14"
    },
    {
      "start": 136.56,
      "duration": 2.0,
      "text": "can go wrong the more that like a",
      "timestamp": "02:16"
    },
    {
      "start": 138.56,
      "duration": 2.399,
      "text": "generic LM API is going to be brittle",
      "timestamp": "02:18"
    },
    {
      "start": 140.959,
      "duration": 1.681,
      "text": "and go off the rails after a certain",
      "timestamp": "02:20"
    },
    {
      "start": 142.64,
      "duration": 2.239,
      "text": "number of steps and RL is kind of the",
      "timestamp": "02:22"
    },
    {
      "start": 144.879,
      "duration": 1.841,
      "text": "way around it it's the trick you can do",
      "timestamp": "02:24"
    },
    {
      "start": 146.72,
      "duration": 2.56,
      "text": "to take the system that kind of works",
      "timestamp": "02:26"
    },
    {
      "start": 149.28,
      "duration": 1.76,
      "text": "maybe it works on small scales but as",
      "timestamp": "02:29"
    },
    {
      "start": 151.04,
      "duration": 1.839,
      "text": "you go harder it starts going off the",
      "timestamp": "02:31"
    },
    {
      "start": 152.879,
      "duration": 2.72,
      "text": "rails and train the model to be better",
      "timestamp": "02:32"
    },
    {
      "start": 155.599,
      "duration": 2.241,
      "text": "at that thing um and so this is a recipe",
      "timestamp": "02:35"
    },
    {
      "start": 157.84,
      "duration": 2.0,
      "text": "that is still kind of like a research",
      "timestamp": "02:37"
    },
    {
      "start": 159.84,
      "duration": 2.08,
      "text": "topic that people are not fully sure",
      "timestamp": "02:39"
    },
    {
      "start": 161.92,
      "duration": 1.92,
      "text": "like the best way to do it especially",
      "timestamp": "02:41"
    },
    {
      "start": 163.84,
      "duration": 2.72,
      "text": "outside of the big labs but it clearly",
      "timestamp": "02:43"
    },
    {
      "start": 166.56,
      "duration": 1.92,
      "text": "is moving in a direction where it's",
      "timestamp": "02:46"
    },
    {
      "start": 168.48,
      "duration": 2.0,
      "text": "becoming more and more reliable more and",
      "timestamp": "02:48"
    },
    {
      "start": 170.48,
      "duration": 2.0,
      "text": "more accessible and the sort of thing",
      "timestamp": "02:50"
    },
    {
      "start": 172.48,
      "duration": 2.64,
      "text": "that I think would be silly to disregard",
      "timestamp": "02:52"
    },
    {
      "start": 175.12,
      "duration": 3.199,
      "text": "as a potential like key piece of the",
      "timestamp": "02:55"
    },
    {
      "start": 178.319,
      "duration": 2.241,
      "text": "future of agentic software and agentic",
      "timestamp": "02:58"
    },
    {
      "start": 180.56,
      "duration": 1.92,
      "text": "applications uh but it's also",
      "timestamp": "03:00"
    },
    {
      "start": 182.48,
      "duration": 2.24,
      "text": "complicated so on the left here this is",
      "timestamp": "03:02"
    },
    {
      "start": 184.72,
      "duration": 2.0,
      "text": "the like architecture diagram of Veril",
      "timestamp": "03:04"
    },
    {
      "start": 186.72,
      "duration": 2.159,
      "text": "which is kind of the most popular",
      "timestamp": "03:06"
    },
    {
      "start": 188.879,
      "duration": 1.601,
      "text": "software people use in the research",
      "timestamp": "03:08"
    },
    {
      "start": 190.48,
      "duration": 3.28,
      "text": "world for writing papers to uh do RL so",
      "timestamp": "03:10"
    },
    {
      "start": 193.76,
      "duration": 1.68,
      "text": "if you want to like take a model and go",
      "timestamp": "03:13"
    },
    {
      "start": 195.44,
      "duration": 2.32,
      "text": "do RL Verl kind of expects that you",
      "timestamp": "03:15"
    },
    {
      "start": 197.76,
      "duration": 2.399,
      "text": "understand all of this um on the left we",
      "timestamp": "03:17"
    },
    {
      "start": 200.159,
      "duration": 2.321,
      "text": "have uh uh the right we have gpo as",
      "timestamp": "03:20"
    },
    {
      "start": 202.48,
      "duration": 1.6,
      "text": "presented in the original deepseek math",
      "timestamp": "03:22"
    },
    {
      "start": 204.08,
      "duration": 2.48,
      "text": "paper back from early 2024 and like",
      "timestamp": "03:24"
    },
    {
      "start": 206.56,
      "duration": 1.36,
      "text": "there's a lot of pieces here a lot of",
      "timestamp": "03:26"
    },
    {
      "start": 207.92,
      "duration": 3.039,
      "text": "like complicated steps going on that I",
      "timestamp": "03:27"
    },
    {
      "start": 210.959,
      "duration": 2.0,
      "text": "think a lot of people who are used to",
      "timestamp": "03:30"
    },
    {
      "start": 212.959,
      "duration": 1.521,
      "text": "thinking about APIs used to thinking",
      "timestamp": "03:32"
    },
    {
      "start": 214.48,
      "duration": 3.039,
      "text": "about building agents kind of like are",
      "timestamp": "03:34"
    },
    {
      "start": 217.519,
      "duration": 2.0,
      "text": "hoping they don't have to worry about it",
      "timestamp": "03:37"
    },
    {
      "start": 219.519,
      "duration": 3.681,
      "text": "um and are hoping that like you can just",
      "timestamp": "03:39"
    },
    {
      "start": 223.2,
      "duration": 2.16,
      "text": "set it aside and like something else",
      "timestamp": "03:43"
    },
    {
      "start": 225.36,
      "duration": 1.599,
      "text": "will work and we'll just use the APIs",
      "timestamp": "03:45"
    },
    {
      "start": 226.959,
      "duration": 2.64,
      "text": "and it'll all be great and I think the",
      "timestamp": "03:46"
    },
    {
      "start": 229.599,
      "duration": 1.36,
      "text": "reality is like somewhere in the middle",
      "timestamp": "03:49"
    },
    {
      "start": 230.959,
      "duration": 1.521,
      "text": "where like I think it doesn't need to be",
      "timestamp": "03:50"
    },
    {
      "start": 232.48,
      "duration": 1.92,
      "text": "this complicated but I think you also",
      "timestamp": "03:52"
    },
    {
      "start": 234.4,
      "duration": 1.44,
      "text": "kind of do have to be aware of it if",
      "timestamp": "03:54"
    },
    {
      "start": 235.84,
      "duration": 1.84,
      "text": "your goal is really like building the",
      "timestamp": "03:55"
    },
    {
      "start": 237.68,
      "duration": 1.279,
      "text": "most performant agents not necessarily",
      "timestamp": "03:57"
    },
    {
      "start": 238.959,
      "duration": 1.441,
      "text": "just like today you need to know about",
      "timestamp": "03:58"
    },
    {
      "start": 240.4,
      "duration": 2.88,
      "text": "it but as a piece of the toolkit to",
      "timestamp": "04:00"
    },
    {
      "start": 243.28,
      "duration": 1.76,
      "text": "potentially make really powerful agentic",
      "timestamp": "04:03"
    },
    {
      "start": 245.04,
      "duration": 1.759,
      "text": "software i think the people who are",
      "timestamp": "04:05"
    },
    {
      "start": 246.799,
      "duration": 3.601,
      "text": "willing to do this and take the best",
      "timestamp": "04:06"
    },
    {
      "start": 250.4,
      "duration": 2.08,
      "text": "open models and really RL them for their",
      "timestamp": "04:10"
    },
    {
      "start": 252.48,
      "duration": 1.52,
      "text": "tasks and can figure out how to do that",
      "timestamp": "04:12"
    },
    {
      "start": 254.0,
      "duration": 1.84,
      "text": "well are going to have a huge advantage",
      "timestamp": "04:14"
    },
    {
      "start": 255.84,
      "duration": 1.519,
      "text": "and that's the kind of thing that also",
      "timestamp": "04:15"
    },
    {
      "start": 257.359,
      "duration": 1.681,
      "text": "allows you to like build a moat beyond",
      "timestamp": "04:17"
    },
    {
      "start": 259.04,
      "duration": 1.52,
      "text": "just like being a wrapper API and",
      "timestamp": "04:19"
    },
    {
      "start": 260.56,
      "duration": 1.68,
      "text": "towards something where it's like oh I",
      "timestamp": "04:20"
    },
    {
      "start": 262.24,
      "duration": 2.959,
      "text": "actually have my own model now but not",
      "timestamp": "04:22"
    },
    {
      "start": 265.199,
      "duration": 1.521,
      "text": "everyone can be a big lab and so we kind",
      "timestamp": "04:25"
    },
    {
      "start": 266.72,
      "duration": 1.039,
      "text": "of need to meet in the middle somewhere",
      "timestamp": "04:26"
    },
    {
      "start": 267.759,
      "duration": 2.321,
      "text": "of like okay how do we make this a thing",
      "timestamp": "04:27"
    },
    {
      "start": 270.08,
      "duration": 2.88,
      "text": "that starts to become feasible for",
      "timestamp": "04:30"
    },
    {
      "start": 272.96,
      "duration": 2.0,
      "text": "startups for individual researchers to",
      "timestamp": "04:32"
    },
    {
      "start": 274.96,
      "duration": 2.64,
      "text": "actually do uh and like at what scale",
      "timestamp": "04:34"
    },
    {
      "start": 277.6,
      "duration": 2.4,
      "text": "does this become like feasible um and so",
      "timestamp": "04:37"
    },
    {
      "start": 280.0,
      "duration": 2.16,
      "text": "agents are like the type of product that",
      "timestamp": "04:40"
    },
    {
      "start": 282.16,
      "duration": 1.68,
      "text": "everyone's excited about we all like",
      "timestamp": "04:42"
    },
    {
      "start": 283.84,
      "duration": 2.96,
      "text": "love cloud code and Devon and Manis and",
      "timestamp": "04:43"
    },
    {
      "start": 286.8,
      "duration": 2.32,
      "text": "uh 03 and deep research and like these",
      "timestamp": "04:46"
    },
    {
      "start": 289.12,
      "duration": 1.28,
      "text": "are the sorts of products that are",
      "timestamp": "04:49"
    },
    {
      "start": 290.4,
      "duration": 2.0,
      "text": "really capturing people's attention um",
      "timestamp": "04:50"
    },
    {
      "start": 292.4,
      "duration": 1.6,
      "text": "they're products that in their current",
      "timestamp": "04:52"
    },
    {
      "start": 294.0,
      "duration": 2.479,
      "text": "iteration happen to work kind of because",
      "timestamp": "04:54"
    },
    {
      "start": 296.479,
      "duration": 2.241,
      "text": "the models that are being used have like",
      "timestamp": "04:56"
    },
    {
      "start": 298.72,
      "duration": 1.84,
      "text": "been RL to basically do these kinds of",
      "timestamp": "04:58"
    },
    {
      "start": 300.56,
      "duration": 2.639,
      "text": "things um like Claude is a very good",
      "timestamp": "05:00"
    },
    {
      "start": 303.199,
      "duration": 2.241,
      "text": "coding agent probably because it has",
      "timestamp": "05:03"
    },
    {
      "start": 305.44,
      "duration": 1.759,
      "text": "been RL on a lot of code and so it's",
      "timestamp": "05:05"
    },
    {
      "start": 307.199,
      "duration": 1.361,
      "text": "like not very surprising that if you",
      "timestamp": "05:07"
    },
    {
      "start": 308.56,
      "duration": 2.0,
      "text": "plug Claude into essentially a while",
      "timestamp": "05:08"
    },
    {
      "start": 310.56,
      "duration": 2.079,
      "text": "loop with some tools it's like quite",
      "timestamp": "05:10"
    },
    {
      "start": 312.639,
      "duration": 1.921,
      "text": "good at doing these things because it's",
      "timestamp": "05:12"
    },
    {
      "start": 314.56,
      "duration": 2.16,
      "text": "basically most likely been trained in",
      "timestamp": "05:14"
    },
    {
      "start": 316.72,
      "duration": 2.64,
      "text": "almost that exact setting um same for",
      "timestamp": "05:16"
    },
    {
      "start": 319.36,
      "duration": 2.0,
      "text": "things like 03 like it can do geogesser",
      "timestamp": "05:19"
    },
    {
      "start": 321.36,
      "duration": 1.92,
      "text": "and whatever because whether it's",
      "timestamp": "05:21"
    },
    {
      "start": 323.28,
      "duration": 1.52,
      "text": "literally geoger or something close to",
      "timestamp": "05:23"
    },
    {
      "start": 324.8,
      "duration": 2.48,
      "text": "it they have talked about training it to",
      "timestamp": "05:24"
    },
    {
      "start": 327.28,
      "duration": 1.84,
      "text": "do this image cropping trick like that's",
      "timestamp": "05:27"
    },
    {
      "start": 329.12,
      "duration": 2.079,
      "text": "a a technique that it didn't just know",
      "timestamp": "05:29"
    },
    {
      "start": 331.199,
      "duration": 1.84,
      "text": "how to do out of the box they said hey",
      "timestamp": "05:31"
    },
    {
      "start": 333.039,
      "duration": 1.841,
      "text": "let's give it these tools to do that and",
      "timestamp": "05:33"
    },
    {
      "start": 334.88,
      "duration": 1.68,
      "text": "use reinforcement learning to train it",
      "timestamp": "05:34"
    },
    {
      "start": 336.56,
      "duration": 1.76,
      "text": "to do that and so that is kind of the",
      "timestamp": "05:36"
    },
    {
      "start": 338.32,
      "duration": 1.439,
      "text": "recipe that we have seen coming from the",
      "timestamp": "05:38"
    },
    {
      "start": 339.759,
      "duration": 2.481,
      "text": "big labs as if you want a powerful agent",
      "timestamp": "05:39"
    },
    {
      "start": 342.24,
      "duration": 2.08,
      "text": "that can do a certain type of task you",
      "timestamp": "05:42"
    },
    {
      "start": 344.32,
      "duration": 1.52,
      "text": "can use reinforcement learning to train",
      "timestamp": "05:44"
    },
    {
      "start": 345.84,
      "duration": 3.12,
      "text": "it to do that task better Um and so",
      "timestamp": "05:45"
    },
    {
      "start": 348.96,
      "duration": 1.04,
      "text": "these are kind of the same thing",
      "timestamp": "05:48"
    },
    {
      "start": 350.0,
      "duration": 2.08,
      "text": "actually like building an agent uh the",
      "timestamp": "05:50"
    },
    {
      "start": 352.08,
      "duration": 3.04,
      "text": "pieces of making an agent in terms of",
      "timestamp": "05:52"
    },
    {
      "start": 355.12,
      "duration": 2.4,
      "text": "the harness the environment the tools",
      "timestamp": "05:55"
    },
    {
      "start": 357.52,
      "duration": 2.959,
      "text": "and the iteration is essentially the",
      "timestamp": "05:57"
    },
    {
      "start": 360.479,
      "duration": 3.201,
      "text": "same conceptual framing as canonical",
      "timestamp": "06:00"
    },
    {
      "start": 363.68,
      "duration": 1.84,
      "text": "reinforcement learning in the sense of",
      "timestamp": "06:03"
    },
    {
      "start": 365.52,
      "duration": 1.679,
      "text": "policies actions states rewards",
      "timestamp": "06:05"
    },
    {
      "start": 367.199,
      "duration": 2.481,
      "text": "transition probabilities um and I think",
      "timestamp": "06:07"
    },
    {
      "start": 369.68,
      "duration": 3.04,
      "text": "the more that we start to view agents as",
      "timestamp": "06:09"
    },
    {
      "start": 372.72,
      "duration": 2.479,
      "text": "this umbrella which is not just about",
      "timestamp": "06:12"
    },
    {
      "start": 375.199,
      "duration": 2.641,
      "text": "static chaining of API calls but as this",
      "timestamp": "06:15"
    },
    {
      "start": 377.84,
      "duration": 2.479,
      "text": "interaction loop with evaluations",
      "timestamp": "06:17"
    },
    {
      "start": 380.319,
      "duration": 2.72,
      "text": "that framing really is the way to think",
      "timestamp": "06:20"
    },
    {
      "start": 383.039,
      "duration": 1.841,
      "text": "about RL which is you build a system",
      "timestamp": "06:23"
    },
    {
      "start": 384.88,
      "duration": 1.68,
      "text": "where a thing is interacting with an",
      "timestamp": "06:24"
    },
    {
      "start": 386.56,
      "duration": 2.24,
      "text": "environment and you have some way of",
      "timestamp": "06:26"
    },
    {
      "start": 388.8,
      "duration": 3.519,
      "text": "evaluating how good it's doing and RL is",
      "timestamp": "06:28"
    },
    {
      "start": 392.319,
      "duration": 1.921,
      "text": "simply an algorithm to improve based on",
      "timestamp": "06:32"
    },
    {
      "start": 394.24,
      "duration": 2.48,
      "text": "the scores of these evaluations",
      "timestamp": "06:34"
    },
    {
      "start": 396.72,
      "duration": 1.68,
      "text": "and if you're building agents and you're",
      "timestamp": "06:36"
    },
    {
      "start": 398.4,
      "duration": 1.2,
      "text": "tuning your prompt and you're fiddling",
      "timestamp": "06:38"
    },
    {
      "start": 399.6,
      "duration": 2.08,
      "text": "with your harnesses this is kind of like",
      "timestamp": "06:39"
    },
    {
      "start": 401.68,
      "duration": 2.079,
      "text": "doing RL by hand what you're doing is",
      "timestamp": "06:41"
    },
    {
      "start": 403.759,
      "duration": 3.28,
      "text": "you're saying like okay currently my",
      "timestamp": "06:43"
    },
    {
      "start": 407.039,
      "duration": 1.521,
      "text": "evals are saying this let's make sure",
      "timestamp": "06:47"
    },
    {
      "start": 408.56,
      "duration": 1.84,
      "text": "the eval are like capturing what I want",
      "timestamp": "06:48"
    },
    {
      "start": 410.4,
      "duration": 1.76,
      "text": "let's look at the data let's see if the",
      "timestamp": "06:50"
    },
    {
      "start": 412.16,
      "duration": 3.12,
      "text": "data matches what my evals are saying",
      "timestamp": "06:52"
    },
    {
      "start": 415.28,
      "duration": 1.919,
      "text": "and then oh let's try a new prompt let's",
      "timestamp": "06:55"
    },
    {
      "start": 417.199,
      "duration": 2.881,
      "text": "try giving it a new tool um let's try uh",
      "timestamp": "06:57"
    },
    {
      "start": 420.08,
      "duration": 3.36,
      "text": "switching out the model um like this is",
      "timestamp": "07:00"
    },
    {
      "start": 423.44,
      "duration": 2.24,
      "text": "the process which is also being targeted",
      "timestamp": "07:03"
    },
    {
      "start": 425.68,
      "duration": 1.84,
      "text": "by reinforcement learning in the general",
      "timestamp": "07:05"
    },
    {
      "start": 427.52,
      "duration": 2.64,
      "text": "sense beyond individual algorithms um",
      "timestamp": "07:07"
    },
    {
      "start": 430.16,
      "duration": 2.08,
      "text": "about these algorithms like there's a",
      "timestamp": "07:10"
    },
    {
      "start": 432.24,
      "duration": 1.679,
      "text": "few of them that are mo very important",
      "timestamp": "07:12"
    },
    {
      "start": 433.919,
      "duration": 0.881,
      "text": "all of them have like different",
      "timestamp": "07:13"
    },
    {
      "start": 434.8,
      "duration": 2.48,
      "text": "implementation details but in general",
      "timestamp": "07:14"
    },
    {
      "start": 437.28,
      "duration": 2.0,
      "text": "the idea is you have a bunch of tasks",
      "timestamp": "07:17"
    },
    {
      "start": 439.28,
      "duration": 1.44,
      "text": "like versions of your problem which are",
      "timestamp": "07:19"
    },
    {
      "start": 440.72,
      "duration": 1.84,
      "text": "essentially prompts you have rollouts",
      "timestamp": "07:20"
    },
    {
      "start": 442.56,
      "duration": 1.44,
      "text": "which are just completions potentially",
      "timestamp": "07:22"
    },
    {
      "start": 444.0,
      "duration": 2.08,
      "text": "involving many steps of interactions but",
      "timestamp": "07:24"
    },
    {
      "start": 446.08,
      "duration": 3.04,
      "text": "like one sequence of stuff happening and",
      "timestamp": "07:26"
    },
    {
      "start": 449.12,
      "duration": 1.84,
      "text": "then you have evaluations potentially",
      "timestamp": "07:29"
    },
    {
      "start": 450.96,
      "duration": 1.76,
      "text": "interly throughout or at the end of the",
      "timestamp": "07:30"
    },
    {
      "start": 452.72,
      "duration": 2.16,
      "text": "sequence and what you're estimating is",
      "timestamp": "07:32"
    },
    {
      "start": 454.88,
      "duration": 2.159,
      "text": "the advantage the advantage here is the",
      "timestamp": "07:34"
    },
    {
      "start": 457.039,
      "duration": 2.801,
      "text": "idea that uh sometimes your model will",
      "timestamp": "07:37"
    },
    {
      "start": 459.84,
      "duration": 2.079,
      "text": "be be better than others like these uh",
      "timestamp": "07:39"
    },
    {
      "start": 461.919,
      "duration": 3.041,
      "text": "LMs are all uh non-deterministic you",
      "timestamp": "07:41"
    },
    {
      "start": 464.96,
      "duration": 1.84,
      "text": "have temperature above zero you have",
      "timestamp": "07:44"
    },
    {
      "start": 466.8,
      "duration": 1.92,
      "text": "different things happen in different uh",
      "timestamp": "07:46"
    },
    {
      "start": 468.72,
      "duration": 3.199,
      "text": "rolls of the dice um and this uh forking",
      "timestamp": "07:48"
    },
    {
      "start": 471.919,
      "duration": 2.0,
      "text": "process of saying like okay this time it",
      "timestamp": "07:51"
    },
    {
      "start": 473.919,
      "duration": 1.921,
      "text": "did better than that time why was it",
      "timestamp": "07:53"
    },
    {
      "start": 475.84,
      "duration": 2.4,
      "text": "different rl is really about saying like",
      "timestamp": "07:55"
    },
    {
      "start": 478.24,
      "duration": 4.079,
      "text": "okay uh this is the actual thing that",
      "timestamp": "07:58"
    },
    {
      "start": 482.319,
      "duration": 3.121,
      "text": "changed that resulted in the reward",
      "timestamp": "08:02"
    },
    {
      "start": 485.44,
      "duration": 1.84,
      "text": "being better the eval being better this",
      "timestamp": "08:05"
    },
    {
      "start": 487.28,
      "duration": 1.84,
      "text": "is the token at which I went down the",
      "timestamp": "08:07"
    },
    {
      "start": 489.12,
      "duration": 2.639,
      "text": "good path versus the bad path um and",
      "timestamp": "08:09"
    },
    {
      "start": 491.759,
      "duration": 3.601,
      "text": "whether you're doing PO or GRPO um like",
      "timestamp": "08:11"
    },
    {
      "start": 495.36,
      "duration": 2.32,
      "text": "this is the mechanism by which you get",
      "timestamp": "08:15"
    },
    {
      "start": 497.68,
      "duration": 2.72,
      "text": "the signal of like you have some things",
      "timestamp": "08:17"
    },
    {
      "start": 500.4,
      "duration": 1.44,
      "text": "that sometimes went better sometimes",
      "timestamp": "08:20"
    },
    {
      "start": 501.84,
      "duration": 2.799,
      "text": "went worse now you can kind of uh very",
      "timestamp": "08:21"
    },
    {
      "start": 504.639,
      "duration": 2.56,
      "text": "surgically have the model learn to do",
      "timestamp": "08:24"
    },
    {
      "start": 507.199,
      "duration": 1.921,
      "text": "more of the good stuff without changing",
      "timestamp": "08:27"
    },
    {
      "start": 509.12,
      "duration": 1.759,
      "text": "too much overall i think this is also",
      "timestamp": "08:29"
    },
    {
      "start": 510.879,
      "duration": 1.921,
      "text": "kind of maybe a reason why DPO I think",
      "timestamp": "08:30"
    },
    {
      "start": 512.8,
      "duration": 1.599,
      "text": "people were hoping DPO would like really",
      "timestamp": "08:32"
    },
    {
      "start": 514.399,
      "duration": 2.56,
      "text": "work well in my view DPO does not",
      "timestamp": "08:34"
    },
    {
      "start": 516.959,
      "duration": 1.841,
      "text": "necessarily have this like fine grain",
      "timestamp": "08:36"
    },
    {
      "start": 518.8,
      "duration": 1.359,
      "text": "advantage estimate like it's not really",
      "timestamp": "08:38"
    },
    {
      "start": 520.159,
      "duration": 1.76,
      "text": "clear just from like a full good",
      "timestamp": "08:40"
    },
    {
      "start": 521.919,
      "duration": 1.841,
      "text": "completion and a full bad completion",
      "timestamp": "08:41"
    },
    {
      "start": 523.76,
      "duration": 1.519,
      "text": "where you're really getting the signal",
      "timestamp": "08:43"
    },
    {
      "start": 525.279,
      "duration": 2.24,
      "text": "about these complex branching processes",
      "timestamp": "08:45"
    },
    {
      "start": 527.519,
      "duration": 2.241,
      "text": "uh PO has this but it's also very",
      "timestamp": "08:47"
    },
    {
      "start": 529.76,
      "duration": 1.92,
      "text": "expensive grpo I think has taken a lot",
      "timestamp": "08:49"
    },
    {
      "start": 531.68,
      "duration": 2.48,
      "text": "of people kind of uh by storm in terms",
      "timestamp": "08:51"
    },
    {
      "start": 534.16,
      "duration": 1.84,
      "text": "of like being a very nice like middle",
      "timestamp": "08:54"
    },
    {
      "start": 536.0,
      "duration": 1.76,
      "text": "ground where it's more computationally",
      "timestamp": "08:56"
    },
    {
      "start": 537.76,
      "duration": 2.56,
      "text": "efficient it's like simple to implement",
      "timestamp": "08:57"
    },
    {
      "start": 540.32,
      "duration": 2.72,
      "text": "um but also it does have this kind of",
      "timestamp": "09:00"
    },
    {
      "start": 543.04,
      "duration": 1.68,
      "text": "forking process that comes just from",
      "timestamp": "09:03"
    },
    {
      "start": 544.72,
      "duration": 2.88,
      "text": "sampling um there's also just too many",
      "timestamp": "09:04"
    },
    {
      "start": 547.6,
      "duration": 2.4,
      "text": "papers so like I think a lot of people",
      "timestamp": "09:07"
    },
    {
      "start": 550.0,
      "duration": 1.839,
      "text": "just see a new paper every day and are",
      "timestamp": "09:10"
    },
    {
      "start": 551.839,
      "duration": 2.0,
      "text": "like do I have to read this one um and I",
      "timestamp": "09:11"
    },
    {
      "start": 553.839,
      "duration": 1.12,
      "text": "feel that too",
      "timestamp": "09:13"
    },
    {
      "start": 554.959,
      "duration": 2.88,
      "text": "i think it's difficult to know upfront",
      "timestamp": "09:14"
    },
    {
      "start": 557.839,
      "duration": 1.841,
      "text": "like which of these are going to be",
      "timestamp": "09:17"
    },
    {
      "start": 559.68,
      "duration": 1.2,
      "text": "important which of them are just going",
      "timestamp": "09:19"
    },
    {
      "start": 560.88,
      "duration": 2.32,
      "text": "to be like noise especially because lots",
      "timestamp": "09:20"
    },
    {
      "start": 563.2,
      "duration": 1.68,
      "text": "of them have very sensationalist titles",
      "timestamp": "09:23"
    },
    {
      "start": 564.88,
      "duration": 3.2,
      "text": "like oh Quen doesn't work um or like or",
      "timestamp": "09:24"
    },
    {
      "start": 568.08,
      "duration": 1.68,
      "text": "everyone everything only works with Quen",
      "timestamp": "09:28"
    },
    {
      "start": 569.76,
      "duration": 2.4,
      "text": "is like kind of true but like there's",
      "timestamp": "09:29"
    },
    {
      "start": 572.16,
      "duration": 1.6,
      "text": "also more to the story than that and I",
      "timestamp": "09:32"
    },
    {
      "start": 573.76,
      "duration": 0.96,
      "text": "think there's like different",
      "timestamp": "09:33"
    },
    {
      "start": 574.72,
      "duration": 1.92,
      "text": "implementation details of like oh if you",
      "timestamp": "09:34"
    },
    {
      "start": 576.64,
      "duration": 1.28,
      "text": "change the loss function like this in",
      "timestamp": "09:36"
    },
    {
      "start": 577.92,
      "duration": 2.88,
      "text": "this experiment then it works and I",
      "timestamp": "09:37"
    },
    {
      "start": 580.8,
      "duration": 2.64,
      "text": "think for most people it is best to just",
      "timestamp": "09:40"
    },
    {
      "start": 583.44,
      "duration": 2.88,
      "text": "like kind of set this aside and to not",
      "timestamp": "09:43"
    },
    {
      "start": 586.32,
      "duration": 2.24,
      "text": "get too caught up in the individual",
      "timestamp": "09:46"
    },
    {
      "start": 588.56,
      "duration": 2.48,
      "text": "details of individual experiments and",
      "timestamp": "09:48"
    },
    {
      "start": 591.04,
      "duration": 1.919,
      "text": "individual papers and kind of think more",
      "timestamp": "09:51"
    },
    {
      "start": 592.959,
      "duration": 1.681,
      "text": "holistically about what is the process",
      "timestamp": "09:52"
    },
    {
      "start": 594.64,
      "duration": 2.4,
      "text": "of reinforcement learning doing um what",
      "timestamp": "09:54"
    },
    {
      "start": 597.04,
      "duration": 1.6,
      "text": "implementation details am I willing to",
      "timestamp": "09:57"
    },
    {
      "start": 598.64,
      "duration": 1.6,
      "text": "kind of leave to other people to figure",
      "timestamp": "09:58"
    },
    {
      "start": 600.24,
      "duration": 1.52,
      "text": "out and eventually come to me with like",
      "timestamp": "10:00"
    },
    {
      "start": 601.76,
      "duration": 2.0,
      "text": "software that like has the the knob set",
      "timestamp": "10:01"
    },
    {
      "start": 603.76,
      "duration": 2.72,
      "text": "correctly um and which pieces are",
      "timestamp": "10:03"
    },
    {
      "start": 606.48,
      "duration": 1.2,
      "text": "actually important for solving the",
      "timestamp": "10:06"
    },
    {
      "start": 607.68,
      "duration": 2.48,
      "text": "problems I care about um and so for a",
      "timestamp": "10:07"
    },
    {
      "start": 610.16,
      "duration": 1.28,
      "text": "lot of people I think the things that",
      "timestamp": "10:10"
    },
    {
      "start": 611.44,
      "duration": 2.56,
      "text": "are going to be really interesting um",
      "timestamp": "10:11"
    },
    {
      "start": 614.0,
      "duration": 1.76,
      "text": "are things that are relating to actual",
      "timestamp": "10:14"
    },
    {
      "start": 615.76,
      "duration": 1.68,
      "text": "software to actual problems that they",
      "timestamp": "10:15"
    },
    {
      "start": 617.44,
      "duration": 2.32,
      "text": "want to solve in the world and agents I",
      "timestamp": "10:17"
    },
    {
      "start": 619.76,
      "duration": 1.28,
      "text": "think are kind of the instantiation of",
      "timestamp": "10:19"
    },
    {
      "start": 621.04,
      "duration": 2.239,
      "text": "that where this makes sense and the",
      "timestamp": "10:21"
    },
    {
      "start": 623.279,
      "duration": 2.081,
      "text": "thing that makes an agent an agent is",
      "timestamp": "10:23"
    },
    {
      "start": 625.36,
      "duration": 2.24,
      "text": "tools uh the ability to interact with an",
      "timestamp": "10:25"
    },
    {
      "start": 627.6,
      "duration": 1.6,
      "text": "environment with a system a lot of",
      "timestamp": "10:27"
    },
    {
      "start": 629.2,
      "duration": 1.12,
      "text": "people here are like very excited about",
      "timestamp": "10:29"
    },
    {
      "start": 630.32,
      "duration": 2.16,
      "text": "MCP at the conference like MCP is just",
      "timestamp": "10:30"
    },
    {
      "start": 632.48,
      "duration": 3.12,
      "text": "tools mcp is about giving your LM the",
      "timestamp": "10:32"
    },
    {
      "start": 635.6,
      "duration": 3.679,
      "text": "ability to like interact with stuff to",
      "timestamp": "10:35"
    },
    {
      "start": 639.279,
      "duration": 2.321,
      "text": "go solve problems that involve changing",
      "timestamp": "10:39"
    },
    {
      "start": 641.6,
      "duration": 2.4,
      "text": "files making requests uh editing code",
      "timestamp": "10:41"
    },
    {
      "start": 644.0,
      "duration": 2.8,
      "text": "running code um and so I think these are",
      "timestamp": "10:44"
    },
    {
      "start": 646.8,
      "duration": 1.12,
      "text": "the papers that I get excited about",
      "timestamp": "10:46"
    },
    {
      "start": 647.92,
      "duration": 1.76,
      "text": "because there feel like like there's",
      "timestamp": "10:47"
    },
    {
      "start": 649.68,
      "duration": 1.2,
      "text": "parts of the puzzle that are not fully",
      "timestamp": "10:49"
    },
    {
      "start": 650.88,
      "duration": 1.28,
      "text": "solved yet of like what's the right way",
      "timestamp": "10:50"
    },
    {
      "start": 652.16,
      "duration": 1.6,
      "text": "to do all of this like there's still",
      "timestamp": "10:52"
    },
    {
      "start": 653.76,
      "duration": 3.519,
      "text": "some open questions um but I think those",
      "timestamp": "10:53"
    },
    {
      "start": 657.279,
      "duration": 1.761,
      "text": "are getting kind of refined we're",
      "timestamp": "10:57"
    },
    {
      "start": 659.04,
      "duration": 2.16,
      "text": "starting to see more and more but like a",
      "timestamp": "10:59"
    },
    {
      "start": 661.2,
      "duration": 2.0,
      "text": "lot of the code the tools we have out in",
      "timestamp": "11:01"
    },
    {
      "start": 663.2,
      "duration": 1.52,
      "text": "the wild to like go do this like if you",
      "timestamp": "11:03"
    },
    {
      "start": 664.72,
      "duration": 2.64,
      "text": "want to like go play around with RL most",
      "timestamp": "11:04"
    },
    {
      "start": 667.36,
      "duration": 2.479,
      "text": "code bases are like very set up for like",
      "timestamp": "11:07"
    },
    {
      "start": 669.839,
      "duration": 2.24,
      "text": "either code and math tasks or things",
      "timestamp": "11:09"
    },
    {
      "start": 672.079,
      "duration": 1.681,
      "text": "that are quite similar to that this is",
      "timestamp": "11:12"
    },
    {
      "start": 673.76,
      "duration": 3.12,
      "text": "kind of my fault um I had a a snippet go",
      "timestamp": "11:13"
    },
    {
      "start": 676.88,
      "duration": 3.04,
      "text": "viral that was like here's how you do RL",
      "timestamp": "11:16"
    },
    {
      "start": 679.92,
      "duration": 1.919,
      "text": "on like GSMK which is like a kind of",
      "timestamp": "11:19"
    },
    {
      "start": 681.839,
      "duration": 2.641,
      "text": "easy math data set um and then I think",
      "timestamp": "11:21"
    },
    {
      "start": 684.48,
      "duration": 1.52,
      "text": "I've seen a lot of people like stick",
      "timestamp": "11:24"
    },
    {
      "start": 686.0,
      "duration": 2.079,
      "text": "with this as like oh we're gonna RL on",
      "timestamp": "11:26"
    },
    {
      "start": 688.079,
      "duration": 1.44,
      "text": "math and I like this is also just like",
      "timestamp": "11:28"
    },
    {
      "start": 689.519,
      "duration": 2.88,
      "text": "math is easy to evaluate um and I think",
      "timestamp": "11:29"
    },
    {
      "start": 692.399,
      "duration": 3.761,
      "text": "people are eval",
      "timestamp": "11:32"
    },
    {
      "start": 696.16,
      "duration": 1.119,
      "text": "parallel to this about like how to build",
      "timestamp": "11:36"
    },
    {
      "start": 697.279,
      "duration": 3.201,
      "text": "a good eval um and so I think a lot of",
      "timestamp": "11:37"
    },
    {
      "start": 700.48,
      "duration": 1.28,
      "text": "researchers gravitate towards things",
      "timestamp": "11:40"
    },
    {
      "start": 701.76,
      "duration": 1.68,
      "text": "that like look like the benchmarks that",
      "timestamp": "11:41"
    },
    {
      "start": 703.44,
      "duration": 1.44,
      "text": "are also really easy to eval because",
      "timestamp": "11:43"
    },
    {
      "start": 704.88,
      "duration": 1.68,
      "text": "there's like a very clear signal of like",
      "timestamp": "11:44"
    },
    {
      "start": 706.56,
      "duration": 2.48,
      "text": "okay this thing is like right this thing",
      "timestamp": "11:46"
    },
    {
      "start": 709.04,
      "duration": 3.28,
      "text": "is wrong good okay we're doing RL um but",
      "timestamp": "11:49"
    },
    {
      "start": 712.32,
      "duration": 1.44,
      "text": "like real world tasks are messier than",
      "timestamp": "11:52"
    },
    {
      "start": 713.76,
      "duration": 3.36,
      "text": "that um we are not going to like get",
      "timestamp": "11:53"
    },
    {
      "start": 717.12,
      "duration": 2.719,
      "text": "great software systems just by like hill",
      "timestamp": "11:57"
    },
    {
      "start": 719.839,
      "duration": 2.321,
      "text": "climbing on whatever question answer",
      "timestamp": "11:59"
    },
    {
      "start": 722.16,
      "duration": 2.4,
      "text": "benchmark is popular today um what we're",
      "timestamp": "12:02"
    },
    {
      "start": 724.56,
      "duration": 1.44,
      "text": "going to do is we're going to have to do",
      "timestamp": "12:04"
    },
    {
      "start": 726.0,
      "duration": 1.92,
      "text": "is start thinking about like the actual",
      "timestamp": "12:06"
    },
    {
      "start": 727.92,
      "duration": 2.08,
      "text": "systems at hand and the challenges that",
      "timestamp": "12:07"
    },
    {
      "start": 730.0,
      "duration": 2.24,
      "text": "emerge when we're trying to design these",
      "timestamp": "12:10"
    },
    {
      "start": 732.24,
      "duration": 1.599,
      "text": "rewards and so like reward hacking is",
      "timestamp": "12:12"
    },
    {
      "start": 733.839,
      "duration": 1.921,
      "text": "like a real thing um I think this is one",
      "timestamp": "12:13"
    },
    {
      "start": 735.76,
      "duration": 2.16,
      "text": "of the lessons that like Rall works but",
      "timestamp": "12:15"
    },
    {
      "start": 737.92,
      "duration": 2.64,
      "text": "also it's not like always going to work",
      "timestamp": "12:17"
    },
    {
      "start": 740.56,
      "duration": 1.839,
      "text": "there are things that can go wrong and",
      "timestamp": "12:20"
    },
    {
      "start": 742.399,
      "duration": 1.921,
      "text": "to me reward hacking is really a message",
      "timestamp": "12:22"
    },
    {
      "start": 744.32,
      "duration": 1.84,
      "text": "about the difficulty of building good",
      "timestamp": "12:24"
    },
    {
      "start": 746.16,
      "duration": 3.28,
      "text": "evals like uh what you really want with",
      "timestamp": "12:26"
    },
    {
      "start": 749.44,
      "duration": 2.639,
      "text": "an eval is for it to be easier for your",
      "timestamp": "12:29"
    },
    {
      "start": 752.079,
      "duration": 2.32,
      "text": "model to do the task than to hack the",
      "timestamp": "12:32"
    },
    {
      "start": 754.399,
      "duration": 2.24,
      "text": "eval you want to build a reward signal",
      "timestamp": "12:34"
    },
    {
      "start": 756.639,
      "duration": 1.281,
      "text": "that actually captures what you care",
      "timestamp": "12:36"
    },
    {
      "start": 757.92,
      "duration": 4.64,
      "text": "about where uh gaming it is like more",
      "timestamp": "12:37"
    },
    {
      "start": 762.56,
      "duration": 2.24,
      "text": "difficult than not gaming it if you can",
      "timestamp": "12:42"
    },
    {
      "start": 764.8,
      "duration": 1.839,
      "text": "if the model can learn to do the task",
      "timestamp": "12:44"
    },
    {
      "start": 766.639,
      "duration": 2.961,
      "text": "directly just by doing what you want it",
      "timestamp": "12:46"
    },
    {
      "start": 769.6,
      "duration": 3.28,
      "text": "to do uh in the spirit of the task then",
      "timestamp": "12:49"
    },
    {
      "start": 772.88,
      "duration": 1.84,
      "text": "like that is what will happen it will",
      "timestamp": "12:52"
    },
    {
      "start": 774.72,
      "duration": 1.52,
      "text": "flow in the path of least resistance",
      "timestamp": "12:54"
    },
    {
      "start": 776.24,
      "duration": 1.52,
      "text": "this is like models just want to learn",
      "timestamp": "12:56"
    },
    {
      "start": 777.76,
      "duration": 2.079,
      "text": "but they want to learn to do better on",
      "timestamp": "12:57"
    },
    {
      "start": 779.839,
      "duration": 1.12,
      "text": "reward signals and so your reward",
      "timestamp": "12:59"
    },
    {
      "start": 780.959,
      "duration": 1.841,
      "text": "signals have to point in the direction",
      "timestamp": "13:00"
    },
    {
      "start": 782.8,
      "duration": 2.159,
      "text": "of the thing you actually care about um",
      "timestamp": "13:02"
    },
    {
      "start": 784.959,
      "duration": 2.721,
      "text": "otherwise like models will find cheats",
      "timestamp": "13:04"
    },
    {
      "start": 787.68,
      "duration": 2.959,
      "text": "um and I think thinking about these",
      "timestamp": "13:07"
    },
    {
      "start": 790.639,
      "duration": 2.241,
      "text": "things in combination kind of points a",
      "timestamp": "13:10"
    },
    {
      "start": 792.88,
      "duration": 1.12,
      "text": "little bit towards a direction that I",
      "timestamp": "13:12"
    },
    {
      "start": 794.0,
      "duration": 1.519,
      "text": "think is going to be very promising and",
      "timestamp": "13:14"
    },
    {
      "start": 795.519,
      "duration": 1.44,
      "text": "there's some very early signs that like",
      "timestamp": "13:15"
    },
    {
      "start": 796.959,
      "duration": 3.841,
      "text": "this actually can work um which is like",
      "timestamp": "13:16"
    },
    {
      "start": 800.8,
      "duration": 1.52,
      "text": "when R1 came out I was kind of like",
      "timestamp": "13:20"
    },
    {
      "start": 802.32,
      "duration": 1.92,
      "text": "speculating like what's next what are",
      "timestamp": "13:22"
    },
    {
      "start": 804.24,
      "duration": 2.48,
      "text": "the things that are going to unlock this",
      "timestamp": "13:24"
    },
    {
      "start": 806.72,
      "duration": 2.0,
      "text": "sort of technique being used more",
      "timestamp": "13:26"
    },
    {
      "start": 808.72,
      "duration": 3.52,
      "text": "generally um and you people talk a lot",
      "timestamp": "13:28"
    },
    {
      "start": 812.24,
      "duration": 1.68,
      "text": "about like generator verifier gaps like",
      "timestamp": "13:32"
    },
    {
      "start": 813.92,
      "duration": 1.68,
      "text": "what are the differences between like",
      "timestamp": "13:33"
    },
    {
      "start": 815.6,
      "duration": 1.52,
      "text": "solving a problem versus checking if you",
      "timestamp": "13:35"
    },
    {
      "start": 817.12,
      "duration": 1.04,
      "text": "have a solution and a lot of problems",
      "timestamp": "13:37"
    },
    {
      "start": 818.16,
      "duration": 2.56,
      "text": "like are much easier to check than solve",
      "timestamp": "13:38"
    },
    {
      "start": 820.72,
      "duration": 1.76,
      "text": "but this isn't like a binary thing this",
      "timestamp": "13:40"
    },
    {
      "start": 822.48,
      "duration": 1.52,
      "text": "is a spectrum of how difficult is it to",
      "timestamp": "13:42"
    },
    {
      "start": 824.0,
      "duration": 3.68,
      "text": "verify a thing but um there's some kind",
      "timestamp": "13:44"
    },
    {
      "start": 827.68,
      "duration": 2.56,
      "text": "of signs that you kind of can do",
      "timestamp": "13:47"
    },
    {
      "start": 830.24,
      "duration": 4.159,
      "text": "evaluations on more ambiguous tasks by",
      "timestamp": "13:50"
    },
    {
      "start": 834.399,
      "duration": 1.12,
      "text": "just breaking them down into smaller",
      "timestamp": "13:54"
    },
    {
      "start": 835.519,
      "duration": 4.161,
      "text": "pieces and by using LMS as sub routines",
      "timestamp": "13:55"
    },
    {
      "start": 839.68,
      "duration": 3.12,
      "text": "in your evaluations like LM judge on",
      "timestamp": "13:59"
    },
    {
      "start": 842.8,
      "duration": 1.12,
      "text": "steroids where maybe you want to",
      "timestamp": "14:02"
    },
    {
      "start": 843.92,
      "duration": 2.08,
      "text": "actually like train a specialized LM who",
      "timestamp": "14:03"
    },
    {
      "start": 846.0,
      "duration": 1.519,
      "text": "is really good at doing these fine grain",
      "timestamp": "14:06"
    },
    {
      "start": 847.519,
      "duration": 2.081,
      "text": "evaluations i like using the term rubric",
      "timestamp": "14:07"
    },
    {
      "start": 849.6,
      "duration": 2.64,
      "text": "as a conceptual general umbrella around",
      "timestamp": "14:09"
    },
    {
      "start": 852.24,
      "duration": 2.32,
      "text": "reward models reward functions alm as",
      "timestamp": "14:12"
    },
    {
      "start": 854.56,
      "duration": 2.48,
      "text": "judge setups like the criteria on which",
      "timestamp": "14:14"
    },
    {
      "start": 857.04,
      "duration": 1.76,
      "text": "you are evaluating a thing there's a",
      "timestamp": "14:17"
    },
    {
      "start": 858.8,
      "duration": 1.52,
      "text": "cool paper from deepseek that I was",
      "timestamp": "14:18"
    },
    {
      "start": 860.32,
      "duration": 1.28,
      "text": "thought found very exciting when it came",
      "timestamp": "14:20"
    },
    {
      "start": 861.6,
      "duration": 1.679,
      "text": "out a couple months ago about like how",
      "timestamp": "14:21"
    },
    {
      "start": 863.279,
      "duration": 1.441,
      "text": "to train reward models that like",
      "timestamp": "14:23"
    },
    {
      "start": 864.72,
      "duration": 1.84,
      "text": "generate these rubrics on the fly there",
      "timestamp": "14:24"
    },
    {
      "start": 866.56,
      "duration": 1.76,
      "text": "was a paper very recently that does this",
      "timestamp": "14:26"
    },
    {
      "start": 868.32,
      "duration": 1.28,
      "text": "for creative writing and kind of found",
      "timestamp": "14:28"
    },
    {
      "start": 869.6,
      "duration": 2.08,
      "text": "that like yes you actually can train",
      "timestamp": "14:29"
    },
    {
      "start": 871.68,
      "duration": 3.12,
      "text": "reward models that will come up with",
      "timestamp": "14:31"
    },
    {
      "start": 874.8,
      "duration": 2.24,
      "text": "nuanced fine-rain evaluation criteria",
      "timestamp": "14:34"
    },
    {
      "start": 877.04,
      "duration": 2.4,
      "text": "for a task on the fly given the actual",
      "timestamp": "14:37"
    },
    {
      "start": 879.44,
      "duration": 2.079,
      "text": "problem and this gives you something",
      "timestamp": "14:39"
    },
    {
      "start": 881.519,
      "duration": 2.081,
      "text": "that results in a very like fine grain",
      "timestamp": "14:41"
    },
    {
      "start": 883.6,
      "duration": 2.0,
      "text": "score that allows you to actually do RL",
      "timestamp": "14:43"
    },
    {
      "start": 885.6,
      "duration": 3.919,
      "text": "and like keep getting better um and I",
      "timestamp": "14:45"
    },
    {
      "start": 889.519,
      "duration": 1.841,
      "text": "think like this is an area that I'm",
      "timestamp": "14:49"
    },
    {
      "start": 891.36,
      "duration": 1.839,
      "text": "really excited about to keep watching um",
      "timestamp": "14:51"
    },
    {
      "start": 893.199,
      "duration": 2.481,
      "text": "but also like multi-turn multi-turn is",
      "timestamp": "14:53"
    },
    {
      "start": 895.68,
      "duration": 1.36,
      "text": "probably where we're headed we want to",
      "timestamp": "14:55"
    },
    {
      "start": 897.04,
      "duration": 1.2,
      "text": "do a jetic search we want to do tool",
      "timestamp": "14:57"
    },
    {
      "start": 898.24,
      "duration": 2.56,
      "text": "calls software games long horizon",
      "timestamp": "14:58"
    },
    {
      "start": 900.8,
      "duration": 2.159,
      "text": "planning computer use memory scaling on",
      "timestamp": "15:00"
    },
    {
      "start": 902.959,
      "duration": 2.161,
      "text": "tool calls let you solve harder problems",
      "timestamp": "15:02"
    },
    {
      "start": 905.12,
      "duration": 1.519,
      "text": "um and so how do we actually like do",
      "timestamp": "15:05"
    },
    {
      "start": 906.639,
      "duration": 2.481,
      "text": "this what's the uh way to go about",
      "timestamp": "15:06"
    },
    {
      "start": 909.12,
      "duration": 2.24,
      "text": "building multi- aent or multi-turn",
      "timestamp": "15:09"
    },
    {
      "start": 911.36,
      "duration": 2.159,
      "text": "agentic systems to do and that we can",
      "timestamp": "15:11"
    },
    {
      "start": 913.519,
      "duration": 2.32,
      "text": "use RL with um and I think the",
      "timestamp": "15:13"
    },
    {
      "start": 915.839,
      "duration": 1.921,
      "text": "conceptual pieces here are environments",
      "timestamp": "15:15"
    },
    {
      "start": 917.76,
      "duration": 1.759,
      "text": "are basically harnesses rewards are",
      "timestamp": "15:17"
    },
    {
      "start": 919.519,
      "duration": 2.56,
      "text": "basically eval tasks are just prompts",
      "timestamp": "15:19"
    },
    {
      "start": 922.079,
      "duration": 2.32,
      "text": "and your policy in the RL sense",
      "timestamp": "15:22"
    },
    {
      "start": 924.399,
      "duration": 1.921,
      "text": "hopefully should just be as simple as",
      "timestamp": "15:24"
    },
    {
      "start": 926.32,
      "duration": 2.24,
      "text": "like an LM API the I think the",
      "timestamp": "15:26"
    },
    {
      "start": 928.56,
      "duration": 1.2,
      "text": "programming interface that makes sense",
      "timestamp": "15:28"
    },
    {
      "start": 929.76,
      "duration": 2.16,
      "text": "for a lot of people is to have an API",
      "timestamp": "15:29"
    },
    {
      "start": 931.92,
      "duration": 1.68,
      "text": "that you're writing code as if it's just",
      "timestamp": "15:31"
    },
    {
      "start": 933.6,
      "duration": 2.56,
      "text": "a normal agent in a loop but then this",
      "timestamp": "15:33"
    },
    {
      "start": 936.16,
      "duration": 2.56,
      "text": "is a thing that you can use to go do RL",
      "timestamp": "15:36"
    },
    {
      "start": 938.72,
      "duration": 1.119,
      "text": "and so that's what I've been building",
      "timestamp": "15:38"
    },
    {
      "start": 939.839,
      "duration": 1.921,
      "text": "over the past couple months um I",
      "timestamp": "15:39"
    },
    {
      "start": 941.76,
      "duration": 3.36,
      "text": "maintain a repo called verifiers um it's",
      "timestamp": "15:41"
    },
    {
      "start": 945.12,
      "duration": 3.12,
      "text": "finally uh on pip uh out in the world",
      "timestamp": "15:45"
    },
    {
      "start": 948.24,
      "duration": 1.519,
      "text": "you can just install it but it's been a",
      "timestamp": "15:48"
    },
    {
      "start": 949.759,
      "duration": 2.561,
      "text": "long time coming um and what it really",
      "timestamp": "15:49"
    },
    {
      "start": 952.32,
      "duration": 2.959,
      "text": "is is a toolkit of these pieces to make",
      "timestamp": "15:52"
    },
    {
      "start": 955.279,
      "duration": 2.401,
      "text": "it so that building an agent that you",
      "timestamp": "15:55"
    },
    {
      "start": 957.68,
      "duration": 2.079,
      "text": "can actually train with RL feels just",
      "timestamp": "15:57"
    },
    {
      "start": 959.759,
      "duration": 1.681,
      "text": "like building an agent um so the",
      "timestamp": "15:59"
    },
    {
      "start": 961.44,
      "duration": 2.0,
      "text": "interaction protocol here is like quite",
      "timestamp": "16:01"
    },
    {
      "start": 963.44,
      "duration": 2.0,
      "text": "simple like this is the entire roll out",
      "timestamp": "16:03"
    },
    {
      "start": 965.44,
      "duration": 1.92,
      "text": "function on the left of like what",
      "timestamp": "16:05"
    },
    {
      "start": 967.36,
      "duration": 1.839,
      "text": "happens in the code when you're running",
      "timestamp": "16:07"
    },
    {
      "start": 969.199,
      "duration": 2.401,
      "text": "an agent to do RL which is that you kind",
      "timestamp": "16:09"
    },
    {
      "start": 971.6,
      "duration": 1.76,
      "text": "of set up some initial state stuff have",
      "timestamp": "16:11"
    },
    {
      "start": 973.36,
      "duration": 2.32,
      "text": "a while loop for is it done yet if it's",
      "timestamp": "16:13"
    },
    {
      "start": 975.68,
      "duration": 2.159,
      "text": "not done do a turn and the thing you're",
      "timestamp": "16:15"
    },
    {
      "start": 977.839,
      "duration": 2.401,
      "text": "passing here is a client object that's",
      "timestamp": "16:17"
    },
    {
      "start": 980.24,
      "duration": 2.64,
      "text": "just an OpenAI compatible API and I",
      "timestamp": "16:20"
    },
    {
      "start": 982.88,
      "duration": 2.399,
      "text": "think this is the kind of interface that",
      "timestamp": "16:22"
    },
    {
      "start": 985.279,
      "duration": 2.0,
      "text": "you really want if you want people to be",
      "timestamp": "16:25"
    },
    {
      "start": 987.279,
      "duration": 2.321,
      "text": "able to go from their agent applications",
      "timestamp": "16:27"
    },
    {
      "start": 989.6,
      "duration": 1.359,
      "text": "to something that's trainable to",
      "timestamp": "16:29"
    },
    {
      "start": 990.959,
      "duration": 2.481,
      "text": "something they can use with RL um it's",
      "timestamp": "16:30"
    },
    {
      "start": 993.44,
      "duration": 1.199,
      "text": "been a lot of fun thinking about like",
      "timestamp": "16:33"
    },
    {
      "start": 994.639,
      "duration": 1.281,
      "text": "what are the abstractions what are the",
      "timestamp": "16:34"
    },
    {
      "start": 995.92,
      "duration": 1.919,
      "text": "pieces here and so like there's things",
      "timestamp": "16:35"
    },
    {
      "start": 997.839,
      "duration": 1.36,
      "text": "like parsers and rubrics that I think",
      "timestamp": "16:37"
    },
    {
      "start": 999.199,
      "duration": 1.76,
      "text": "are like nice building blocks that you",
      "timestamp": "16:39"
    },
    {
      "start": 1000.959,
      "duration": 1.281,
      "text": "sometimes want to use you can also like",
      "timestamp": "16:40"
    },
    {
      "start": 1002.24,
      "duration": 1.279,
      "text": "not use them if you don't want to but",
      "timestamp": "16:42"
    },
    {
      "start": 1003.519,
      "duration": 1.76,
      "text": "like I tried to make it fun and user",
      "timestamp": "16:43"
    },
    {
      "start": 1005.279,
      "duration": 2.48,
      "text": "friendly um the other day I like was",
      "timestamp": "16:45"
    },
    {
      "start": 1007.759,
      "duration": 1.361,
      "text": "like let's train a Wordle agent i think",
      "timestamp": "16:47"
    },
    {
      "start": 1009.12,
      "duration": 1.519,
      "text": "this was like a fun little toy problem",
      "timestamp": "16:49"
    },
    {
      "start": 1010.639,
      "duration": 2.801,
      "text": "where it's like it's not that hard of",
      "timestamp": "16:50"
    },
    {
      "start": 1013.44,
      "duration": 2.399,
      "text": "like a game for us as humans but like",
      "timestamp": "16:53"
    },
    {
      "start": 1015.839,
      "duration": 1.68,
      "text": "it's actually like kind of tricky to get",
      "timestamp": "16:55"
    },
    {
      "start": 1017.519,
      "duration": 2.0,
      "text": "your code to be this sort of thing where",
      "timestamp": "16:57"
    },
    {
      "start": 1019.519,
      "duration": 1.601,
      "text": "you have this like multi-turn",
      "timestamp": "16:59"
    },
    {
      "start": 1021.12,
      "duration": 1.76,
      "text": "interaction protocol that you actually",
      "timestamp": "17:01"
    },
    {
      "start": 1022.88,
      "duration": 2.24,
      "text": "can do learning with um but now it's",
      "timestamp": "17:02"
    },
    {
      "start": 1025.12,
      "duration": 2.16,
      "text": "like much easier like the code to do",
      "timestamp": "17:05"
    },
    {
      "start": 1027.28,
      "duration": 1.758,
      "text": "these things is like quite simple and",
      "timestamp": "17:07"
    },
    {
      "start": 1029.039,
      "duration": 1.92,
      "text": "the reward functions can kind of be",
      "timestamp": "17:09"
    },
    {
      "start": 1030.959,
      "duration": 1.441,
      "text": "relatively simple for this sort of setup",
      "timestamp": "17:10"
    },
    {
      "start": 1032.4,
      "duration": 1.36,
      "text": "where it's like okay you want to reward",
      "timestamp": "17:12"
    },
    {
      "start": 1033.76,
      "duration": 2.158,
      "text": "it for like uh solving the thing",
      "timestamp": "17:13"
    },
    {
      "start": 1035.919,
      "duration": 1.681,
      "text": "eventually but also like give it more",
      "timestamp": "17:15"
    },
    {
      "start": 1037.6,
      "duration": 1.68,
      "text": "rewards for doing it in less turns and",
      "timestamp": "17:17"
    },
    {
      "start": 1039.28,
      "duration": 2.638,
      "text": "like this is a 7B model like works",
      "timestamp": "17:19"
    },
    {
      "start": 1041.919,
      "duration": 1.519,
      "text": "reasonably well but one of the reasons",
      "timestamp": "17:21"
    },
    {
      "start": 1043.439,
      "duration": 2.321,
      "text": "it works um which I'll talk about in a",
      "timestamp": "17:23"
    },
    {
      "start": 1045.76,
      "duration": 2.798,
      "text": "sec is uh SF warm-up as a way of kind of",
      "timestamp": "17:25"
    },
    {
      "start": 1048.559,
      "duration": 2.24,
      "text": "lowering the barrier of entry like this",
      "timestamp": "17:28"
    },
    {
      "start": 1050.799,
      "duration": 1.76,
      "text": "the code as it is is very much set up so",
      "timestamp": "17:30"
    },
    {
      "start": 1052.559,
      "duration": 2.0,
      "text": "that like your environments for RL are",
      "timestamp": "17:32"
    },
    {
      "start": 1054.559,
      "duration": 1.441,
      "text": "also just like synthetic data loops or",
      "timestamp": "17:34"
    },
    {
      "start": 1056.0,
      "duration": 2.64,
      "text": "evals where you can plug in claude or",
      "timestamp": "17:36"
    },
    {
      "start": 1058.64,
      "duration": 2.0,
      "text": "deepseek or open AAI and like test so",
      "timestamp": "17:38"
    },
    {
      "start": 1060.64,
      "duration": 1.76,
      "text": "you don't have to like do RL to debug",
      "timestamp": "17:40"
    },
    {
      "start": 1062.4,
      "duration": 2.24,
      "text": "you can like debug with an API in terms",
      "timestamp": "17:42"
    },
    {
      "start": 1064.64,
      "duration": 2.0,
      "text": "of seeing is this a good eval is this a",
      "timestamp": "17:44"
    },
    {
      "start": 1066.64,
      "duration": 1.44,
      "text": "good reward once you're kind of",
      "timestamp": "17:46"
    },
    {
      "start": 1068.08,
      "duration": 1.76,
      "text": "comfortable with it you can like use",
      "timestamp": "17:48"
    },
    {
      "start": 1069.84,
      "duration": 1.92,
      "text": "whatever API you like that you are",
      "timestamp": "17:49"
    },
    {
      "start": 1071.76,
      "duration": 2.4,
      "text": "allowed to use and make synthetic data",
      "timestamp": "17:51"
    },
    {
      "start": 1074.16,
      "duration": 1.92,
      "text": "do some SFT on it and now you can start",
      "timestamp": "17:54"
    },
    {
      "start": 1076.08,
      "duration": 1.599,
      "text": "doing RL and this like helps a lot with",
      "timestamp": "17:56"
    },
    {
      "start": 1077.679,
      "duration": 2.401,
      "text": "small models um I think there's a lot of",
      "timestamp": "17:57"
    },
    {
      "start": 1080.08,
      "duration": 2.24,
      "text": "efficiency challenges that are like I've",
      "timestamp": "18:00"
    },
    {
      "start": 1082.32,
      "duration": 1.2,
      "text": "been kind of hard at work trying to",
      "timestamp": "18:02"
    },
    {
      "start": 1083.52,
      "duration": 1.76,
      "text": "solve in terms of like having all of",
      "timestamp": "18:03"
    },
    {
      "start": 1085.28,
      "duration": 1.84,
      "text": "your computation be utilized effectively",
      "timestamp": "18:05"
    },
    {
      "start": 1087.12,
      "duration": 1.84,
      "text": "having everything be like fully async so",
      "timestamp": "18:07"
    },
    {
      "start": 1088.96,
      "duration": 1.12,
      "text": "you don't have to worry about like",
      "timestamp": "18:08"
    },
    {
      "start": 1090.08,
      "duration": 2.56,
      "text": "batching um and that your trainer and",
      "timestamp": "18:10"
    },
    {
      "start": 1092.64,
      "duration": 1.279,
      "text": "your inference can kind of go at the",
      "timestamp": "18:12"
    },
    {
      "start": 1093.919,
      "duration": 1.281,
      "text": "same time you can be like a little bit",
      "timestamp": "18:13"
    },
    {
      "start": 1095.2,
      "duration": 2.24,
      "text": "off policy um a lot of engineering that",
      "timestamp": "18:15"
    },
    {
      "start": 1097.44,
      "duration": 1.76,
      "text": "I'm hoping like if you want to worry",
      "timestamp": "18:17"
    },
    {
      "start": 1099.2,
      "duration": 2.479,
      "text": "about that great dig into it fork the",
      "timestamp": "18:19"
    },
    {
      "start": 1101.679,
      "duration": 2.161,
      "text": "repo mess with things if you don't want",
      "timestamp": "18:21"
    },
    {
      "start": 1103.84,
      "duration": 4.4,
      "text": "to you shouldn't have to um and like the",
      "timestamp": "18:23"
    },
    {
      "start": 1108.24,
      "duration": 1.679,
      "text": "idea here is that this should become",
      "timestamp": "18:28"
    },
    {
      "start": 1109.919,
      "duration": 2.721,
      "text": "something that more people are trying",
      "timestamp": "18:29"
    },
    {
      "start": 1112.64,
      "duration": 1.76,
      "text": "out more people are having fun with with",
      "timestamp": "18:32"
    },
    {
      "start": 1114.4,
      "duration": 3.12,
      "text": "exploring and getting a feel for it um",
      "timestamp": "18:34"
    },
    {
      "start": 1117.52,
      "duration": 1.519,
      "text": "because if it's going to be a thing we",
      "timestamp": "18:37"
    },
    {
      "start": 1119.039,
      "duration": 1.361,
      "text": "have to worry about if this is the",
      "timestamp": "18:39"
    },
    {
      "start": 1120.4,
      "duration": 2.639,
      "text": "future of building better agent models",
      "timestamp": "18:40"
    },
    {
      "start": 1123.039,
      "duration": 2.721,
      "text": "uh for your applications like now's a",
      "timestamp": "18:43"
    },
    {
      "start": 1125.76,
      "duration": 2.4,
      "text": "good time to start um and so this stuff",
      "timestamp": "18:45"
    },
    {
      "start": 1128.16,
      "duration": 1.6,
      "text": "is set up so you can like on a couple",
      "timestamp": "18:48"
    },
    {
      "start": 1129.76,
      "duration": 2.96,
      "text": "GPUs like uh do a lot of interesting",
      "timestamp": "18:49"
    },
    {
      "start": 1132.72,
      "duration": 1.52,
      "text": "research like the barrier of entry is",
      "timestamp": "18:52"
    },
    {
      "start": 1134.24,
      "duration": 2.319,
      "text": "like much lower now than it used to be",
      "timestamp": "18:54"
    },
    {
      "start": 1136.559,
      "duration": 1.921,
      "text": "um I have a lot of fun doing this on",
      "timestamp": "18:56"
    },
    {
      "start": 1138.48,
      "duration": 2.559,
      "text": "like a couple GPUs uh we sell GPUs by",
      "timestamp": "18:58"
    },
    {
      "start": 1141.039,
      "duration": 3.841,
      "text": "the way um thanks everybody uh I don't",
      "timestamp": "19:01"
    },
    {
      "start": 1144.88,
      "duration": 2.72,
      "text": "think we have time for questions but uh",
      "timestamp": "19:04"
    },
    {
      "start": 1147.6,
      "duration": 3.0,
      "text": "yeah",
      "timestamp": "19:07"
    },
    {
      "start": 1151.63,
      "duration": 6.54,
      "text": "[Music]",
      "timestamp": "19:11"
    }
  ],
  "extraction_timestamp": "2025-07-09T17:09:41",
  "processing_type": "single_video"
}