# Processing Result for: llm_processed_The Enterprise Awakens: Deploying Generative AI at Scale - SuperAI Singapore 2025
# Generated at: 2025-07-01T18:10:51.472031
# ==================================================

ProcessingResult(success=False, result=None, error="OpenAI API error: Error code: 400 - {'error': {'message': 'max_tokens is too large: 50000. This model supports at most 16384 completion tokens, whereas you provided 50000.', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'invalid_value'}}", input_data={'language': 'en', 'is_auto_generated': False, 'total_segments': 366, 'aggregated_text': 'a great crowd here i know you guys have been here for about 2 days and yeah very interesting topic uh enterprise uh AI and something that I\'m really uh passionate about uh one important stats that I search uh you know it\'s really enterprise AI is going to hit about $286 billion by 2026 alone and we have the experts in the house uh who will showcase to you like what are the use cases about enterprise AI we\'ll talk a lot about open source model some of the challenges and governance in terms of trust uh but first of all I\'d like to maybe uh get everyone to introduce themselves uh maybe start from Jason you can introduce yourself like who you are and like what do you feel most excited about yeah I\'m Jason i\'m executive chairman at Ironclad i founded the company 11 years ago and recently transitioned to executive chair from being CEO so I can spend more time doing this um uh and I\'d say like the thing that I\'m thinking about the most is uh disrupting ourselves we\'ve been around for 11 years and uh that\'s the thing on my mind yeah thanks Lel uh thanks Justin so uh my name is Girish uh I have been with Amazon for more than 10 years uh mostly focused on AI deep learning uh deep technology background in my current role I get to keep a track of how the technology is evolving chips models new techniques i\'m lucky to be able to travel and meet a lot of interesting people at different conferences so I advise AWS as well as AWS customers as well as different governments on AI adoption so yeah that\'s about me thanks hello sir thank you my name is Dona Huang i\'m work for Mastercard R&D team i joined the uh 14 years back as a first employee in R&D in Singapore and starting with for basis from scratch building the team and over a decade and then I decided to move on a global role leading emerging technology initially working with web3 and blockchain technologies but last couple of years I switch over to work on AI machine learning and the generative AI and very interestingly so I\'m I\'m also pursuing a part-time degree at doctorate degree at Singapore management university I\'m very excite excited to bring the latest um techniques in AI domain to our financial application development awesome thanks everyone uh and obviously it\'s a very hot topic because uh you know when I walk around there\'s a lot of like enterprise tech startups in terms of AI wise uh and I was talking to Jason just now like in terms of how he scaled his startups 11 years ago uh since September uh 2014 uh so my first question is to Jason uh what is the challenge in terms of scaling Genai from prototype to innovation in the legal tech arena I I know that you are a very strong builder and recently have transitioned to an executive chairman role and focus more on product maybe you can tell us from your experience very extensive experience of how uh you look at a challenge and maybe one of the the non uh non-obvious challenge also in terms of scaling that yeah so yeah so just for a bit of context Ironcloud we\'re on the enterprise panel so I can actually say our full category name without being embarrassed enterprise contract life cycle management which means we help companies and I think Mastercard is a great customer of ours with the entire life cycle of a business contract from the creation to the negotiation to the signatures and then the tracking and porting of that data to all of the places it needs to go and of course there\'s AI across all of that um and I think the real challenge and and perhaps surprising thing uh that is for us the thing that we spend a lot of time doing is making sure that AI works with the technology that is already in the enterprise so for lawyers uh what that means is working deeply with Microsoft Word and my one of my favorite anecdotes about building enterprise AI is we have some really great engineers we have uh folks from MIT a lot of our founding team um and early engineers at Palunteer and one of our best engineers he said that the hardest computer science problem he has ever worked on is programmatically turning text white turning text white in a uh docx file format in the browser so it gives you a sense of like where the real if you\'re going into the enterprise you really have to commit to to deeply working with the tools that are already there and not just building from scratch on uh the architecture you might want to use cuz I I kind of wish we didn\'t have to build on Microsoft Word and DocX but uh we do and that\'s the surprising thing for me yeah I guess exactly i think uh versatility and dynamism is so important especially in this day and age where we have to pivot and we have to scale uh the next question will be for Jes like you know what kind of uh architectural pitfalls or challenges do you see in enterprise AI and how does successful ones move past them we have discussed a lot about the open source model has we have uh discussed just now like maybe you can tell me more from your lens uh from the future and also the same time like what are the challenges and how do we overcome that yeah thanks for that question so uh enterprises uh see such a massive potential in adoption of AI but they have a huge legacy legacy of their success they can\'t uh they can\'t squander it right uh they have to make sure that the business is not disrupted while adopting AI so we do see massive adoption of AI to improve the bottom line uh that is to improve the efficiency we are seeing uh now uh very early adoption of AI to improve the top line like to generate net new revenue so both things are happening slowly but surely uh that said uh enterprises are bit more cautious and rightfully so in adopting AI so uh you and I were talking uh whether it\'s a skill set challenge it\'s not a skill set challenge of course if you are writing CUDA kernels and building models from scratch and all uh that skill set is not so widespread but most enterprise applications do not require the kind of skill set and now there are a lot of great coding tools and all so it\'s not a skill set issue at all but what happens with this technology is that going from 0 to 90 is very easy right you can spin up something that looks cool works fast you can show it to your team but when you start doing very thorough testing to go from that 90 to 100 it takes hell lot of time and the way enterprises think uh even if 99 things are right and one things are wrong they will think 10 times before adopting it so that is slowing down the adoption i\'m not saying that the caution is not warranted but yeah that is the scene of enterprise adoption but that said things are changing so enterprises are adopting primarily for internal uh use cases slowly they will do it for external use cases once they are more confident but at this stage it is mostly internal b2c is much lesser and uh there is also a lot of focus on open source this is new uh so so far people were using claude or you know Gemini or open AAI right and these uh models are not fully under the control of enterprises although uh platforms like bedrock offer uh lot of data security guarantees etc but enterprises like control rightfully so again uh so a lot of enterprises are exploring opensource AI uh my esteemed panelist had a great talk about it in the morning uh and opensource AI has become viable It wasn\'t viable before with Deep Sea Quen and lot of great hosting platforms so adoption was slow but we are seeing a massive J curve about to happen with commercial models and particularly with open source models long answer but yeah I have to say all those things amazing you can see the passion in Jerish when he explained open source model and the innovation in enterprise AI so over to Tongha like I attended your this morning\'s session about how do you regulate in terms of open source model itself uh one of the question that I got a lot in terms of financial industry uh is how do you build trust in terms of genai deployment especially in a very highly regulated industry like yourself and also uh maybe you can share with the audience some of the best practices uh that you deploy uh AI in your industry thank thank you for the question the very first thing we start even before we did start trying to use generative AI so we have established a very strong foundational principles the for data responsibility and ethical AI we we had mascar have been using AI for a long time combating the fraud um in real time so we have tried to use u uh built on top of the existing uh risk management principle to to reinforce that to be able to adapt that for our GI use cases the second part is we believe that um uh we we need to have a very strong governance structure in the in the enterprises so our AI governance um council is already in place for more than five years you consisting of of a team cross functional team of experts from uh data science um security legal and privacy and which uh try build a very very big focus on asking not only say can we build with generative AI or we kind of should we build with this kind of a technology and we also adopt uh the privacy by design for all the AI and data related product which make it the um very important in the finance where the customer trust and compliance um regulatory compliance are very important to us awesome thank you uh you mentioned a couple of different things uh governance and user trust and also at the same time uh privacy by design which is a very important word itself uh it goes back to the topic because uh obviously enterprise AI a lot of people would knew it has a very long sales cycle and obviously we have different stakeholders at play so I think the next question to the panel here is uh who decides the budget for enterprise AI do you need a chief AI officer to play the role maybe over to Jason in terms of explaining that yeah I mean I so for us we sell to we took kind of an unusual path to get where we are which is we sold to an underserved buyer the general counsel and one that was considered to be sort of a bad buyer of software but for us what that meant is like we could become the number one most important software solution to that buyer the the lawyer the chief legal officer the general counsel um and I think that my hot take would be that I think the end user is the right buyer um because the end user understands what their requirements are the best and we like selling to the lawyers because we can get deep with them and on the first call they can be asking questions about um a deep understanding of a contract negotiation and like understanding of why a particular result that an AI is showing them is superior to uh a different one so I would say that the right buyer is uh the the end user so uh AI at the end of the day is a technology so it needs to be cost effective secure scalable reliable so those uh things of traditional uh technology considerations equally apply so CTO\'s office needs to be uh very much involved uh very much uh attentive to AI projects but that said AI has its own characteristics uh with respect to reliability so unless end users are involved different departments and unless they sign off AI projects will not be successful so the end users are typically the real buyers or recommenders they can tell their CTO that it can save us like 20% 30% increase our speed by such and such percent so their involvement is required for sure it cannot come top down but we are seeing one trend that is uh uh not new I would say uh but it is worth noting down that lot of organizations are setting up something called as AI center of excellence so some people who are committed and passionate to roll out AI across the organization because while this technology is very powerful it has its rough ages so yeah there needs to be center of excellence but the final approval and the budget will typically come from the respective departments awesome yeah that\'s what I would say thanks yeah very interestingly actually M I mentioned that Mascal had been using the AI for quite some time since the advent of the chatb and the general AI technologies last year in April Mascat had a great big reorg to set up a a new um organization headed by our chief AI and data officer so combined our capability of AI and data together and recently they also they they also as part of that big organization they have a center of excellence for AI but which I I\'m partnering with them so the the recently they um uh we announced at Mascar that uh we are going to um build a series of the product platform to support the agent commerce so with Mascar we call agent pay uh platform which is led by that uh organization and I\'m I\'m I\'m very very happy to be part of the whole journey to uh to drive the uh future agent commerce you can imagine that you could have this uh your agent could pay on your behalf without you uh worry about to buy some grocery at $100 right so who who really cares right awesome i\'m hearing a lot of uh very interesting views one is the customer is the buyer second set up your center of excellence in the parts of the world to showcase your commitment the third as you mentioned in terms of the converging of the roles between the CIO chief AI officer and everything so this gives me to the next question in terms of uh what kind of best practice you know will you advocate to a startup founder who wants to start up something in the enterprise space we have a lot of startup entrepreneurs in in super AI and probably would love uh your perspective uh both from a company perspective and from a startup builder perspective so I my advice for a startup founder that wants to start to get to the enterprise is to not start in the enterprise um I I think what really helped us have a lot of momentum in the enterprise is that we built up a really strong mid-market and small business practice first uh and that helped us iterate on a much more rapid cycle the enterprise cycles are are long i mean we can it can take us a year to go through an enterprise sales cycle um whereas the small businesses and the mediumsiz businesses it\'s like 30 days and we\'re deployed 30 days later so that rhythm for us as a product focused company helped us build a really great product and then over time each year we would develop new capabilities that would allow us to make a little bit more progress into the enterprise um and then once we finally cracked in the enterprise it was kind of like the floodgates opened um but I think kind of getting battle tested in the mid-market helped us a lot and that would be my advice to a startup founder awesome durish so the question is what startups should do to be able to sell to enterprises exactly yeah if I\'m a startup founder if I want to start up an enterprise AI company uh should I should I not uh what kind of advice would you give them yeah yeah so uh good question so selling to enterprises is actually hard okay because they are very judicious they will ask so many questions and I advise a lot of startups um and they are very excited about the features adding agents how things are running and how the output is beautiful and all and all that is very valuable that\'s why we care about AI so much but enterprises as I said have a legacy to maintain right so they are going to quiz you a lot about uh not just cost enterprises generally pay well compared to the B2C customers uh But they want to know about how reliable your product is whether you are using guard rails in your AI application so that your AI doesn\'t say stupid things or whether you are using rag properly so that your AI doesn\'t give unreliable answers right or you have things like automated reasoning or tool call when the AI must do some simple mathematics to give the answer right so these are the kind of conversations that startups need to be prepared to have and they also need to think about what the compliance team of the enterprise is going to think about it or what the regulators are going to say about it so for example if you are trying to sell it to a bank but if you cannot answer the typical questions that the banking regulators in that nation have then you are not going to be able to successfully sell it to a bank right bank is never going to buy a product that their regulators are not going to be happy about so think of what regulators expect right so it is going to constrain you a bit or to some extent uh but if you ignore those constraints you cannot buy or sell to enterprises at Amazon we have a program called as SAS factory where we help you package your products well with all those considerations uh but yeah without those considerations being paid attention to you cannot successfully sell to enterprises so yeah that\'s what I have seen all the time interestingly that if you really want to sell your product to banks then try join master card start pass program actually we have thousand of startups already within our programs and recently we have a very big focus on AI and technologies so the the whole um startup kind of program is has been very successful I think it had won a lot of times of the best incubation program in the f financial industry so it\'s very well recognized normally we are masterard we are bit uh we put uh you the company into a consist program where we link you to a lot of global bank banks uh which are all our customers right so this is a best way of doing the collaboration with uh uh with the with mascard and to to sell your product to uh to banks normally at R&D whenever a startup approach me I always say okay if you don\'t join start pass then I cannot work with you so so basically that\'s my recommendation it\'s amazing uh obviously there\'s a lot of programs out there to facilitate startups who wants to venture into the enterprise space but we can also know that there are challenges out there like what Jason\'s mentioned in terms of like regulation and and policy framework uh so obviously you know it leads me to the kind of next question in terms of uh with the rise of you know open source model like deepse R1 the cost of compute the cost of uh designing an architecture has went down significantly uh I would love to understand from the panelists in terms of how do you view uh open source model and how do you see the evolution of open source model uh affecting enterprise AI maybe uh Jason yeah I mean I think that\'s definitely the trend that we\'re observing with uh peer companies and that our customers ask about i think for us we have historically been pretty closely aligned with OpenAI we\'re talking backstage but we Y Combinator is a big startup accelerator in the United States and the Sam Alman the CEO of OpenAI was the president of Y Combinator when we went through it so like we\'ve had a long-standing relationship with the company and um it\'s been a they\'ve been a great partner of ours but it is something that we\'re constantly evaluating and our teams are always looking at like definitely what the best model for the job is awesome yeah so uh we are partnered with Anthropic amazon has a big investment in Anthropic they train their models with Amazon chips uh they are available on Amazon\'s bedrock platform and I absolutely love anthropic like u like chatting with you feels like chatting to a very sensitive and intelligent human uh but that said uh that\'s a closed model uh we run it on bedrock we offer a lot of security guarantees and there are many customers who are very very happy some of the most regulated customers with that but at the same time in terms of capabilities uh opensource has caught up a thought right so open source actually uh always had a promise but it was quite disappointing till very recently right so uh open source people are talking about uh open source being an answer to closed source and all uh since at least when chat GP was launched and llama 1 got leaked uh but that promise uh didn\'t uh come to reality because open source lagged closed source in quality but thanks to letter of great labs in China uh it had changed right Deepc R1 amazing model their May update amazing Quen models very good price toerformance ratio so models are great but there was one more thing you need in addition to the models that is the middleware or the hosting infrastructure on which the models can run successfully so running open source models actually was expensive because you can never run it probably as efficiently as the big labs can run but that has also changed because of great people at VLM SG lang etc so we do see large enterprises governments who want to have complete visibility to their AI platform investing serious money and people power in exploring open-source models and given the fact that opensource has reached to such an extent that even if it didn\'t progress any further at all even it if it freezes in time here still those models are good enough for many many use cases so I generally like to give example of perplexity how many of you use perplexity here can I see a raise of hands yeah quite a few so others who haven\'t used it please download it amazing app thank me later and I always choose DeepSeek as a model on perplexity or I use its deep research feature brilliant brilliant experience right and it is powered by an open source model so open source has definitely arrived that is what I would say yeah so at Mascar product development we uh like uh Gish mentioned we really want to have full control of the what we are building so we when whenever we are trying to build touch our own prop priority data we always try to evaluate the our use our uh open source models so we can we probably initially we uh this morning I talk about the the product on boarding assistant the product developed by Mascar R&D we uh initially we use very big models like um DBRX and also the llama for five billion parameters is very huge and very slow and also very expensive but after we try create a train uh domain adaptation data for specifically for our product onboarding assistant tasks and we managed to get the uh performance uh 10% better but than the than the biggest models ever but also we managed to cut down the cost by four times and increase the speed by five times so that\'s in that kind of a uh approach we believe the open-source models are very good for enterprise applications especially for the vertical application you have very specific goals task just try to create your data fine-tune it and then you are get the best of the performance and the efficiency and of course the cost effectiveness thanks for the input a very huge velocity of change in terms of how open source can bring to enterprise companies in terms of uh higher performance lower costs at the same time in terms of streamlining your operation so uh yeah the next question would be like more of like if you have this uh you know you know if you look at the future of enterprise AI like what are the things that you are most looking forward to in the next uh 5 to 10 years uh for me it\'s it\'s getting really deep on the verticals i think like gen one has been just take the the benefits that the foundational models provide and translate them for a particular audience um I think we\'re going to see that trend increase tenfold and it we\'re going to see much more uh interesting and deep use cases uh for the different verticals um and so I I\'m excited for verticalization and at apps that continue to like exist on at that layer ai probably has been adopted the most by individuals right like the students indie developers and all that uh enterprises as I said have uh legacy to maintain so they are a bit slow to adopt uh rightfully so so most of the adoption so far has been focused on the bottom line that is to improve efficiency of code development of customer support uh because you can have immediate predictable gains there right but very few enterprises as of today are using AI for the top line top line in the sense to improve revenue uh to get more customers or to make more money per customer right so I keep giving example of this uh Robin Hood wealth adviser which is an FSI application built with help of AI to advise people on how to invest and they will take a cut based on whether the investment is successful or not but the point is this creates a net new revenue stream for the enterprise I\'m hoping in next 2 years we\'ll see a lot of that right now the focus has been on bottom line efficiency but we\'ll also see there are going to be some very bold companies like Mastercard uh supported by people like Jason who will be willing to take risk and use AI to get net new customers and get more revenue out of those customers by giving them great service so yeah that\'s what I\'m excited about for next two years so I I would hope that like I mentioned the agent pay uh platform we are trying to build i\'m really hoping that in the future you can have you your glass is very very smart has a kind you can it it kind of kind of agent running your glass or any any device you have and it can negotiate the agent with any any merchant for example you take a look at this TV show and hey I like it and then the agent can send my best favorite video to the VTP TV to show hey this is how cool it is and eventually I say I I can say hey Yes this is good i really like it i want to get it purchased by just talk to my glass and I get everything start sorted and then the TV will be shifted shipped to my to my home right so that\'s kind of a vision you think about all the agents can secure be under your control and running your edge device and with cloud uh um infrastructure to facilitate the secure communication across different agents that will be something I will be very excited awesome very uh fantastic view of like how you guys look at the futuristic view of uh enterprise AI from not just uh looking at cost cutting but at the same time in terms of streamlining your operations and uh I think it\'s really about productizing like a lot of what what you are having out there in a way and I think the the most important question like I get like in terms of like building the ecosystem wise is uh how enterprise AI and gender uh trust uh among users and also uh based one of the latest report from the CIO magazine uh user trust in terms of generative AI applications uh has fallen in a way so uh yeah I just want to take get a take from from from you guys in terms of like how do you look at trust in the age of AI and how does enterprise AI is able to engender that in their product management in their user deployment and also privacy by design which is a very good term coined by Tonga so maybe Jason over to you yeah and I think this is so foundational like to connect to your question on advice for startup founders as well if you want to sell to the enterprise trust is foundational it\'s not like a uh one thing you\'re scored on it is like a test that must be passed to sell on other things and you know one of the ways that that we do that is by showing the reasoning so we were one of the first um interfaces that would show you in real time sort of what the system was thinking and how it got to its result because we we talked to our user the lawyer and they\'re like "Well the results good but I kind of want to see how the AI got there cuz one it\'s going to help me prompt better next time um and two I want to see like what it did or did not evaluate to get to this end result." So I think we\'re starting to see some like best practices emerge and of course if you use a model like 03 you can actually see the reasoning now uh in that interface i think that trend is going to continue uh and as we find ways to build that feedback loop with systems yeah yeah so that was a very good point so what he mentioned is they show users how the model came to that particular advice the thought process so one of the reasons people absolutely love Deepseek and it went viral is because uh Deepseek thinks out loud you see the thought process it looks a lot like human thought process it\'s entertaining uh but it also increases the user confidence in the answer so that is made possible by other commercial models as well like cloud 3.7 uh in addition to that backing up the answer like every assertion or fact in the answer with a document reference is very important like perplexity does it so everything that it will say if you ask it a medical question it will uh point it to the research paper from where that answer came right so the users can verify so that is absolutely a must but apart from that there are some additional techniques for example Amazon launched something called as automated reasoning So that is one of the ways to automatically ensure that the model does not hallucinate there is also a lot of research happening uh at our partner anthropic they\'re trying to figure out how to detect through the activation states itself whether the model is hallucinating or not so uh please do read about uh these things uh like guardrails automated reasoning and what anthropic is doing that will allow you to build applications whose answers will be trustworthy but that said in my humble opinion even uh the user mindset needs to change the enterprise mindset need to change and regulator mindset need to change uh if a system can make a mistake like at 0.01% 01% times just because it made mistake that rarely you cannot throw away the system so there is this very uh uh infamous case of Air Canada uh so Air Canada had a chatbot and uh a person was asking questions about uh uh some refund or cancellation policy and the model hallucinated and it confirmed that there was a cancellation policy that didn\'t exist right so uh rightfully judges held Air Canada accountable to honor that policy uh they could have avoided it by using rag automated reasoning thinking out loud kind of techniques but that said no matter what you do no matter what you do okay this technology is not going to be 100% perfect okay it will be 99.99999% accurate with all these things but there is always going to be that some probability of a failure so in that sense this technology is like any other technology aircraft engine fails right so the user mindset need to evolve enterprise CIO mindset need to evolve and all of us need to work together with regulators to bring them to this appreciation that let us not throw away the baby with the bath water yes yes so it like um Kesh mentioned that the guarders are very important at mascot we are be very um uh very focused on building the guard for all the AI including generative AI applications so the one thing is very clear is that we want the yeah we want to use use leverage the power of the generative AI but we really want to make sure that when we we\'re building the products even though there\'s a 0.001% 001% of a failure that failure will not cause a big damage to your to to our enterprise applications or to our consumer card right so so imagine if you had doing kind of recently we did some research on the invoice reconstellation and we realize because of harnessation of da junken models you are updating the invoice ID 1 2 3 4 but it actually updated the mod the agent update 1 2 3 3 4 so it kind repetition problem I mentioned this morning and that might might have very bad effect let\'s say because just the first transaction might just be $10 but second one might be $10,000 right so that\'s will be a big impact to your business so all this part need to be safeguarded in the aentic AI time frames which is previously never been seen without that being solved from not from the model perspective but from the uh foundation software engineering perspective and and the guard rare perspective then we won\'t be able to safely roll out for um for scale use uses it\'s amazing it\'s really a masterclass in enterprise AI I\'m learning so much that trust is really the foundation of all uh generative AI deployment so the last question I want to throw to the panelists is like you know what is the last kind of message that you want to send to the crowd about enterprise AI hopes aspiration opport opportunity solutions yeah I mean I I just think it\'s an exciting time um I was telling to someone you know being from the legal tech vertical legal tech feels like it\'s f where fintech was uh 10 to 15 years ago and it\'s such a big space but it still feels like such early days um and so I think it\'s just very exciting and to be at a place like this where there\'s community built being built around those functions so what I would say is first figure out how the great looks like what I mean by that is install perplexity i\'m not a perplexity salesman i don\'t get uh any incentive for saying that but you will see how a well-designed app looks like use their deep research feature use perplexity lab feature so it will use Python to do simple mathematics the model will not do even simple mathematics by itself to ensure 100% accuracy so look at how the good looks like and set yourself that benchmark you can build those kind of applications for your enterprise customers or for yourself if you are an enterprise all the tools are available from various players we have all the tools available in bedrock uh so yeah look at what the great looks like and go for the skies yeah as previously one of our mascar executives said that the biggest risk of AI is not using it so like Gish mentioned download whatever apps I personally I have perplexity have chat GPD have claw all this in my my pocket already right so this not only help me to do all these kind of writing also the all the research um my research papers I also try to leverage the to polish my my languages because English is not my first language from enterprise perspective of course they uh try to find the best model not the big bigger model best vertical model for your applications that\'s awesome and uh thank you so much for all the panelists and obviously hope you guys have learned a lot about enterprise AI and I really value your opinion and contributions thank you so', 'text_length': 34007, 'word_count': 6464}, prompt_type='extract', model_used=None, tokens_used=None)